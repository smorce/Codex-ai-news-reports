{
  "generated_at": "2025-10-10T02:09:56Z",
  "site": "github-trending",
  "num_articles": 39,
  "articles": [
    {
      "url": "https://github.com/Stremio/stremio-web",
      "title": "Stremio/stremio-web",
      "date": null,
      "executive_summary": [
        "Stremio - Freedom to Stream",
        "---",
        "Stremio - Freedom to Stream\nStremio is a modern media center that's a one-stop solution for your video entertainment. You discover, watch and organize video content from easy to install addons.\nBuild\nPrerequisites\nNode.js 12 or higher\npnpm\n10 or higher\nInstall dependencies\npnpm install\nStart development server\npnpm start\nProduction build\npnpm run build\nRun with Docker\ndocker build -t stremio-web\n.\ndocker run -p 8080:8080 stremio-web\nScreenshots\nBoard\nDiscover\nMeta Details\nLicense\nStremio is copyright 2017-2023 Smart code and available under GPLv2 license. See the\nLICENSE\nfile in the project for more information.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 1,576",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 6,765"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/Stremio/stremio-web"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/TibixDev/winboat",
      "title": "TibixDev/winboat",
      "date": null,
      "executive_summary": [
        "Run Windows apps on üêß Linux with ‚ú® seamless integration",
        "---",
        "WinBoat\nWindows for Penguins.\nRun Windows apps on üêß Linux with ‚ú® seamless integration\nScreenshots\n‚ö†Ô∏è\nWork in Progress\n‚ö†Ô∏è\nWinBoat is currently in beta, so expect to occasionally run into hiccups and bugs. You should be comfortable with some level of troubleshooting if you decide to try it, however we encourage you to give it a shot anyway.\nFeatures\nüé® Elegant Interface\n: Sleek and intuitive interface that seamlessly integrates Windows into your Linux desktop environment, making it feel like a native experience\nüì¶ Automated Installs\n: Simple installation process through our interface - pick your preferences & specs and let us handle the rest\nüöÄ Run Any App\n: If it runs on Windows, it can run on WinBoat. Enjoy the full range of Windows applications as native OS-level windows in your Linux environment\nüñ•Ô∏è Full Windows Desktop\n: Access the complete Windows desktop experience when you need it, or run individual apps seamlessly integrated into your Linux workflow\nüìÅ Filesystem Integration\n: Your home directory is mounted in Windows, allowing easy file sharing between the two systems without any hassle\n‚ú® And many more\n: Smartcard passthrough, resource monitoring, and more features being added regularly\nHow Does It Work?\nWinBoat is an Electron app which allows you to run Windows apps on Linux using a containerized approach. Windows runs as a VM inside a Docker container, we communicate with it using the\nWinBoat Guest Server\nto retrieve data we need from Windows. For compositing applications as native OS-level windows, we use FreeRDP together with Windows's RemoteApp protocol.\nPrerequisites\nBefore running WinBoat, ensure your system meets the following requirements:\nRAM\n: At least 4 GB of RAM\nCPU\n: At least 2 CPU threads\nStorage\n: At least 32 GB free space in\n/var\nVirtualization\n: KVM enabled in BIOS/UEFI\nHow to enable virtualization\nDocker\n: Required for containerization\nInstallation Guide\n‚ö†Ô∏è\nNOTE:\nDocker Desktop is\nnot\nsupported, you will run into issues if you use it\nDocker Compose v2\n: Required for compatibility with docker-compose.yml files\nInstallation Guide\nDocker User Group\n: Add your user to the\ndocker\ngroup\nSetup Instructions\nFreeRDP\n: Required for remote desktop connection (Please make sure you have\nVersion 3.x.x\nwith sound support included)\nInstallation Guide\n[OPTIONAL]\nKernel Modules\n: The\niptables\n/\nnftables\nand\niptable_nat\nkernel modules can be loaded for network autodiscovery and better shared filesystem performance, but this is not obligatory in newer versions of WinBoat\nModule loading instructions\nDownloading\nYou can download the latest Linux builds under the\nReleases\ntab. We currently offer four variants:\nAppImage:\nA popular & portable app format which should run fine on most distributions\nUnpacked:\nThe raw unpacked files, simply run the executable (\nlinux-unpacked/winboat\n)\n.deb:\nThe intended format for Debian based distributions\n.rpm:\nThe intended format for Fedora based distributions\nKnown Issues About Container Runtimes\nPodman is\nunsupported\nfor now\nDocker Desktop is\nunsupported\nfor now\nDistros that emulate Docker through a Podman socket are\nunsupported\nAny rootless containerization solution is currently\nunsupported\nBuilding WinBoat\nFor building you need to have NodeJS and Go installed on your system\nClone the repo (\ngit clone https://github.com/TibixDev/WinBoat\n)\nInstall the dependencies (\nnpm i\n)\nBuild the app and the guest server using\nnpm run build:linux-gs\nYou can now find the built app under\ndist\nwith an AppImage and an Unpacked variant\nRunning WinBoat in development mode\nMake sure you meet the\nprerequisites\nAdditionally, for development you need to have NodeJS and Go installed on your system\nClone the repo (\ngit clone https://github.com/TibixDev/WinBoat\n)\nInstall the dependencies (\nnpm i\n)\nBuild the guest server (\nnpm run build-guest-server\n)\nRun the app (\nnpm run dev\n)\nContributing\nContributions are welcome! Whether it's bug fixes, feature improvements, or documentation updates, we appreciate your help making WinBoat better.\nPlease note\n: We maintain a focus on technical contributions only. Pull requests containing political/sexual content, or other sensitive/controversial topics will not be accepted. Let's keep things focused on making great software! üöÄ\nFeel free to:\nReport bugs and issues\nSubmit feature requests\nContribute code improvements\nHelp with documentation\nShare feedback and suggestions\nCheck out our issues page to get started, or feel free to open a new issue if you've found something that needs attention.\nLicense\nWinBoat is licensed under the\nMIT\nlicense\nInspiration / Alternatives\nThese past few years some cool projects have surfaced with similar concepts, some of which we've also taken inspirations from.\nThey're awesome and you should check them out:\nWinApps\nCassowary\ndockur/windows\n(üåü Also used in WinBoat)\nSocials & Contact\nStar History",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 859",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 8,356"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/TibixDev/winboat"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/TapXWorld/ChinaTextbook",
      "title": "TapXWorld/ChinaTextbook",
      "date": null,
      "executive_summary": [
        "ÊâÄÊúâÂ∞èÂàùÈ´ò„ÄÅÂ§ßÂ≠¶PDFÊïôÊùê„ÄÇ",
        "---",
        "È°πÁõÆÁöÑÁî±Êù•\nËôΩÁÑ∂ÂõΩÂÜÖÊïôËÇ≤ÁΩëÁ´ôÂ∑≤Êèê‰æõÂÖçË¥πËµÑÊ∫êÔºå‰ΩÜÂ§ßÂ§öÊï∞ÊôÆÈÄö‰∫∫Ëé∑Âèñ‰ø°ÊÅØÁöÑÈÄîÂæÑ‰æùÁÑ∂ÂèóÈôê„ÄÇÊúâ‰∫õ‰∫∫Âà©Áî®Ëøô‰∏ÄÁÇπÔºåÂú®ÊüêÁ´ô‰∏äÈîÄÂîÆËøô‰∫õÂ∏¶ÊúâÁßÅ‰∫∫Ê∞¥Âç∞ÁöÑËµÑÊ∫ê„ÄÇ‰∏∫‰∫ÜÂ∫îÂØπËøôÁßçÊÉÖÂÜµÔºåÊàëËÆ°ÂàíÂ∞ÜËøô‰∫õËµÑÊ∫êÈõÜ‰∏≠Âπ∂ÂºÄÊ∫êÔºå‰ª•‰øÉËøõ‰πâÂä°ÊïôËÇ≤ÁöÑÊôÆÂèäÂíåÊ∂àÈô§Âú∞Âå∫Èó¥ÁöÑÊïôËÇ≤Ë¥´Âõ∞„ÄÇ\nËøòÊúâ‰∏Ä‰∏™ÊúÄÈáçË¶ÅÁöÑÂéüÂõ†ÊòØÔºåÂ∏åÊúõÊµ∑Â§ñÂçé‰∫∫ËÉΩÂ§üËÆ©Ëá™Â∑±ÁöÑÂ≠©Â≠êÁªßÁª≠‰∫ÜËß£ÂõΩÂÜÖÊïôËÇ≤„ÄÇ\nÂ≠¶‰π†Êï∞Â≠¶\nÂ∏åÊúõÊú™Êù•Âá∫Áé∞Êõ¥Â§ö‰∏çÊòØ‰∏∫‰∫ÜËÄÉÂ≠¶ËÄåËØª‰π¶ÁöÑ‰∫∫„ÄÇ\nÂ∞èÂ≠¶Êï∞Â≠¶\n‰∏ÄÂπ¥Á∫ß‰∏äÂÜå\n‰∏ÄÂπ¥Á∫ß‰∏ãÂÜå\n‰∫åÂπ¥Á∫ß‰∏äÂÜå\n‰∫åÂπ¥Á∫ß‰∏ãÂÜå\n‰∏âÂπ¥Á∫ß‰∏äÂÜå\n‰∏âÂπ¥Á∫ß‰∏ãÂÜå\nÂõõÂπ¥Á∫ß‰∏äÂÜå\nÂõõÂπ¥Á∫ß‰∏ãÂÜå\n‰∫îÂπ¥Á∫ß‰∏äÂÜå\n‰∫îÂπ¥Á∫ß‰∏ãÂÜå\nÂÖ≠Âπ¥Á∫ß‰∏äÂÜå\nÂÖ≠Âπ¥Á∫ß‰∏ãÂÜå\nÂàù‰∏≠Êï∞Â≠¶\nÂàù‰∏Ä‰∏äÂÜå\nÂàù‰∏Ä‰∏ãÂÜå\nÂàù‰∫å‰∏äÂÜå\nÂàù‰∫å‰∏ãÂÜå\nÂàù‰∏â‰∏äÂÜå\nÂàù‰∏â‰∏ãÂÜå\nÈ´ò‰∏≠Êï∞Â≠¶\nÁõÆÂΩï\nÂ§ßÂ≠¶Êï∞Â≠¶\nÈ´òÁ≠âÊï∞Â≠¶\nÁ∫øÊÄß‰ª£Êï∞\nÁ¶ªÊï£Êï∞Â≠¶\nÊ¶ÇÁéáËÆ∫\nÊõ¥Â§öÊï∞Â≠¶ËµÑÊñô-(Â§ßÂ≠¶Êï∞Â≠¶ÁΩë)\nÈóÆÈ¢òÔºöÂ¶Ç‰ΩïÂêàÂπ∂Ë¢´ÊãÜÂàÜÁöÑÊñá‰ª∂Ôºü\nÁî±‰∫é GitHub ÂØπÂçï‰∏™Êñá‰ª∂ÁöÑ‰∏ä‰º†ÊúâÊúÄÂ§ßÈôêÂà∂ÔºåË∂ÖËøá 100MB ÁöÑÊñá‰ª∂‰ºöË¢´ÊãíÁªù‰∏ä‰º†ÔºåË∂ÖËøá 50MB ÁöÑÊñá‰ª∂‰∏ä‰º†Êó∂‰ºöÊî∂Âà∞Ë≠¶Âëä„ÄÇÂõ†Ê≠§ÔºåÊñá‰ª∂Â§ßÂ∞èË∂ÖËøá 50MB ÁöÑÊñá‰ª∂‰ºöË¢´ÊãÜÂàÜÊàêÊØè‰∏™ 35MB ÁöÑÂ§ö‰∏™Êñá‰ª∂„ÄÇ\nÁ§∫‰æã\nÊñá‰ª∂Ë¢´ÊãÜÂàÜÁöÑÁ§∫‰æãÔºö\n‰πâÂä°ÊïôËÇ≤ÊïôÁßë‰π¶ ¬∑ Êï∞Â≠¶‰∏ÄÂπ¥Á∫ß‰∏äÂÜå.pdf.1\n‰πâÂä°ÊïôËÇ≤ÊïôÁßë‰π¶ ¬∑ Êï∞Â≠¶‰∏ÄÂπ¥Á∫ß‰∏äÂÜå.pdf.2\nËß£ÂÜ≥ÂäûÊ≥ï\nË¶ÅÂêàÂπ∂Ëøô‰∫õË¢´ÊãÜÂàÜÁöÑÊñá‰ª∂ÔºåÊÇ®Âè™ÈúÄÊâßË°å‰ª•‰∏ãÊ≠•È™§(ÂÖ∂‰ªñÊìç‰ΩúÁ≥ªÁªüÂêåÁêÜ)Ôºö\nÂ∞ÜÂêàÂπ∂Á®ãÂ∫è\nmergePDFs-windows-amd64.exe\n‰∏ãËΩΩÂà∞ÂåÖÂê´ PDF Êñá‰ª∂ÁöÑÊñá‰ª∂Â§π‰∏≠„ÄÇ\nÁ°Æ‰øù\nmergePDFs-windows-amd64.exe\nÂíåË¢´ÊãÜÂàÜÁöÑ PDF Êñá‰ª∂Âú®Âêå‰∏ÄÁõÆÂΩï‰∏ã„ÄÇ\nÂèåÂáª\nmergePDFs-windows-amd64.exe\nÁ®ãÂ∫èÂç≥ÂèØËá™Âä®ÂÆåÊàêÊñá‰ª∂ÂêàÂπ∂„ÄÇ\n‰∏ãËΩΩÊñπÂºè\nÊÇ®ÂèØ‰ª•ÈÄöËøá‰ª•‰∏ãÈìæÊé•Ôºå‰∏ãËΩΩÊñá‰ª∂ÂêàÂπ∂Á®ãÂ∫èÔºö\n‰∏ãËΩΩÊñá‰ª∂ÂêàÂπ∂Á®ãÂ∫è\nÊñá‰ª∂ÂíåÁ®ãÂ∫èÁ§∫‰æã\nmergePDFs-windows-amd64.exe\n‰πâÂä°ÊïôËÇ≤ÊïôÁßë‰π¶ ¬∑ Êï∞Â≠¶‰∏ÄÂπ¥Á∫ß‰∏äÂÜå.pdf.1\n‰πâÂä°ÊïôËÇ≤ÊïôÁßë‰π¶ ¬∑ Êï∞Â≠¶‰∏ÄÂπ¥Á∫ß‰∏äÂÜå.pdf.2\nÈáçÊñ∞‰∏ãËΩΩ\nÂ¶ÇÊûúÊÇ®‰Ωç‰∫éÂÜÖÂú∞ÔºåÂπ∂‰∏îÁΩëÁªú‰∏çÈîôÔºåÊÉ≥ÈáçÊñ∞‰∏ãËΩΩÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî®\ntchMaterial-parser\nÈ°πÁõÆÔºàÈºìÂä±ÂºÄÊ∫êÔºâÔºåËøõË°åÈáçÊñ∞‰∏ãËΩΩ„ÄÇ\nÂ¶ÇÊûúÊÇ®‰Ωç‰∫éÂõΩÂ§ñÔºåÂíåÂÜÖÂú∞ÁΩëÁªúÈÄö‰ø°ÈÄüÂ∫¶ËæÉÊÖ¢ÔºåÂª∫ËÆÆ‰ΩøÁî®Êú¨Â≠òÂÇ®Â∫ìËøõË°åÁ≠æÂá∫„ÄÇ\nÊïôÊùêÊçêÁåÆ\nÂ¶ÇÊûúËøô‰∏™È°πÁõÆÂ∏ÆÂä©ÊÇ®ÂÖçË¥πËé∑ÂèñÊïôËÇ≤ËµÑÊ∫êÔºåËØ∑ËÄÉËôëÊîØÊåÅÊàë‰ª¨Êé®ÂπøÂºÄÊîæÊïôËÇ≤ÁöÑÂä™ÂäõÔºÅÊÇ®ÁöÑÊçêÁåÆÂ∞ÜÂ∏ÆÂä©Êàë‰ª¨Áª¥Êä§ÂíåÊâ©Â±ïËøô‰∏™ËµÑÊ∫êÂ∫ì„ÄÇ\nÂä†ÂÖ•Êàë‰ª¨ÁöÑ Telegram Á§æÂå∫ÔºåËé∑ÂèñÊúÄÊñ∞Âä®ÊÄÅÂπ∂ÂàÜ‰∫´ÊÇ®ÁöÑÊÉ≥Ê≥ïÔºö\nhttps://t.me/+1V6WjEq8WEM4MDM1\nÊîØÊåÅÊàë\nÂ¶ÇÊûúÊÇ®ËßâÂæóËøô‰∏™È°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåÊÇ®ÂèØ‰ª•Êâ´Êèè‰ª•‰∏ã‰∫åÁª¥Á†ÅËøõË°åÊçêËµ†Ôºö",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 606",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 52,156"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/TapXWorld/ChinaTextbook"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/aandrew-me/ytDownloader",
      "title": "aandrew-me/ytDownloader",
      "date": null,
      "executive_summary": [
        "Desktop App for downloading Videos and Audios from hundreds of sites",
        "---",
        "ytDownloader\nA modern GUI video and audio downloader supporting\nhundreds of sites\nFeatures üöÄ\n‚úÖ Supports hundreds of sites including Youtube, Facebook, Instagram, Tiktok, Twitter and so on.\n‚úÖ Multiple themes\n‚úÖ Video Compressor with Hardware Acceleration\n‚úÖ Advanced options like Range Selection, Subtitles\n‚úÖ Download playlists\n‚úÖ Available on Linux, Windows & macOS\n‚úÖ Fast download speeds\n‚úÖ And of-course no trackers or ads\nScreenshots\nInstallation\nWindows ü™ü\nTraditional way\nDownload and install the exe or msi file. Exe file lets you choose custom download location, msi file doesn't ask for location. Windows defender may show a popup saying\nWindows Protected Your PC\n. Just click on\nMore info\nand click on\nRun Anyway\nChocolatey\nApp can be installed from\nChocolatey\nusing the following command\nchoco install ytdownloader\nScoop\nApp can be installed with\nScoop\nusing the following command\nscoop install https://raw.githubusercontent.com/aandrew-me/ytDownloader/main/ytdownloader.json\nWinget\nApp can be installed with\nWinget\nusing the following command\nwinget install aandrew-me.ytDownloader\nLinux üêß\nLinux has several options available - Flatpak, AppImage and Snap.\nFlatpak is recommended. For arm processors, download from flathub.\nAppImage\nAppImage\nformat is supported on most Linux distros and has Auto-Update support.\nIt just needs to be executed after downloading. See more about\nAppImages here\n.\nAppImageLauncher\nis recommended for integrating AppImages.\nFlatpak\nflatpak install flathub io.github.aandrew_me.ytdn\nSnapcraft\nsudo snap install ytdownloader\nmacOS üçé\nSince the app is not signed, when you will try to open the app, macOS will not allow you to open it.\nYou need to open terminal and execute:\nsudo xattr -r -d com.apple.quarantine /Applications/YTDownloader.app\nYou will also need to install\nyt-dlp\nwith\nhomebrew\nbrew install yt-dlp\nInternationalization (Localization) üåç\nTranslations into other languages would be highly appreciated. If you want to help translating the app to other languages, you can join from\nhere\n. Open a new issue and that language will be added to Crowdin. Please don't make pull requests with json files, instead use Crowdin.\n‚úÖ Available languages\nName\nStatus\nArabic\n‚úîÔ∏è\nEnglish\n‚úîÔ∏è\nSimplified Chinese\n‚úîÔ∏è\nFinnish\n‚úîÔ∏è\nFrench\n‚úîÔ∏è\nGerman\n‚úîÔ∏è\nGreek\n‚úîÔ∏è\nHungarian\n‚úîÔ∏è\nItalian\n‚úîÔ∏è\nJapanese\n‚úîÔ∏è\nPersian\n‚úîÔ∏è\nPolish\n‚úîÔ∏è\nPortuguese (Brazil)\n‚úîÔ∏è\nRussian\n‚úîÔ∏è\nSpanish\n‚úîÔ∏è\nTurkish\n‚úîÔ∏è\nUkrainian\n‚úîÔ∏è\nVietnamese\n‚úîÔ∏è\nThanks to\nnxjosephofficial\n,\nLINUX-SAUNA\n,\nProxycon\n,\nalbanobattistella\n,\nTheBlueQuasar\n,\nMrQuerter\n,\nKotoWhiskas\n,\nAndr√©\n,\nhaggen88\n,\nXfedeX\n,\nJok3r\n,\nTitouanReal\n,\nsoredake\n,\nyoi\n,\nHowlingWerewolf\n,\nKum\n,\nMohammed Bakry\n,\nHuang Bingfeng\nand others for helping.\nUsed technologies\nyt-dlp\nElectron\nffmpeg\nnodeJS\nflaticon\nFor building or running from source code\nNodejs\n(along with npm) needs to be installed.\nRequired commands to get started.\ngit clone https://github.com/aandrew-me/ytDownloader.git\ncd ytDownloader\nnpm i\nTo run with\nElectron\n:\nnpm start\nYou need to download ffmpeg and put it in the root directory of the project. If you don't need to build for arm processor, you can download ffmpeg by executing any of the files - linux.sh / mac.sh / windows.sh depending on the platform. Otherwise you need to download ffmpeg from\nhere\nfor windows/linux and from\nhere\nfor mac (not tested)\nTo build for Linux (It will create packages as specified in package.json). The builds are stored in\nrelease\nfolder.\nnpm run linux\nTo build for Windows\nnpm run windows\nTo build for macOS\nnpm run mac\nIf you only want to build for one format, you can do\nnpx electron-builder -l appimage\nIt will just create a linux appimage build.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 541",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 4,281"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/aandrew-me/ytDownloader"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/browserbase/stagehand",
      "title": "browserbase/stagehand",
      "date": null,
      "executive_summary": [
        "The AI Browser Automation Framework",
        "---",
        "The AI Browser Automation Framework\nRead the Docs\nIf you're looking for the Python implementation, you can find it\nhere\nVibe code\nStagehand with\nDirector\nWhy Stagehand?\nMost existing browser automation tools either require you to write low-level code in a framework like Selenium, Playwright, or Puppeteer, or use high-level agents that can be unpredictable in production. By letting developers choose what to write in code vs. natural language, Stagehand is the natural choice for browser automations in production.\nChoose when to write code vs. natural language\n: use AI when you want to navigate unfamiliar pages, and use code (\nPlaywright\n) when you know exactly what you want to do.\nPreview and cache actions\n: Stagehand lets you preview AI actions before running them, and also helps you easily cache repeatable actions to save time and tokens.\nComputer use models with one line of code\n: Stagehand lets you integrate SOTA computer use models from OpenAI and Anthropic into the browser with one line of code.\nExample\nHere's how to build a sample browser automation with Stagehand:\n// Use Playwright functions on the page object\nconst\npage\n=\nstagehand\n.\npage\n;\nawait\npage\n.\ngoto\n(\n\"https://github.com/browserbase\"\n)\n;\n// Use act() to execute individual actions\nawait\npage\n.\nact\n(\n\"click on the stagehand repo\"\n)\n;\n// Use Computer Use agents for larger actions\nconst\nagent\n=\nstagehand\n.\nagent\n(\n{\nprovider\n:\n\"openai\"\n,\nmodel\n:\n\"computer-use-preview\"\n,\n}\n)\n;\nawait\nagent\n.\nexecute\n(\n\"Get to the latest PR\"\n)\n;\n// Use extract() to read data from the page\nconst\n{\nauthor\n,\ntitle\n}\n=\nawait\npage\n.\nextract\n(\n{\ninstruction\n:\n\"extract the author and title of the PR\"\n,\nschema\n:\nz\n.\nobject\n(\n{\nauthor\n:\nz\n.\nstring\n(\n)\n.\ndescribe\n(\n\"The username of the PR author\"\n)\n,\ntitle\n:\nz\n.\nstring\n(\n)\n.\ndescribe\n(\n\"The title of the PR\"\n)\n,\n}\n)\n,\n}\n)\n;\nDocumentation\nVisit\ndocs.stagehand.dev\nto view the full documentation.\nGetting Started\nStart with Stagehand with one line of code, or check out our\nQuickstart Guide\nfor more information:\nnpx create-browser-app\nWatch Anirudh demo create-browser-app to create a Stagehand project!\nBuild and Run from Source\ngit clone https://github.com/browserbase/stagehand.git\ncd\nstagehand\npnpm install\npnpm playwright install\npnpm run build\npnpm run example\n#\nrun the blank script at ./examples/example.ts\npnpm run example 2048\n#\nrun the 2048 example at ./examples/2048.ts\npnpm run evals -man\n#\nsee evaluation suite options\nStagehand is best when you have an API key for an LLM provider and Browserbase credentials. To add these to your project, run:\ncp .env.example .env\nnano .env\n#\nEdit the .env file to add API keys\nContributing\nNote\nWe highly value contributions to Stagehand! For questions or support, please join our\nSlack community\n.\nAt a high level, we're focused on improving reliability, speed, and cost in that order of priority. If you're interested in contributing, we strongly recommend reaching out to\nMiguel Gonzalez\nor\nPaul Klein\nin our\nSlack community\nbefore starting to ensure that your contribution aligns with our goals.\nFor more information, please see our\nContributing Guide\n.\nAcknowledgements\nThis project heavily relies on\nPlaywright\nas a resilient backbone to automate the web. It also would not be possible without the awesome techniques and discoveries made by\ntarsier\n,\ngemini-zod\n, and\nfuji-web\n.\nWe'd like to thank the following people for their major contributions to Stagehand:\nPaul Klein\nAnirudh Kamath\nSean McGuire\nMiguel Gonzalez\nSameel Arif\nFilip Michalsky\nJeremy Press\nNavid Pour\nLicense\nLicensed under the MIT License.\nCopyright 2025 Browserbase, Inc.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 366",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 17,891"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/browserbase/stagehand"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/BeehiveInnovations/zen-mcp-server",
      "title": "BeehiveInnovations/zen-mcp-server",
      "date": null,
      "executive_summary": [
        "The power of Claude Code / GeminiCLI / CodexCLI + [Gemini / OpenAI / OpenRouter / Azure / Grok / Ollama / Custom Model / All Of The Above] working as one.",
        "---",
        "Zen MCP: Many Workflows. One Context.\nZen_CLink_web.mp4\nüëâ\nWatch more examples\nYour CLI + Multiple Models = Your AI Dev Team\nUse the ü§ñ CLI you love:\nClaude Code\n¬∑\nGemini CLI\n¬∑\nCodex CLI\n¬∑\nQwen Code CLI\n¬∑\nCursor\n¬∑\nand more\nWith multiple models within a single prompt:\nGemini ¬∑ OpenAI ¬∑ Anthropic ¬∑ Grok ¬∑ Azure ¬∑ Ollama ¬∑ OpenRouter ¬∑ DIAL ¬∑ On-Device Model\nüÜï Now with CLI-to-CLI Bridge\nThe new\nclink\n(CLI + Link) tool connects external AI CLIs directly into your workflow:\nConnect external CLIs\nlike\nGemini CLI\n,\nCodex CLI\n, and\nClaude Code\ndirectly into your workflow\nCLI Subagents\n- Launch isolated CLI instances from\nwithin\nyour current CLI! Claude Code can spawn Codex subagents, Codex can spawn Gemini CLI subagents, etc. Offload heavy tasks (code reviews, bug hunting) to fresh contexts while your main session's context window remains unpolluted. Each subagent returns only final results.\nContext Isolation\n- Run separate investigations without polluting your primary workspace\nRole Specialization\n- Spawn\nplanner\n,\ncodereviewer\n, or custom role agents with specialized system prompts\nFull CLI Capabilities\n- Web search, file inspection, MCP tool access, latest documentation lookups\nSeamless Continuity\n- Sub-CLIs participate as first-class members with full conversation context between tools\n#\nCodex spawns Codex subagent for isolated code review in fresh context\nclink with codex codereviewer to audit auth module\nfor\nsecurity issues\n#\nSubagent reviews in isolation, returns final report without cluttering your context as codex reads each file and walks the directory structure\n#\nConsensus from different AI models ‚Üí Implementation handoff with full context preservation between tools\nUse consensus with gpt-5 and gemini-pro to decide: dark mode or offline support next\nContinue with clink gemini - implement the recommended feature\n#\nGemini receives full debate context and starts coding immediately\nüëâ\nLearn more about clink\nWhy Zen MCP?\nWhy rely on one AI model when you can orchestrate them all?\nA Model Context Protocol server that supercharges tools like\nClaude Code\n,\nCodex CLI\n, and IDE clients such\nas\nCursor\nor the\nClaude Dev VS Code extension\n.\nZen MCP connects your favorite AI tool\nto multiple AI models\nfor enhanced code analysis, problem-solving, and collaborative development.\nTrue AI Collaboration with Conversation Continuity\nZen supports\nconversation threading\nso your CLI can\ndiscuss ideas with multiple AI models, exchange reasoning, get second opinions, and even run collaborative debates between models\nto help you reach deeper insights and better solutions.\nYour CLI always stays in control but gets perspectives from the best AI for each subtask. Context carries forward seamlessly across tools and models, enabling complex workflows like: code reviews with multiple models ‚Üí automated planning ‚Üí implementation ‚Üí pre-commit validation.\nYou're in control.\nYour CLI of choice orchestrates the AI team, but you decide the workflow. Craft powerful prompts that bring in Gemini Pro, GPT 5, Flash, or local offline models exactly when needed.\nReasons to Use Zen MCP\nA typical workflow with Claude Code as an example:\nMulti-Model Orchestration\n- Claude coordinates with Gemini Pro, O3, GPT-5, and 50+ other models to get the best analysis for each task\nContext Revival Magic\n- Even after Claude's context resets, continue conversations seamlessly by having other models \"remind\" Claude of the discussion\nGuided Workflows\n- Enforces systematic investigation phases that prevent rushed analysis and ensure thorough code examination\nExtended Context Windows\n- Break Claude's limits by delegating to Gemini (1M tokens) or O3 (200K tokens) for massive codebases\nTrue Conversation Continuity\n- Full context flows across tools and models - Gemini remembers what O3 said 10 steps ago\nModel-Specific Strengths\n- Extended thinking with Gemini Pro, blazing speed with Flash, strong reasoning with O3, privacy with local Ollama\nProfessional Code Reviews\n- Multi-pass analysis with severity levels, actionable feedback, and consensus from multiple AI experts\nSmart Debugging Assistant\n- Systematic root cause analysis with hypothesis tracking and confidence levels\nAutomatic Model Selection\n- Claude intelligently picks the right model for each subtask (or you can specify)\nVision Capabilities\n- Analyze screenshots, diagrams, and visual content with vision-enabled models\nLocal Model Support\n- Run Llama, Mistral, or other models locally for complete privacy and zero API costs\nBypass MCP Token Limits\n- Automatically works around MCP's 25K limit for large prompts and responses\nThe Killer Feature:\nWhen Claude's context resets, just ask to \"continue with O3\" - the other model's response magically revives Claude's understanding without re-ingesting documents!\nExample: Multi-Model Code Review Workflow\nPerform a codereview using gemini pro and o3 and use planner to generate a detailed plan, implement the fixes and do a final precommit check by continuing from the previous codereview\nThis triggers a\ncodereview\nworkflow where Claude walks the code, looking for all kinds of issues\nAfter multiple passes, collects relevant code and makes note of issues along the way\nMaintains a\nconfidence\nlevel between\nexploring\n,\nlow\n,\nmedium\n,\nhigh\nand\ncertain\nto track how confidently it's been able to find and identify issues\nGenerates a detailed list of critical -> low issues\nShares the relevant files, findings, etc with\nGemini Pro\nto perform a deep dive for a second\ncodereview\nComes back with a response and next does the same with o3, adding to the prompt if a new discovery comes to light\nWhen done, Claude takes in all the feedback and combines a single list of all critical -> low issues, including good patterns in your code. The final list includes new findings or revisions in case Claude misunderstood or missed something crucial and one of the other models pointed this out\nIt then uses the\nplanner\nworkflow to break the work down into simpler steps if a major refactor is required\nClaude then performs the actual work of fixing highlighted issues\nWhen done, Claude returns to Gemini Pro for a\nprecommit\nreview\nAll within a single conversation thread! Gemini Pro in step 11\nknows\nwhat was recommended by O3 in step 7! Taking that context\nand review into consideration to aid with its final pre-commit review.\nThink of it as Claude Code\nfor\nClaude Code.\nThis MCP isn't magic. It's just\nsuper-glue\n.\nRemember:\nClaude stays in full control ‚Äî but\nYOU\ncall the shots.\nZen is designed to have Claude engage other models only when needed ‚Äî and to follow through with meaningful back-and-forth.\nYou're\nthe one who crafts the powerful prompt that makes Claude bring in Gemini, Flash, O3 ‚Äî or fly solo.\nYou're the guide. The prompter. The puppeteer.\nYou are the AI -\nActually Intelligent\n.\nRecommended AI Stack\nFor Claude Code Users\nFor best results when using\nClaude Code\n:\nSonnet 4.5\n- All agentic work and orchestration\nGemini 2.5 Pro\nOR\nGPT-5-Pro\n- Deep thinking, additional code reviews, debugging and validations, pre-commit analysis\nFor Codex Users\nFor best results when using\nCodex CLI\n:\nGPT-5 Codex Medium\n- All agentic work and orchestration\nGemini 2.5 Pro\nOR\nGPT-5-Pro\n- Deep thinking, additional code reviews, debugging and validations, pre-commit analysis\nQuick Start (5 minutes)\nPrerequisites:\nPython 3.10+, Git,\nuv installed\n1. Get API Keys\n(choose one or more):\nOpenRouter\n- Access multiple models with one API\nGemini\n- Google's latest models\nOpenAI\n- O3, GPT-5 series\nAzure OpenAI\n- Enterprise deployments of GPT-4o, GPT-4.1, GPT-5 family\nX.AI\n- Grok models\nDIAL\n- Vendor-agnostic model access\nOllama\n- Local models (free)\n2. Install\n(choose one):\nOption A: Clone and Automatic Setup\n(recommended)\ngit clone https://github.com/BeehiveInnovations/zen-mcp-server.git\ncd\nzen-mcp-server\n#\nHandles everything: setup, config, API keys from system environment.\n#\nAuto-configures Claude Desktop, Claude Code, Gemini CLI, Codex CLI, Qwen CLI\n#\nEnable / disable additional settings in .env\n./run-server.sh\nOption B: Instant Setup with\nuvx\n// Add to ~/.claude/settings.json or .mcp.json\n// Don't forget to add your API keys under env\n{\n\"mcpServers\"\n: {\n\"zen\"\n: {\n\"command\"\n:\n\"\nbash\n\"\n,\n\"args\"\n: [\n\"\n-c\n\"\n,\n\"\nfor p in $(which uvx 2>/dev/null) $HOME/.local/bin/uvx /opt/homebrew/bin/uvx /usr/local/bin/uvx uvx; do [ -x\n\\\"\n$p\n\\\"\n] && exec\n\\\"\n$p\n\\\"\n--from git+https://github.com/BeehiveInnovations/zen-mcp-server.git zen-mcp-server; done; echo 'uvx not found' >&2; exit 1\n\"\n],\n\"env\"\n: {\n\"PATH\"\n:\n\"\n/usr/local/bin:/usr/bin:/bin:/opt/homebrew/bin:~/.local/bin\n\"\n,\n\"GEMINI_API_KEY\"\n:\n\"\nyour-key-here\n\"\n,\n\"DISABLED_TOOLS\"\n:\n\"\nanalyze,refactor,testgen,secaudit,docgen,tracer\n\"\n,\n\"DEFAULT_MODEL\"\n:\n\"\nauto\n\"\n}\n    }\n  }\n}\n3. Start Using!\n\"Use zen to analyze this code for security issues with gemini pro\"\n\"Debug this error with o3 and then get flash to suggest optimizations\"\n\"Plan the migration strategy with zen, get consensus from multiple models\"\n\"clink with cli_name=\\\"gemini\\\" role=\\\"planner\\\" to draft a phased rollout plan\"\nüëâ\nComplete Setup Guide\nwith detailed installation, configuration for Gemini / Codex / Qwen, and troubleshooting\nüëâ\nCursor & VS Code Setup\nfor IDE integration instructions\nüì∫\nWatch tools in action\nto see real-world examples\nProvider Configuration\nZen activates any provider that has credentials in your\n.env\n. See\n.env.example\nfor deeper customization.\nCore Tools\nNote:\nEach tool comes with its own multi-step workflow, parameters, and descriptions that consume valuable context window space even when not in use. To optimize performance, some tools are disabled by default. See\nTool Configuration\nbelow to enable them.\nCollaboration & Planning\n(Enabled by default)\nclink\n- Bridge requests to external AI CLIs (Gemini planner, codereviewer, etc.)\nchat\n- Brainstorm ideas, get second opinions, validate approaches. With capable models (GPT-5 Pro, Gemini 2.5 Pro), generates complete code / implementation\nthinkdeep\n- Extended reasoning, edge case analysis, alternative perspectives\nplanner\n- Break down complex projects into structured, actionable plans\nconsensus\n- Get expert opinions from multiple AI models with stance steering\nCode Analysis & Quality\ndebug\n- Systematic investigation and root cause analysis\nprecommit\n- Validate changes before committing, prevent regressions\ncodereview\n- Professional reviews with severity levels and actionable feedback\nanalyze\n(disabled by default -\nenable\n)\n- Understand architecture, patterns, dependencies across entire codebases\nDevelopment Tools\n(Disabled by default -\nenable\n)\nrefactor\n- Intelligent code refactoring with decomposition focus\ntestgen\n- Comprehensive test generation with edge cases\nsecaudit\n- Security audits with OWASP Top 10 analysis\ndocgen\n- Generate documentation with complexity analysis\nUtilities\napilookup\n- Forces current-year API/SDK documentation lookups in a sub-process (saves tokens within the current context window), prevents outdated training data responses\nchallenge\n- Prevent \"You're absolutely right!\" responses with critical analysis\ntracer\n(disabled by default -\nenable\n)\n- Static analysis prompts for call-flow mapping\nüëâ Tool Configuration\nDefault Configuration\nTo optimize context window usage, only essential tools are enabled by default:\nEnabled by default:\nchat\n,\nthinkdeep\n,\nplanner\n,\nconsensus\n- Core collaboration tools\ncodereview\n,\nprecommit\n,\ndebug\n- Essential code quality tools\napilookup\n- Rapid API/SDK information lookup\nchallenge\n- Critical thinking utility\nDisabled by default:\nanalyze\n,\nrefactor\n,\ntestgen\n,\nsecaudit\n,\ndocgen\n,\ntracer\nEnabling Additional Tools\nTo enable additional tools, remove them from the\nDISABLED_TOOLS\nlist:\nOption 1: Edit your .env file\n#\nDefault configuration (from .env.example)\nDISABLED_TOOLS=analyze,refactor,testgen,secaudit,docgen,tracer\n#\nTo enable specific tools, remove them from the list\n#\nExample: Enable analyze tool\nDISABLED_TOOLS=refactor,testgen,secaudit,docgen,tracer\n#\nTo enable ALL tools\nDISABLED_TOOLS=\nOption 2: Configure in MCP settings\n// In ~/.claude/settings.json or .mcp.json\n{\n\"mcpServers\"\n: {\n\"zen\"\n: {\n\"env\"\n: {\n// Tool configuration\n\"DISABLED_TOOLS\"\n:\n\"\nrefactor,testgen,secaudit,docgen,tracer\n\"\n,\n\"DEFAULT_MODEL\"\n:\n\"\npro\n\"\n,\n\"DEFAULT_THINKING_MODE_THINKDEEP\"\n:\n\"\nhigh\n\"\n,\n// API configuration\n\"GEMINI_API_KEY\"\n:\n\"\nyour-gemini-key\n\"\n,\n\"OPENAI_API_KEY\"\n:\n\"\nyour-openai-key\n\"\n,\n\"OPENROUTER_API_KEY\"\n:\n\"\nyour-openrouter-key\n\"\n,\n// Logging and performance\n\"LOG_LEVEL\"\n:\n\"\nINFO\n\"\n,\n\"CONVERSATION_TIMEOUT_HOURS\"\n:\n\"\n6\n\"\n,\n\"MAX_CONVERSATION_TURNS\"\n:\n\"\n50\n\"\n}\n    }\n  }\n}\nOption 3: Enable all tools\n// Remove or empty the DISABLED_TOOLS to enable everything\n{\n\"mcpServers\"\n: {\n\"zen\"\n: {\n\"env\"\n: {\n\"DISABLED_TOOLS\"\n:\n\"\n\"\n}\n    }\n  }\n}\nNote:\nEssential tools (\nversion\n,\nlistmodels\n) cannot be disabled\nAfter changing tool configuration, restart your Claude session for changes to take effect\nEach tool adds to context window usage, so only enable what you need\nüì∫ Watch Tools In Action\nChat Tool\n- Collaborative decision making and multi-turn conversations\nPicking Redis vs Memcached:\nChat.Redis.or.Memcached_web.webm\nMulti-turn conversation with continuation:\nChat.With.Gemini_web.webm\nConsensus Tool\n- Multi-model debate and decision making\nMulti-model consensus debate:\nZen.Debate_web.webm\nPreCommit Tool\n- Comprehensive change validation\nPre-commit validation workflow:\nAPI Lookup Tool\n- Current vs outdated API documentation\nWithout Zen - outdated APIs:\nAPI_without_zen_web.mp4\nWith Zen - current APIs:\nAPI_with_zen.mp4\nChallenge Tool\n- Critical thinking vs reflexive agreement\nWithout Zen:\nWith Zen:\nKey Features\nAI Orchestration\nAuto model selection\n- Claude picks the right AI for each task\nMulti-model workflows\n- Chain different models in single conversations\nConversation continuity\n- Context preserved across tools and models\nContext revival\n- Continue conversations even after context resets\nModel Support\nMultiple providers\n- Gemini, OpenAI, Azure, X.AI, OpenRouter, DIAL, Ollama\nLatest models\n- GPT-5, Gemini 2.5 Pro, O3, Grok-4, local Llama\nThinking modes\n- Control reasoning depth vs cost\nVision support\n- Analyze images, diagrams, screenshots\nDeveloper Experience\nGuided workflows\n- Systematic investigation prevents rushed analysis\nSmart file handling\n- Auto-expand directories, manage token limits\nWeb search integration\n- Access current documentation and best practices\nLarge prompt support\n- Bypass MCP's 25K token limit\nExample Workflows\nMulti-model Code Review:\n\"Perform a codereview using gemini pro and o3, then use planner to create a fix strategy\"\n‚Üí Claude reviews code systematically ‚Üí Consults Gemini Pro ‚Üí Gets O3's perspective ‚Üí Creates unified action plan\nCollaborative Debugging:\n\"Debug this race condition with max thinking mode, then validate the fix with precommit\"\n‚Üí Deep investigation ‚Üí Expert analysis ‚Üí Solution implementation ‚Üí Pre-commit validation\nArchitecture Planning:\n\"Plan our microservices migration, get consensus from pro and o3 on the approach\"\n‚Üí Structured planning ‚Üí Multiple expert opinions ‚Üí Consensus building ‚Üí Implementation roadmap\nüëâ\nAdvanced Usage Guide\nfor complex workflows, model configuration, and power-user features\nQuick Links\nüìñ Documentation\nDocs Overview\n- High-level map of major guides\nGetting Started\n- Complete setup guide\nTools Reference\n- All tools with examples\nAdvanced Usage\n- Power user features\nConfiguration\n- Environment variables, restrictions\nAdding Providers\n- Provider-specific setup (OpenAI, Azure, custom gateways)\nModel Ranking Guide\n- How intelligence scores drive auto-mode suggestions\nüîß Setup & Support\nWSL Setup\n- Windows users\nTroubleshooting\n- Common issues\nContributing\n- Code standards, PR process\nLicense\nApache 2.0 License - see\nLICENSE\nfile for details.\nAcknowledgments\nBuilt with the power of\nMulti-Model AI\ncollaboration ü§ù\nA\nctual\nI\nntelligence by real Humans\nMCP (Model Context Protocol)\nCodex CLI\nClaude Code\nGemini\nOpenAI\nAzure OpenAI\nStar History",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 273",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 8,534"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/BeehiveInnovations/zen-mcp-server"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/thingsboard/thingsboard",
      "title": "thingsboard/thingsboard",
      "date": null,
      "executive_summary": [
        "Open-source IoT Platform - Device management, data collection, processing and visualization.",
        "---",
        "Open-source IoT platform for data collection, processing, visualization, and device management.\nüí°\nGet started\n‚Ä¢‚ÄÇüåê\nWebsite\n‚Ä¢‚ÄÇüìö\nDocumentation\n‚Ä¢‚ÄÇüìî\nBlog\n‚Ä¢\n‚ñ∂Ô∏è\nLive demo\n‚Ä¢‚ÄÇüîó\nLinkedIn\nüöÄ Installation options\nInstall ThingsBoard\nOn-premise\nTry\nThingsBoard Cloud\nor\nUse our Live demo\nüí° Getting started with ThingsBoard\nCheck out our\nGetting Started guide\nor\nwatch the video\nto learn the basics of ThingsBoard and create your first dashboard! You will learn to:\nConnect devices to ThingsBoard\nPush data from devices to ThingsBoard\nBuild real-time dashboards\nCreate a Customer and assign the dashboard with them.\nDefine thresholds and trigger alarms\nSet up notifications via email, SMS, mobile apps, or integrate with third-party services.\n‚ú® Features\nProvision and manage\ndevices and assets\nProvision, monitor and control your IoT entities in secure way using rich server-side APIs. Define relations between your devices, assets, customers or any other entities.\nRead more ‚ûú\nCollect and visualize\nyour data\nCollect and store telemetry data in scalable and fault-tolerant way. Visualize your data with built-in or custom widgets and flexible dashboards. Share dashboards with your customers.\nRead more ‚ûú\nSCADA Dashboards\nMonitor and control your industrial processes in real time with SCADA. Use SCADA symbols on dashboards to create and manage any workflow, offering full flexibility to design and oversee operations according to your requirements.\nRead more ‚ûú\nProcess and React\nDefine data processing rule chains. Transform and normalize your device data. Raise alarms on incoming telemetry events, attribute updates, device inactivity and user actions.\nRead more ‚ûú\n‚öôÔ∏è Powerful IoT Rule Engine\nThingsBoard allows you to create complex\nRule Chains\nto process data from your devices and match your application specific use cases.\nRead more about Rule Engine ‚ûú\nüì¶ Real-Time IoT Dashboards\nThingsBoard is a scalable, user-friendly, and device-agnostic IoT platform that speeds up time-to-market with powerful built-in solution templates. It enables data collection and analysis from any devices, saving resources on routine tasks and letting you focus on your solution‚Äôs unique aspects. See more our Use Cases\nhere\n.\nSmart energy\nSCADA swimming pool\nFleet tracking\nSmart farming\nSmart metering\nCheck more of our use cases ‚ûú\nü´∂ Support\nTo get support, please visit our\nGitHub issues page\nüìÑ Licenses\nThis project is released under\nApache 2.0 License",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 265",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 20,166"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/thingsboard/thingsboard"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/Zie619/n8n-workflows",
      "title": "Zie619/n8n-workflows",
      "date": null,
      "executive_summary": [
        "all of the workflows of n8n i could find (also from the site itself)",
        "---",
        "‚ö° N8N Workflow Collection & Documentation\nA professionally organized collection of\n2,057 n8n workflows\nwith a lightning-fast documentation system that provides instant search, analysis, and browsing capabilities.\n‚ö†Ô∏è\nIMPORTANT NOTICE (Aug 14, 2025):\nRepository history has been rewritten due to DMCA compliance. If you have a fork or local clone, please see\nIssue 85\nfor instructions on syncing your copy.\nSupport My Work\nIf you'd like to say thanks, consider buying me a coffee‚Äîyour support helps me keep improving this project!\nüöÄ\nNEW: Public Search Interface & High-Performance Documentation\nüåê\nBrowse workflows online\n- No installation required!\nOr run locally for development with 100x performance improvement:\nOption 1: Online Search (Recommended for Users)\nüîó Visit:\nzie619.github.io/n8n-workflows\n‚ö°\nInstant access\n- No setup required\nüîç\nSearch 2,057+ workflows\ndirectly in browser\nüì±\nMobile-friendly\ninterface\nüè∑Ô∏è\nCategory filtering\nacross 15 categories\nüì•\nDirect download\nof workflow JSON files\nOption 2: Local Development System\n#\nInstall dependencies\npip install -r requirements.txt\n#\nStart the fast API server\npython run.py\n#\nOpen in browser\nhttp://localhost:8000\nFeatures:\n‚ö°\nSub-100ms response times\nwith SQLite FTS5 search\nüîç\nInstant full-text search\nwith advanced filtering\nüì±\nResponsive design\n- works perfectly on mobile\nüåô\nDark/light themes\nwith system preference detection\nüìä\nLive statistics\n- 365 unique integrations, 29,445 total nodes\nüéØ\nSmart categorization\nby trigger type and complexity\nüéØ\nUse case categorization\nby service name mapped to categories\nüìÑ\nOn-demand JSON viewing\nand download\nüîó\nMermaid diagram generation\nfor workflow visualization\nüîÑ\nReal-time workflow naming\nwith intelligent formatting\nPerformance Comparison\nMetric\nOld System\nNew System\nImprovement\nFile Size\n71MB HTML\n<100KB\n700x smaller\nLoad Time\n10+ seconds\n<1 second\n10x faster\nSearch\nClient-side only\nFull-text with FTS5\nInstant\nMemory Usage\n~2GB RAM\n<50MB RAM\n40x less\nMobile Support\nPoor\nExcellent\nFully responsive\nüìÇ Repository Organization\nWorkflow Collection\n2,057 workflows\nwith meaningful, searchable names\n365 unique integrations\nacross popular platforms\n29,445 total nodes\nwith professional categorization\nQuality assurance\n- All workflows analyzed and categorized\nAdvanced Naming System ‚ú®\nOur intelligent naming system converts technical filenames into readable titles:\nBefore\n:\n2051_Telegram_Webhook_Automation_Webhook.json\nAfter\n:\nTelegram Webhook Automation\n100% meaningful names\nwith smart capitalization\nAutomatic integration detection\nfrom node analysis\nUse Case Category ‚ú®\nThe search interface includes a dropdown filter that lets you browse 2,057+ workflows by category.\nThe system includes an automated categorization feature that organizes workflows by service categories to make them easier to discover and filter.\nHow Categorization Works\nRun the categorization script\npython create_categories.py\nService Name Recognition\nThe script analyzes each workflow JSON filename to identify recognized service names (e.g., \"Twilio\", \"Slack\", \"Gmail\", etc.)\nCategory Mapping\nEach recognized service name is matched to its corresponding category using the definitions in\ncontext/def_categories.json\n. For example:\nTwilio ‚Üí Communication & Messaging\nGmail ‚Üí Communication & Messaging\nAirtable ‚Üí Data Processing & Analysis\nSalesforce ‚Üí CRM & Sales\nSearch Categories Generation\nThe script produces a\nsearch_categories.json\nfile that contains the categorized workflow data\nFilter Interface\nUsers can then filter workflows by category in the search interface, making it easier to find workflows for specific use cases\nAvailable Categories\nThe categorization system includes the following main categories:\nAI Agent Development\nBusiness Process Automation\nCloud Storage & File Management\nCommunication & Messaging\nCreative Content & Video Automation\nCreative Design Automation\nCRM & Sales\nData Processing & Analysis\nE-commerce & Retail\nFinancial & Accounting\nMarketing & Advertising Automation\nProject Management\nSocial Media Management\nTechnical Infrastructure & DevOps\nWeb Scraping & Data Extraction\nContribute Categories\nYou can help expand the categorization by adding more service-to-category mappings (e.g., Twilio ‚Üí Communication & Messaging) in context/defs_categories.json.\nMany workflow JSON files are conveniently named with the service name, often separated by underscores (_).\nüõ† Usage Instructions\nOption 1: Modern Fast System (Recommended)\n#\nClone repository\ngit clone\n<\nrepo-url\n>\ncd\nn8n-workflows\n#\nInstall Python dependencies\npip install -r requirements.txt\n#\nStart the documentation server\npython run.py\n#\nBrowse workflows at http://localhost:8000\n#\n- Instant search across 2,057 workflows\n#\n- Professional responsive interface\n#\n- Real-time workflow statistics\nOption 2: Development Mode\n#\nStart with auto-reload for development\npython run.py --dev\n#\nOr specify custom host/port\npython run.py --host 0.0.0.0 --port 3000\n#\nForce database reindexing\npython run.py --reindex\nImport Workflows into n8n\n#\nUse the Python importer (recommended)\npython import_workflows.py\n#\nOr manually import individual workflows:\n#\n1. Open your n8n Editor UI\n#\n2. Click menu (‚ò∞) ‚Üí Import workflow\n#\n3. Choose any .json file from the workflows/ folder\n#\n4. Update credentials/webhook URLs before running\nüìä Workflow Statistics\nCurrent Collection Stats\nTotal Workflows\n: 2,057 automation workflows\nActive Workflows\n: 215 (10.5% active rate)\nTotal Nodes\n: 29,528 (avg 14.4 nodes per workflow)\nUnique Integrations\n: 367 different services and APIs\nDatabase\n: SQLite with FTS5 full-text search\nTrigger Distribution\nComplex\n: 832 workflows (40.4%) - Multi-trigger systems\nWebhook\n: 521 workflows (25.3%) - API-triggered automations\nManual\n: 478 workflows (23.2%) - User-initiated workflows\nScheduled\n: 226 workflows (11.0%) - Time-based executions\nComplexity Analysis\nLow (‚â§5 nodes)\n: ~35% - Simple automations\nMedium (6-15 nodes)\n: ~45% - Standard workflows\nHigh (16+ nodes)\n: ~20% - Complex enterprise systems\nPopular Integrations\nTop services by usage frequency:\nCommunication\n: Telegram, Discord, Slack, WhatsApp\nCloud Storage\n: Google Drive, Google Sheets, Dropbox\nDatabases\n: PostgreSQL, MySQL, MongoDB, Airtable\nAI/ML\n: OpenAI, Anthropic, Hugging Face\nDevelopment\n: HTTP Request, Webhook, GraphQL\nüîç Advanced Search Features\nSmart Search Categories\nOur system automatically categorizes workflows into 15 main categories:\nAvailable Categories:\nAI Agent Development\n: OpenAI, Anthropic, Hugging Face, CalcsLive\nBusiness Process Automation\n: Workflow utilities, scheduling, data processing\nCloud Storage & File Management\n: Google Drive, Dropbox, OneDrive, Box\nCommunication & Messaging\n: Telegram, Discord, Slack, WhatsApp, Email\nCreative Content & Video Automation\n: YouTube, Vimeo, content creation\nCreative Design Automation\n: Canva, Figma, image processing\nCRM & Sales\n: Salesforce, HubSpot, Pipedrive, customer management\nData Processing & Analysis\n: Database operations, analytics, data transformation\nE-commerce & Retail\n: Shopify, Stripe, PayPal, online stores\nFinancial & Accounting\n: Financial tools, payment processing, accounting\nMarketing & Advertising Automation\n: Email marketing, campaigns, lead generation\nProject Management\n: Jira, Trello, Asana, task management\nSocial Media Management\n: LinkedIn, Twitter/X, Facebook, Instagram\nTechnical Infrastructure & DevOps\n: GitHub, deployment, monitoring\nWeb Scraping & Data Extraction\n: HTTP requests, webhooks, data collection\nAPI Usage Examples\n#\nSearch workflows by text\ncurl\n\"\nhttp://localhost:8000/api/workflows?q=telegram+automation\n\"\n#\nFilter by trigger type and complexity\ncurl\n\"\nhttp://localhost:8000/api/workflows?trigger=Webhook&complexity=high\n\"\n#\nFind all messaging workflows\ncurl\n\"\nhttp://localhost:8000/api/workflows/category/messaging\n\"\n#\nGet database statistics\ncurl\n\"\nhttp://localhost:8000/api/stats\n\"\n#\nBrowse available categories\ncurl\n\"\nhttp://localhost:8000/api/categories\n\"\nüèó Technical Architecture\nModern Stack\nSQLite Database\n- FTS5 full-text search with 365 indexed integrations\nFastAPI Backend\n- RESTful API with automatic OpenAPI documentation\nResponsive Frontend\n- Modern HTML5 with embedded CSS/JavaScript\nSmart Analysis\n- Automatic workflow categorization and naming\nKey Features\nChange Detection\n- MD5 hashing for efficient re-indexing\nBackground Processing\n- Non-blocking workflow analysis\nCompressed Responses\n- Gzip middleware for optimal speed\nError Handling\n- Graceful degradation and comprehensive logging\nMobile Optimization\n- Touch-friendly interface design\nDatabase Performance\n--\nOptimized schema for lightning-fast queries\nCREATE\nTABLE\nworkflows\n(\n    id\nINTEGER\nPRIMARY KEY\n,\n    filename\nTEXT\nUNIQUE,\n    name\nTEXT\n,\n    active\nBOOLEAN\n,\n    trigger_type\nTEXT\n,\n    complexity\nTEXT\n,\n    node_count\nINTEGER\n,\n    integrations\nTEXT\n,\n--\nJSON array of 365 unique services\ndescription\nTEXT\n,\n    file_hash\nTEXT\n,\n--\nMD5 for change detection\nanalyzed_at\nTIMESTAMP\n);\n--\nFull-text search with ranking\nCREATE VIRTUAL TABLE workflows_fts USING fts5(\n    filename, name, description, integrations, tags,\n    content\n=\n'\nworkflows\n'\n, content_rowid\n=\n'\nid\n'\n);\nüîß Setup & Requirements\nSystem Requirements\nPython 3.7+\n- For running the documentation system\nModern Browser\n- Chrome, Firefox, Safari, Edge\n50MB Storage\n- For SQLite database and indexes\nn8n Instance\n- For importing and running workflows\nInstallation\n#\nClone repository\ngit clone\n<\nrepo-url\n>\ncd\nn8n-workflows\n#\nInstall dependencies\npip install -r requirements.txt\n#\nStart documentation server\npython run.py\n#\nAccess at http://localhost:8000\nDevelopment Setup\n#\nCreate virtual environment\npython3 -m venv .venv\nsource\n.venv/bin/activate\n#\nLinux/Mac\n#\nor .venv\\Scripts\\activate  # Windows\n#\nInstall dependencies\npip install -r requirements.txt\n#\nRun with auto-reload for development\npython api_server.py --reload\n#\nForce database reindexing\npython workflow_db.py --index --force\nüìã Naming Convention\nIntelligent Formatting System\nOur system automatically converts technical filenames to user-friendly names:\n#\nAutomatic transformations:\n2051_Telegram_Webhook_Automation_Webhook.json ‚Üí\n\"\nTelegram Webhook Automation\n\"\n0250_HTTP_Discord_Import_Scheduled.json ‚Üí\n\"\nHTTP Discord Import Scheduled\n\"\n0966_OpenAI_Data_Processing_Manual.json ‚Üí\n\"\nOpenAI Data Processing Manual\n\"\nTechnical Format\n[ID]_[Service1]_[Service2]_[Purpose]_[Trigger].json\nSmart Capitalization Rules\nHTTP\n‚Üí HTTP (not Http)\nAPI\n‚Üí API (not Api)\nwebhook\n‚Üí Webhook\nautomation\n‚Üí Automation\nscheduled\n‚Üí Scheduled\nüöÄ API Documentation\nCore Endpoints\nGET /\n- Main workflow browser interface\nGET /api/stats\n- Database statistics and metrics\nGET /api/workflows\n- Search with filters and pagination\nGET /api/workflows/{filename}\n- Detailed workflow information\nGET /api/workflows/{filename}/download\n- Download workflow JSON\nGET /api/workflows/{filename}/diagram\n- Generate Mermaid diagram\nAdvanced Search\nGET /api/workflows/category/{category}\n- Search by service category\nGET /api/categories\n- List all available categories\nGET /api/integrations\n- Get integration statistics\nPOST /api/reindex\n- Trigger background reindexing\nResponse Examples\n// GET /api/stats\n{\n\"total\"\n:\n2053\n,\n\"active\"\n:\n215\n,\n\"inactive\"\n:\n1838\n,\n\"triggers\"\n: {\n\"Complex\"\n:\n831\n,\n\"Webhook\"\n:\n519\n,\n\"Manual\"\n:\n477\n,\n\"Scheduled\"\n:\n226\n},\n\"total_nodes\"\n:\n29445\n,\n\"unique_integrations\"\n:\n365\n}\nü§ù Contributing\nüéâ This project solves\nIssue #84\n- providing online access to workflows without requiring local setup!\nAdding New Workflows\nExport workflow\nas JSON from n8n\nName descriptively\nfollowing the established pattern:\n[ID]_[Service]_[Purpose]_[Trigger].json\nAdd to workflows/\ndirectory (create service folder if needed)\nRemove sensitive data\n(credentials, personal URLs)\nAdd tags\nfor better searchability (calculation, automation, etc.)\nGitHub Actions automatically\nupdates the public search interface\nQuality Standards\n‚úÖ Workflow must be functional and tested\n‚úÖ Remove all credentials and sensitive data\n‚úÖ Follow naming convention for consistency\n‚úÖ Verify compatibility with recent n8n versions\n‚úÖ Include meaningful description or comments\n‚úÖ Add relevant tags for search optimization\nCustom Node Workflows\n‚úÖ Include npm package links in descriptions\n‚úÖ Document custom node requirements\n‚úÖ Add installation instructions\n‚úÖ Use descriptive tags (like CalcsLive example)\nReindexing (for local development)\n#\nForce database reindexing after adding workflows\npython run.py --reindex\n#\nOr update search index only\npython scripts/generate_search_index.py\n‚ö†Ô∏è\nImportant Notes\nSecurity & Privacy\nReview before use\n- All workflows shared as-is for educational purposes\nUpdate credentials\n- Replace API keys, tokens, and webhooks\nTest safely\n- Verify in development environment first\nCheck permissions\n- Ensure proper access rights for integrations\nCompatibility\nn8n Version\n- Compatible with n8n 1.0+ (most workflows)\nCommunity Nodes\n- Some workflows may require additional node installations\nAPI Changes\n- External services may have updated their APIs since creation\nDependencies\n- Verify required integrations before importing\nüìö Resources & References\nWorkflow Sources\nThis comprehensive collection includes workflows from:\nOfficial n8n.io\n- Documentation and community examples\nGitHub repositories\n- Open source community contributions\nBlog posts & tutorials\n- Real-world automation patterns\nUser submissions\n- Tested and verified workflows\nEnterprise use cases\n- Business process automations\nLearn More\nn8n Documentation\n- Official documentation\nn8n Community\n- Community forum and support\nWorkflow Templates\n- Official template library\nIntegration Docs\n- Service-specific guides\nüèÜ Project Achievements\nRepository Transformation\n2,053 workflows\nprofessionally organized and named\n365 unique integrations\nautomatically detected and categorized\n100% meaningful names\n(improved from basic filename patterns)\nZero data loss\nduring intelligent renaming process\nAdvanced search\nwith 15 service categories\nPerformance Revolution\nSub-100ms search\nwith SQLite FTS5 full-text indexing\nInstant filtering\nacross 29,445 workflow nodes\nMobile-optimized\nresponsive design for all devices\nReal-time statistics\nwith live database queries\nProfessional interface\nwith modern UX principles\nSystem Reliability\nRobust error handling\nwith graceful degradation\nChange detection\nfor efficient database updates\nBackground processing\nfor non-blocking operations\nComprehensive logging\nfor debugging and monitoring\nProduction-ready\nwith proper middleware and security\nThis repository represents the most comprehensive and well-organized collection of n8n workflows available, featuring cutting-edge search technology and professional documentation that makes workflow discovery and usage a delightful experience.\nüéØ Perfect for\n: Developers, automation engineers, business analysts, and anyone looking to streamline their workflows with proven n8n automations.\n‰∏≠Êñá",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 240",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 35,687"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/Zie619/n8n-workflows"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/MODSetter/SurfSense",
      "title": "MODSetter/SurfSense",
      "date": null,
      "executive_summary": [
        "Open Source Alternative to NotebookLM / Perplexity, connected to external sources such as Search Engines, Slack, Linear, Jira, ClickUp, Confluence, Notion, YouTube, GitHub, Discord and more. Join our discord: https://discord.gg/ejRNvftDp9",
        "---",
        "SurfSense\nWhile tools like NotebookLM and Perplexity are impressive and highly effective for conducting research on any topic/query, SurfSense elevates this capability by integrating with your personal knowledge base. It is a highly customizable AI research agent, connected to external sources such as Search Engines (Tavily, LinkUp), Slack, Linear, Jira, ClickUp, Confluence, Gmail, Notion, YouTube, GitHub, Discord, Airtable, Google Calendar, Luma and more to come.\nVideo\ntemp_demo_v7.mp4\nPodcast Sample\nelon_vs_trump_podcast.mp4\nKey Features\nüí°\nIdea\n:\nHave your own highly customizable private NotebookLM and Perplexity integrated with external sources.\nüìÅ\nMultiple File Format Uploading Support\nSave content from your own personal files\n(Documents, images, videos and supports\n50+ file extensions\n)\nto your own personal knowledge base .\nüîç\nPowerful Search\nQuickly research or find anything in your saved content .\nüí¨\nChat with your Saved Content\nInteract in Natural Language and get cited answers.\nüìÑ\nCited Answers\nGet Cited answers just like Perplexity.\nüîî\nPrivacy & Local LLM Support\nWorks Flawlessly with Ollama local LLMs.\nüè†\nSelf Hostable\nOpen source and easy to deploy locally.\nüéôÔ∏è Podcasts\nBlazingly fast podcast generation agent. (Creates a 3-minute podcast in under 20 seconds.)\nConvert your chat conversations into engaging audio content\nSupport for local TTS providers (Kokoro TTS)\nSupport for multiple TTS providers (OpenAI, Azure, Google Vertex AI)\nüìä\nAdvanced RAG Techniques\nSupports 100+ LLM's\nSupports 6000+ Embedding Models.\nSupports all major Rerankers (Pinecode, Cohere, Flashrank etc)\nUses Hierarchical Indices (2 tiered RAG setup).\nUtilizes Hybrid Search (Semantic + Full Text Search combined with Reciprocal Rank Fusion).\nRAG as a Service API Backend.\n‚ÑπÔ∏è\nExternal Sources\nSearch Engines (Tavily, LinkUp)\nSlack\nLinear\nJira\nClickUp\nConfluence\nNotion\nGmail\nYoutube Videos\nGitHub\nDiscord\nAirtable\nGoogle Calendar\nLuma\nand more to come.....\nüìÑ\nSupported File Extensions\nNote\n: File format support depends on your ETL service configuration. LlamaCloud supports 50+ formats, Unstructured supports 34+ core formats, and Docling (core formats, local processing, privacy-focused, no API key).\nDocuments & Text\nLlamaCloud\n:\n.pdf\n,\n.doc\n,\n.docx\n,\n.docm\n,\n.dot\n,\n.dotm\n,\n.rtf\n,\n.txt\n,\n.xml\n,\n.epub\n,\n.odt\n,\n.wpd\n,\n.pages\n,\n.key\n,\n.numbers\n,\n.602\n,\n.abw\n,\n.cgm\n,\n.cwk\n,\n.hwp\n,\n.lwp\n,\n.mw\n,\n.mcw\n,\n.pbd\n,\n.sda\n,\n.sdd\n,\n.sdp\n,\n.sdw\n,\n.sgl\n,\n.sti\n,\n.sxi\n,\n.sxw\n,\n.stw\n,\n.sxg\n,\n.uof\n,\n.uop\n,\n.uot\n,\n.vor\n,\n.wps\n,\n.zabw\nUnstructured\n:\n.doc\n,\n.docx\n,\n.odt\n,\n.rtf\n,\n.pdf\n,\n.xml\n,\n.txt\n,\n.md\n,\n.markdown\n,\n.rst\n,\n.html\n,\n.org\n,\n.epub\nDocling\n:\n.pdf\n,\n.docx\n,\n.html\n,\n.htm\n,\n.xhtml\n,\n.adoc\n,\n.asciidoc\nPresentations\nLlamaCloud\n:\n.ppt\n,\n.pptx\n,\n.pptm\n,\n.pot\n,\n.potm\n,\n.potx\n,\n.odp\n,\n.key\nUnstructured\n:\n.ppt\n,\n.pptx\nDocling\n:\n.pptx\nSpreadsheets & Data\nLlamaCloud\n:\n.xlsx\n,\n.xls\n,\n.xlsm\n,\n.xlsb\n,\n.xlw\n,\n.csv\n,\n.tsv\n,\n.ods\n,\n.fods\n,\n.numbers\n,\n.dbf\n,\n.123\n,\n.dif\n,\n.sylk\n,\n.slk\n,\n.prn\n,\n.et\n,\n.uos1\n,\n.uos2\n,\n.wk1\n,\n.wk2\n,\n.wk3\n,\n.wk4\n,\n.wks\n,\n.wq1\n,\n.wq2\n,\n.wb1\n,\n.wb2\n,\n.wb3\n,\n.qpw\n,\n.xlr\n,\n.eth\nUnstructured\n:\n.xls\n,\n.xlsx\n,\n.csv\n,\n.tsv\nDocling\n:\n.xlsx\n,\n.csv\nImages\nLlamaCloud\n:\n.jpg\n,\n.jpeg\n,\n.png\n,\n.gif\n,\n.bmp\n,\n.svg\n,\n.tiff\n,\n.webp\n,\n.html\n,\n.htm\n,\n.web\nUnstructured\n:\n.jpg\n,\n.jpeg\n,\n.png\n,\n.bmp\n,\n.tiff\n,\n.heic\nDocling\n:\n.jpg\n,\n.jpeg\n,\n.png\n,\n.bmp\n,\n.tiff\n,\n.tif\n,\n.webp\nAudio & Video\n(Always Supported)\n.mp3\n,\n.mpga\n,\n.m4a\n,\n.wav\n,\n.mp4\n,\n.mpeg\n,\n.webm\nEmail & Communication\nUnstructured\n:\n.eml\n,\n.msg\n,\n.p7s\nüîñ Cross Browser Extension\nThe SurfSense extension can be used to save any webpage you like.\nIts main usecase is to save any webpages protected beyond authentication.\nFEATURE REQUESTS AND FUTURE\nSurfSense is actively being developed.\nWhile it's not yet production-ready, you can help us speed up the process.\nJoin the\nSurfSense Discord\nand help shape the future of SurfSense!\nüöÄ Roadmap\nStay up to date with our development progress and upcoming features!\nCheck out our public roadmap and contribute your ideas or feedback:\nView the Roadmap:\nSurfSense Roadmap on GitHub Projects\nHow to get started?\nInstallation Options\nSurfSense provides two installation methods:\nDocker Installation\n- The easiest way to get SurfSense up and running with all dependencies containerized.\nIncludes pgAdmin for database management through a web UI\nSupports environment variable customization via\n.env\nfile\nFlexible deployment options (full stack or core services only)\nNo need to manually edit configuration files between environments\nSee\nDocker Setup Guide\nfor detailed instructions\nFor deployment scenarios and options, see\nDeployment Guide\nManual Installation (Recommended)\n- For users who prefer more control over their setup or need to customize their deployment.\nBoth installation guides include detailed OS-specific instructions for Windows, macOS, and Linux.\nBefore installation, make sure to complete the\nprerequisite setup steps\nincluding:\nPGVector setup\nFile Processing ETL Service\n(choose one):\nUnstructured.io API key (supports 34+ formats)\nLlamaIndex API key (enhanced parsing, supports 50+ formats)\nDocling (local processing, no API key required, supports PDF, Office docs, images, HTML, CSV)\nOther required API keys\nScreenshots\nResearch Agent\nSearch Spaces\nManage Documents\nPodcast Agent\nAgent Chat\nBrowser Extension\nTech Stack\nBackEnd\nFastAPI\n: Modern, fast web framework for building APIs with Python\nPostgreSQL with pgvector\n: Database with vector search capabilities for similarity searches\nSQLAlchemy\n: SQL toolkit and ORM (Object-Relational Mapping) for database interactions\nAlembic\n: A database migrations tool for SQLAlchemy.\nFastAPI Users\n: Authentication and user management with JWT and OAuth support\nLangGraph\n: Framework for developing AI-agents.\nLangChain\n: Framework for developing AI-powered applications.\nLLM Integration\n: Integration with LLM models through LiteLLM\nRerankers\n: Advanced result ranking for improved search relevance\nHybrid Search\n: Combines vector similarity and full-text search for optimal results using Reciprocal Rank Fusion (RRF)\nVector Embeddings\n: Document and text embeddings for semantic search\npgvector\n: PostgreSQL extension for efficient vector similarity operations\nChonkie\n: Advanced document chunking and embedding library\nUses\nAutoEmbeddings\nfor flexible embedding model selection\nLateChunker\nfor optimized document chunking based on embedding model's max sequence length\nFrontEnd\nNext.js 15.2.3\n: React framework featuring App Router, server components, automatic code-splitting, and optimized rendering.\nReact 19.0.0\n: JavaScript library for building user interfaces.\nTypeScript\n: Static type-checking for JavaScript, enhancing code quality and developer experience.\nVercel AI SDK Kit UI Stream Protocol\n: To create scalable chat UI.\nTailwind CSS 4.x\n: Utility-first CSS framework for building custom UI designs.\nShadcn\n: Headless components library.\nLucide React\n: Icon set implemented as React components.\nFramer Motion\n: Animation library for React.\nSonner\n: Toast notification library.\nGeist\n: Font family from Vercel.\nReact Hook Form\n: Form state management and validation.\nZod\n: TypeScript-first schema validation with static type inference.\n@hookform/resolvers\n: Resolvers for using validation libraries with React Hook Form.\n@tanstack/react-table\n: Headless UI for building powerful tables & datagrids.\nDevOps\nDocker\n: Container platform for consistent deployment across environments\nDocker Compose\n: Tool for defining and running multi-container Docker applications\npgAdmin\n: Web-based PostgreSQL administration tool included in Docker setup\nExtension\nManifest v3 on Plasmo\nFuture Work\nAdd More Connectors.\nPatch minor bugs.\nDocument Podcasts\nContribute\nContributions are very welcome! A contribution can be as small as a ‚≠ê or even finding and creating issues.\nFine-tuning the Backend is always desired.\nFor detailed contribution guidelines, please see our\nCONTRIBUTING.md\nfile.\nStar History",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 236",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 8,894"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/MODSetter/SurfSense"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/timelinize/timelinize",
      "title": "timelinize/timelinize",
      "date": null,
      "executive_summary": [
        "Store your data from all your accounts and devices in a single cohesive timeline on your own computer",
        "---",
        "Organize your photos & videos, chats & messages, location history, social media content, contacts, and more into a single cohesive timeline on your own computer where you can keep them alive forever.\nTimelinize lets you import your data from practically anywhere: your computer, phone, online accounts, GPS-enabled radios, various apps and programs, contact lists, cameras, and more.\nJoin our Discord\nto discuss!\nNote\nI am looking for a better name for this project. If you have an idea for a good name that is short, relevant, unique, and available,\nI'd love to hear it!\nScreenshots\nThese were captured using a dev repository of mine filled with a subset of my real data, so I've run Timelinize in obfuscation mode: images and videos are blurred (except profile pictures---need to fix that); names, identifiers, and locations around sensitive areas are all randomized, and text has been replaced with random words so that the string is about the same length.\n(I hope to make a video tour soon.)\nPlease remember this is an early alpha preview, and the software is very much evolving and improving. And you can help!\nWIP dashboard.\nVery\nWIP. The bubble chart is particularly interesting as it shows you what kinds of data are most common at which times of day throughout the years.\nThe classic timeline view is a combination of all data grouped by types and time segments for reconstructing a day or other custom time period.\nViewing an item shows all the information about it, regardless of type: text, photo, live photo, video, location, etc.\nI had to make a custom file picker since browser APIs are too limiting. This is how you'll import most of your data into your timeline, but this flow is being revised soon.\nThe large map view is capable of 3D exploration, showing your memories right where they happened with a color-coded path that represents time.\nBecause Timelinize is entity-aware and supports multiple data sources, it can show data on a map even if it doesn't have geolocation information. That's what the gray dots or pins represent. In this example, a text message was received while at church, even though it doesn't have any geolocation info associated with it directly.\nTimelinize treats entities (people, pets/animals, organizations, etc.) as first-class data points which you can filter and organize.\nTimelinize will automatically recognize the same entity across data sources with enough information, but if it isn't possible automatically, you can manually merge entities with a click.\nConversations are aggregated across data sources that have messaging capabilities. They become emergent from the database by querying relationships between items and entities.\nIn this conversation view, you can see messages exchanged with this person across both Facebook and SMS/text message are displayed together. Reactions are also supported.\nA gallery displays photos and videos, but not just those in your photo library: it includes pictures and memes sent via messages, photos and videos uploaded to social media, and any other photos/videos in your data. You can always filter to drill down.\nHow it works\nObtain your data.\nThis usually involves exporting your data from apps, online accounts, or devices. For example, requesting an archive from Google Takeout. (Apple iCloud, Facebook, Twitter/X, Strava, Instagram, etc. all offer similar functionality for GDPR compliance.) Do this early/soon, because some services take days to provide your data.\nImport your data using Timelinize. You don't need to extract or decompress .tar or .zip archives; Timelinize will attempt to recognize your data in its original format and folder structure. All the data you import is indexed in a SQLite database and stored on disk organized by date -- no obfuscation or proprietary formats; you can simply browse your files if you wish.\nExplore and organize! Timelinize has a UI that portrays data using various projections and filters. It can recall moments from your past and help you view your life more comprehensively. (It's a great living family history tool.)\nRepeat steps 1-3 as often as desired. Timelinize will skip any existing data that is the same and only import new content. You could do this every few weeks or months for busy accounts that are most important to you.\nCaution\nTimelinize is in active development and is still considered unstable. The schema is still changing, necessitating starting over from a clean slate when updating. Always keep your original source data. Expect to delete and recreate your timelines as you upgrade during this alpha development period.\nDownload and run\nDownload the\nlatest release\nfor your platform.\nSee the website for\ninstallation instructions\n.\nDevelop\nSee our\nproject wiki\nfor instructions on\ncompiling from source\n.\nCommand line interface\nTimelinize has a symmetric HTTP API and CLI. When an HTTP API endpoint is created in the code, it automatically adds to the command line as well.\nRun\ntimelinize help\n(or\ngo run main.go help\nif you're running from source) to view the list of commands, which are also HTTP endpoints. JSON or form inputs are converted to command line args/flags that represent the JSON schema or form fields.\nSetup Development Environment\nDev Container setup is provided for easy development using GitHub Codespaces or Visual Studio Code with the DevContainers extension.\nGetting started with VSCode\nMake sure you have the following installed:\nDocker\nDevContainers for VSCode\nOpen this project in VSCode\nGo to the\nRemote Explorer\non Activity Bar\nClick on\nNew Dev Container (+)\nClick on\nOpen Current Folder in Container\nThis sets up a docker container with all the dependencies required for building this project. You can get started with contributing quickly.\nMotivation and vision\n(For roadmap, see\nissues tagged\nlong-term üî≠\n.)\nThe motivation for this project is two-fold. Both press upon me with a sense of urgency, which is why I dedicated some nights and weekends to work on this.\nConnecting with my family -- both living and deceased -- is important to me and my close relatives. But I wish we had more insights into the lives of those who came before us. What was important to them? Where did they live / travel / spend their time? What lessons did they learn? How did global and local events -- or heck, even the weather -- affect them? What hardships did they endure? What would they have wanted to remember? What would it be like to talk to them? A lot of this could not be known unless they wrote it all down. But these days, we have that data for ourselves. What better time than right now to start collecting personal histories from all available sources and develop a rich timeline of our life for our family, or even just for our own reference and nostalgia.\nOur lives are better-documented than any before us, but the record of our life is more ephemeral than any before us, too. We lose control of our data by relying on centralized, proprietary apps and cloud services which are useful today, and gone tomorrow. I wrote Timelinize because now is the time to liberate my data from corporations who don't own it, yet who have the only copy of it. This reality has made me feel uneasy for years, and it's not going away soon. Timelinize makes it bearable.\nImagine being able to pull up a single screen with your data from any and all of your online accounts and services -- while offline. And there you see so many aspects of your life at a glance: your photos and videos, social media posts, locations on a map and how you got there, emails and letters, documents, health and physical activities, mental and emotional wellness, and maybe even music you listened to, for any given day. You can \"zoom out\" and get the big picture. Machine learning algorithms could suggest major clusters based on your content to summarize your days, months, or years, and from that, even recommend printing physical memorabilia. It's like a highly-detailed, automated journal, fully in your control, which you can add to in the app: augment it with your own thoughts like a regular journal.\nThen cross-reference your own timeline with a global public timeline: see how locations you went to changed over time, or what major news events may have affected you, or what the political/social climate -- or the literal climate -- was like at the time. For example, you may wonder, \"Why did the family stay inside so much of the summer one year?\" You could then see, \"Oh, because it was 110 F (43 C) degrees for two months straight.\"\nOr translate the projection sideways, and instead of looking at time cross-sections, look at cross-sections of your timeline by media type: photos, posts, location, sentiment. Look at plots, charts, graphs, of your physical activity.\nOr view projections by space instead of time: view interrelations between items on a map, even items that don't have location data, because the database is entity-aware. So if a person receives a text message and the same person has location information at about the same time from a photo or GPS device, then the text message can appear on a map too, reminding you where you first got the text with the news about your nephew's birth.\nAnd all of this runs on your own computer: no one else has access to it, no one else owns it, but you.\nAnd if everyone had their own timeline, in theory they could be merged into a global supertimeline to become a thorough record of the human race, all without the need for centralizing our data on cloud services that are controlled by greedy corporations.\nHistory\nI've been working on this project since about 2013, even before I conceptualized\nCaddy\n. My initial vision was to create an automated backup of my Picasa albums that I could store on my own hard drive. This project was called Photobak. Picasa eventually became Google Photos, and about the same time I realized I wanted to backup my photos posted to Facebook, Instagram, and Twitter, too. And while I was at it, why not include my Google Location History to augment the location data from the photos. The vision continued to expand as I realized that my family could use this too, so the schema was upgraded to support multiple people/entities as well. This could allow us to merge databases, or timelines, as family members pass, or as they share parts of their timeline around with each other. Timelinize is the mature evolution of the original project that is now designed to be a comprehensive, highly detailed archive of one's life through digital (or\ndigitized\n) content. An authoritative, unified record that is easy to preserve and organize.\nLicense\nThis project is licensed with AGPL. I chose this license because I do not want others to make proprietary or commercial software using this package. The point of this project is liberation of and control over one's own, personal data, and I want to ensure that this project won't be used in anything that would perpetuate the walled garden dilemma we already face today. Even if the future of this project ever has proprietary source code, I can ensure it will stay aligned with my values and the project's original goals.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 225",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 2,204"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/timelinize/timelinize"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/openai/codex",
      "title": "openai/codex",
      "date": null,
      "executive_summary": [
        "Lightweight coding agent that runs in your terminal",
        "---",
        "npm i -g @openai/codex\nor\nbrew install codex\nCodex CLI\nis a coding agent from OpenAI that runs locally on your computer.\nIf you want Codex in your code editor (VS Code, Cursor, Windsurf),\ninstall in your IDE\nIf you are looking for the\ncloud-based agent\nfrom OpenAI,\nCodex Web\n, go to\nchatgpt.com/codex\nQuickstart\nInstalling and running Codex CLI\nInstall globally with your preferred package manager. If you use npm:\nnpm install -g @openai/codex\nAlternatively, if you use Homebrew:\nbrew install codex\nThen simply run\ncodex\nto get started:\ncodex\nYou can also go to the\nlatest GitHub Release\nand download the appropriate binary for your platform.\nEach GitHub Release contains many executables, but in practice, you likely want one of these:\nmacOS\nApple Silicon/arm64:\ncodex-aarch64-apple-darwin.tar.gz\nx86_64 (older Mac hardware):\ncodex-x86_64-apple-darwin.tar.gz\nLinux\nx86_64:\ncodex-x86_64-unknown-linux-musl.tar.gz\narm64:\ncodex-aarch64-unknown-linux-musl.tar.gz\nEach archive contains a single entry with the platform baked into the name (e.g.,\ncodex-x86_64-unknown-linux-musl\n), so you likely want to rename it to\ncodex\nafter extracting it.\nUsing Codex with your ChatGPT plan\nRun\ncodex\nand select\nSign in with ChatGPT\n. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan.\nLearn more about what's included in your ChatGPT plan\n.\nYou can also use Codex with an API key, but this requires\nadditional setup\n. If you previously used an API key for usage-based billing, see the\nmigration steps\n. If you're having trouble with login, please comment on\nthis issue\n.\nModel Context Protocol (MCP)\nCodex can access MCP servers. To configure them, refer to the\nconfig docs\n.\nConfiguration\nCodex CLI supports a rich set of configuration options, with preferences stored in\n~/.codex/config.toml\n. For full configuration options, see\nConfiguration\n.\nDocs & FAQ\nGetting started\nCLI usage\nRunning with a prompt as input\nExample prompts\nMemory with AGENTS.md\nConfiguration\nSandbox & approvals\nAuthentication\nAuth methods\nLogin on a \"Headless\" machine\nAutomating Codex\nGitHub Action\nTypeScript SDK\nNon-interactive mode (\ncodex exec\n)\nAdvanced\nTracing / verbose logging\nModel Context Protocol (MCP)\nZero data retention (ZDR)\nContributing\nInstall & build\nSystem Requirements\nDotSlash\nBuild from source\nFAQ\nOpen source fund\nLicense\nThis repository is licensed under the\nApache-2.0 License\n.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 219",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 46,727"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/openai/codex"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/google/computer-use-preview",
      "title": "google/computer-use-preview",
      "date": null,
      "executive_summary": [
        "---",
        "Computer Use Preview\nQuick Start\nThis section will guide you through setting up and running the Computer Use Preview model. Follow these steps to get started.\n1. Installation\nClone the Repository\ngit clone https://github.com/google/computer-use-preview.git\ncd\ncomputer-use-preview\nSet up Python Virtual Environment and Install Dependencies\npython3 -m venv .venv\nsource\n.venv/bin/activate\npip install -r requirements.txt\nInstall Playwright and Browser Dependencies\n#\nInstall system dependencies required by Playwright for Chrome\nplaywright install-deps chrome\n#\nInstall the Chrome browser for Playwright\nplaywright install chrome\n2. Configuration\nYou can get started using either the Gemini Developer API or Vertex AI.\nA. If using the Gemini Developer API:\nYou need a Gemini API key to use the agent:\nexport\nGEMINI_API_KEY=\n\"\nYOUR_GEMINI_API_KEY\n\"\nOr to add this to your virtual environment:\necho\n'\nexport GEMINI_API_KEY=\"YOUR_GEMINI_API_KEY\"\n'\n>>\n.venv/bin/activate\n#\nAfter editing, you'll need to deactivate and reactivate your virtual\n#\nenvironment if it's already active:\ndeactivate\nsource\n.venv/bin/activate\nReplace\nYOUR_GEMINI_API_KEY\nwith your actual key.\nB. If using the Vertex AI Client:\nYou need to explicitly use Vertex AI, then provide project and location to use the agent:\nexport\nUSE_VERTEXAI=true\nexport\nVERTEXAI_PROJECT=\n\"\nYOUR_PROJECT_ID\n\"\nexport\nVERTEXAI_LOCATION=\n\"\nYOUR_LOCATION\n\"\nOr to add this to your virtual environment:\necho\n'\nexport USE_VERTEXAI=true\n'\n>>\n.venv/bin/activate\necho\n'\nexport VERTEXAI_PROJECT=\"your-project-id\"\n'\n>>\n.venv/bin/activate\necho\n'\nexport VERTEXAI_LOCATION=\"your-location\"\n'\n>>\n.venv/bin/activate\n#\nAfter editing, you'll need to deactivate and reactivate your virtual\n#\nenvironment if it's already active:\ndeactivate\nsource\n.venv/bin/activate\nReplace\nYOUR_PROJECT_ID\nand\nYOUR_LOCATION\nwith your actual project and location.\n3. Running the Tool\nThe primary way to use the tool is via the\nmain.py\nscript.\nGeneral Command Structure:\npython main.py --query\n\"\nGo to Google and type 'Hello World' into the search bar\n\"\nAvailable Environments:\nYou can specify a particular environment with the\n--env <environment>\nflag.  Available options:\nplaywright\n: Runs the browser locally using Playwright.\nbrowserbase\n: Connects to a Browserbase instance.\nLocal Playwright\nRuns the agent using a Chrome browser instance controlled locally by Playwright.\npython main.py --query=\n\"\nGo to Google and type 'Hello World' into the search bar\n\"\n--env=\n\"\nplaywright\n\"\nYou can also specify an initial URL for the Playwright environment:\npython main.py --query=\n\"\nGo to Google and type 'Hello World' into the search bar\n\"\n--env=\n\"\nplaywright\n\"\n--initial_url=\n\"\nhttps://www.google.com/search?q=latest+AI+news\n\"\nBrowserbase\nRuns the agent using Browserbase as the browser backend. Ensure the proper Browserbase environment variables are set:\nBROWSERBASE_API_KEY\nand\nBROWSERBASE_PROJECT_ID\n.\npython main.py --query=\n\"\nGo to Google and type 'Hello World' into the search bar\n\"\n--env=\n\"\nbrowserbase\n\"\nAgent CLI\nThe\nmain.py\nscript is the command-line interface (CLI) for running the browser agent.\nCommand-Line Arguments\nArgument\nDescription\nRequired\nDefault\nSupported Environment(s)\n--query\nThe natural language query for the browser agent to execute.\nYes\nN/A\nAll\n--env\nThe computer use environment to use. Must be one of the following:\nplaywright\n, or\nbrowserbase\nNo\nN/A\nAll\n--initial_url\nThe initial URL to load when the browser starts.\nNo\nhttps://www.google.com\nAll\n--highlight_mouse\nIf specified, the agent will attempt to highlight the mouse cursor's position in the screenshots. This is useful for visual debugging.\nNo\nFalse (not highlighted)\nplaywright\nEnvironment Variables\nVariable\nDescription\nRequired\nGEMINI_API_KEY\nYour API key for the Gemini model.\nYes\nBROWSERBASE_API_KEY\nYour API key for Browserbase.\nYes (when using the browserbase environment)\nBROWSERBASE_PROJECT_ID\nYour Project ID for Browserbase.\nYes (when using the browserbase environment)",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 203",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 688"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/google/computer-use-preview"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/LukeGus/Termix",
      "title": "LukeGus/Termix",
      "date": null,
      "executive_summary": [
        "Termix is a web-based server management platform with SSH terminal, tunneling, and file editing capabilities.",
        "---",
        "Repo Stats\nEnglish |\n‰∏≠Êñá\nAchieved on September 1st, 2025\nTop Technologies\nIf you would like, you can support the project here!\nOverview\nTermix is an open-source, forever-free, self-hosted all-in-one server management platform. It provides a web-based\nsolution for managing your servers and infrastructure through a single, intuitive interface. Termix offers SSH terminal\naccess, SSH tunneling capabilities, and remote file management, with many more tools to come.\nFeatures\nSSH Terminal Access\n- Full-featured terminal with split-screen support (up to 4 panels) and tab system\nSSH Tunnel Management\n- Create and manage SSH tunnels with automatic reconnection and health monitoring\nRemote File Manager\n- Manage files directly on remote servers with support for viewing and editing code, images, audio, and video. Upload, download, rename, delete, and move files seamlessly.\nSSH Host Manager\n- Save, organize, and manage your SSH connections with tags and folders and easily save reusable login info while being able to automate the deploying of SSH keys\nServer Stats\n- View CPU, memory, and HDD usage on any SSH server\nUser Authentication\n- Secure user management with admin controls and OIDC and 2FA (TOTP) support\nDatabase Encryption\n- SQLite database files encrypted at rest with automatic encryption/decryption\nData Export/Import\n- Export and import SSH hosts, credentials, and file manager data with incremental sync\nAutomatic SSL Setup\n- Built-in SSL certificate generation and management with HTTPS redirects\nModern UI\n- Clean desktop/mobile-friendly interface built with React, Tailwind CSS, and Shadcn\nLanguages\n- Built-in support for English, Chinese, and German\nPlatform Support\n- Available as a web app, desktop application (Windows & Linux), and dedicated mobile app for iOS and Android. macOS and iPadOS support is planned.\nPlanned Features\nSee\nProjects\nfor all planned features. If you are looking to contribute, see\nContributing\n.\nInstallation\nSupported Devices:\nWebsite (any modern browser like Google, Safari, and Firefox)\nWindows (app)\nLinux (app)\niOS (app)\nAndroid (app)\niPadOS and macOS are in progress\nVisit the Termix\nDocs\nfor more information on how to install Termix on all platforms. Otherwise, view\na sample Docker Compose file here:\nservices\n:\ntermix\n:\nimage\n:\nghcr.io/lukegus/termix:latest\ncontainer_name\n:\ntermix\nrestart\n:\nunless-stopped\nports\n:\n      -\n\"\n8080:8080\n\"\nvolumes\n:\n      -\ntermix-data:/app/data\nenvironment\n:\nPORT\n:\n\"\n8080\n\"\nvolumes\n:\ntermix-data\n:\ndriver\n:\nlocal\nSupport\nIf you need help with Termix, you can join the\nDiscord\nserver and visit the support\nchannel. You can also open an issue or open a pull request on the\nGitHub\nrepo.\nShow-off\n2025-09-30.23-13-19.mp4\nLicense\nDistributed under the Apache License Version 2.0. See LICENSE for more information.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 119",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 5,131"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/LukeGus/Termix"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/openai/openai-agents-python",
      "title": "openai/openai-agents-python",
      "date": null,
      "executive_summary": [
        "A lightweight, powerful framework for multi-agent workflows",
        "---",
        "OpenAI Agents SDK\nThe OpenAI Agents SDK is a lightweight yet powerful framework for building multi-agent workflows. It is provider-agnostic, supporting the OpenAI Responses and Chat Completions APIs, as well as 100+ other LLMs.\nNote\nLooking for the JavaScript/TypeScript version? Check out\nAgents SDK JS/TS\n.\nCore concepts:\nAgents\n: LLMs configured with instructions, tools, guardrails, and handoffs\nHandoffs\n: A specialized tool call used by the Agents SDK for transferring control between agents\nGuardrails\n: Configurable safety checks for input and output validation\nSessions\n: Automatic conversation history management across agent runs\nTracing\n: Built-in tracking of agent runs, allowing you to view, debug and optimize your workflows\nExplore the\nexamples\ndirectory to see the SDK in action, and read our\ndocumentation\nfor more details.\nGet started\nTo get started, set up your Python environment (Python 3.9 or newer required), and then install OpenAI Agents SDK package.\nvenv\npython -m venv .venv\nsource\n.venv/bin/activate\n#\nOn Windows: .venv\\Scripts\\activate\npip install openai-agents\nFor voice support, install with the optional\nvoice\ngroup:\npip install 'openai-agents[voice]'\n.\nFor Redis session support, install with the optional\nredis\ngroup:\npip install 'openai-agents[redis]'\n.\nuv\nIf you're familiar with\nuv\n, using the tool would be even similar:\nuv init\nuv add openai-agents\nFor voice support, install with the optional\nvoice\ngroup:\nuv add 'openai-agents[voice]'\n.\nFor Redis session support, install with the optional\nredis\ngroup:\nuv add 'openai-agents[redis]'\n.\nHello world example\nfrom\nagents\nimport\nAgent\n,\nRunner\nagent\n=\nAgent\n(\nname\n=\n\"Assistant\"\n,\ninstructions\n=\n\"You are a helpful assistant\"\n)\nresult\n=\nRunner\n.\nrun_sync\n(\nagent\n,\n\"Write a haiku about recursion in programming.\"\n)\nprint\n(\nresult\n.\nfinal_output\n)\n# Code within the code,\n# Functions calling themselves,\n# Infinite loop's dance.\n(\nIf running this, ensure you set the\nOPENAI_API_KEY\nenvironment variable\n)\n(\nFor Jupyter notebook users, see\nhello_world_jupyter.ipynb\n)\nHandoffs example\nfrom\nagents\nimport\nAgent\n,\nRunner\nimport\nasyncio\nspanish_agent\n=\nAgent\n(\nname\n=\n\"Spanish agent\"\n,\ninstructions\n=\n\"You only speak Spanish.\"\n,\n)\nenglish_agent\n=\nAgent\n(\nname\n=\n\"English agent\"\n,\ninstructions\n=\n\"You only speak English\"\n,\n)\ntriage_agent\n=\nAgent\n(\nname\n=\n\"Triage agent\"\n,\ninstructions\n=\n\"Handoff to the appropriate agent based on the language of the request.\"\n,\nhandoffs\n=\n[\nspanish_agent\n,\nenglish_agent\n],\n)\nasync\ndef\nmain\n():\nresult\n=\nawait\nRunner\n.\nrun\n(\ntriage_agent\n,\ninput\n=\n\"Hola, ¬øc√≥mo est√°s?\"\n)\nprint\n(\nresult\n.\nfinal_output\n)\n# ¬°Hola! Estoy bien, gracias por preguntar. ¬øY t√∫, c√≥mo est√°s?\nif\n__name__\n==\n\"__main__\"\n:\nasyncio\n.\nrun\n(\nmain\n())\nFunctions example\nimport\nasyncio\nfrom\nagents\nimport\nAgent\n,\nRunner\n,\nfunction_tool\n@\nfunction_tool\ndef\nget_weather\n(\ncity\n:\nstr\n)\n->\nstr\n:\nreturn\nf\"The weather in\n{\ncity\n}\nis sunny.\"\nagent\n=\nAgent\n(\nname\n=\n\"Hello world\"\n,\ninstructions\n=\n\"You are a helpful agent.\"\n,\ntools\n=\n[\nget_weather\n],\n)\nasync\ndef\nmain\n():\nresult\n=\nawait\nRunner\n.\nrun\n(\nagent\n,\ninput\n=\n\"What's the weather in Tokyo?\"\n)\nprint\n(\nresult\n.\nfinal_output\n)\n# The weather in Tokyo is sunny.\nif\n__name__\n==\n\"__main__\"\n:\nasyncio\n.\nrun\n(\nmain\n())\nThe agent loop\nWhen you call\nRunner.run()\n, we run a loop until we get a final output.\nWe call the LLM, using the model and settings on the agent, and the message history.\nThe LLM returns a response, which may include tool calls.\nIf the response has a final output (see below for more on this), we return it and end the loop.\nIf the response has a handoff, we set the agent to the new agent and go back to step 1.\nWe process the tool calls (if any) and append the tool responses messages. Then we go to step 1.\nThere is a\nmax_turns\nparameter that you can use to limit the number of times the loop executes.\nFinal output\nFinal output is the last thing the agent produces in the loop.\nIf you set an\noutput_type\non the agent, the final output is when the LLM returns something of that type. We use\nstructured outputs\nfor this.\nIf there's no\noutput_type\n(i.e. plain text responses), then the first LLM response without any tool calls or handoffs is considered as the final output.\nAs a result, the mental model for the agent loop is:\nIf the current agent has an\noutput_type\n, the loop runs until the agent produces structured output matching that type.\nIf the current agent does not have an\noutput_type\n, the loop runs until the current agent produces a message without any tool calls/handoffs.\nCommon agent patterns\nThe Agents SDK is designed to be highly flexible, allowing you to model a wide range of LLM workflows including deterministic flows, iterative loops, and more. See examples in\nexamples/agent_patterns\n.\nTracing\nThe Agents SDK automatically traces your agent runs, making it easy to track and debug the behavior of your agents. Tracing is extensible by design, supporting custom spans and a wide variety of external destinations, including\nLogfire\n,\nAgentOps\n,\nBraintrust\n,\nScorecard\n, and\nKeywords AI\n. For more details about how to customize or disable tracing, see\nTracing\n, which also includes a larger list of\nexternal tracing processors\n.\nLong running agents & human-in-the-loop\nYou can use the Agents SDK\nTemporal\nintegration to run durable, long-running workflows, including human-in-the-loop tasks. View a demo of Temporal and the Agents SDK working in action to complete long-running tasks\nin this video\n, and\nview docs here\n.\nSessions\nThe Agents SDK provides built-in session memory to automatically maintain conversation history across multiple agent runs, eliminating the need to manually handle\n.to_input_list()\nbetween turns.\nQuick start\nfrom\nagents\nimport\nAgent\n,\nRunner\n,\nSQLiteSession\n# Create agent\nagent\n=\nAgent\n(\nname\n=\n\"Assistant\"\n,\ninstructions\n=\n\"Reply very concisely.\"\n,\n)\n# Create a session instance\nsession\n=\nSQLiteSession\n(\n\"conversation_123\"\n)\n# First turn\nresult\n=\nawait\nRunner\n.\nrun\n(\nagent\n,\n\"What city is the Golden Gate Bridge in?\"\n,\nsession\n=\nsession\n)\nprint\n(\nresult\n.\nfinal_output\n)\n# \"San Francisco\"\n# Second turn - agent automatically remembers previous context\nresult\n=\nawait\nRunner\n.\nrun\n(\nagent\n,\n\"What state is it in?\"\n,\nsession\n=\nsession\n)\nprint\n(\nresult\n.\nfinal_output\n)\n# \"California\"\n# Also works with synchronous runner\nresult\n=\nRunner\n.\nrun_sync\n(\nagent\n,\n\"What's the population?\"\n,\nsession\n=\nsession\n)\nprint\n(\nresult\n.\nfinal_output\n)\n# \"Approximately 39 million\"\nSession options\nNo memory\n(default): No session memory when session parameter is omitted\nsession: Session = DatabaseSession(...)\n: Use a Session instance to manage conversation history\nfrom\nagents\nimport\nAgent\n,\nRunner\n,\nSQLiteSession\n# SQLite - file-based or in-memory database\nsession\n=\nSQLiteSession\n(\n\"user_123\"\n,\n\"conversations.db\"\n)\n# Redis - for scalable, distributed deployments\n# from agents.extensions.memory import RedisSession\n# session = RedisSession.from_url(\"user_123\", url=\"redis://localhost:6379/0\")\nagent\n=\nAgent\n(\nname\n=\n\"Assistant\"\n)\n# Different session IDs maintain separate conversation histories\nresult1\n=\nawait\nRunner\n.\nrun\n(\nagent\n,\n\"Hello\"\n,\nsession\n=\nsession\n)\nresult2\n=\nawait\nRunner\n.\nrun\n(\nagent\n,\n\"Hello\"\n,\nsession\n=\nSQLiteSession\n(\n\"user_456\"\n,\n\"conversations.db\"\n)\n)\nCustom session implementations\nYou can implement your own session memory by creating a class that follows the\nSession\nprotocol:\nfrom\nagents\n.\nmemory\nimport\nSession\nfrom\ntyping\nimport\nList\nclass\nMyCustomSession\n:\n\"\"\"Custom session implementation following the Session protocol.\"\"\"\ndef\n__init__\n(\nself\n,\nsession_id\n:\nstr\n):\nself\n.\nsession_id\n=\nsession_id\n# Your initialization here\nasync\ndef\nget_items\n(\nself\n,\nlimit\n:\nint\n|\nNone\n=\nNone\n)\n->\nList\n[\ndict\n]:\n# Retrieve conversation history for the session\npass\nasync\ndef\nadd_items\n(\nself\n,\nitems\n:\nList\n[\ndict\n])\n->\nNone\n:\n# Store new items for the session\npass\nasync\ndef\npop_item\n(\nself\n)\n->\ndict\n|\nNone\n:\n# Remove and return the most recent item from the session\npass\nasync\ndef\nclear_session\n(\nself\n)\n->\nNone\n:\n# Clear all items for the session\npass\n# Use your custom session\nagent\n=\nAgent\n(\nname\n=\n\"Assistant\"\n)\nresult\n=\nawait\nRunner\n.\nrun\n(\nagent\n,\n\"Hello\"\n,\nsession\n=\nMyCustomSession\n(\n\"my_session\"\n)\n)\nDevelopment (only needed if you need to edit the SDK/examples)\nEnsure you have\nuv\ninstalled.\nuv --version\nInstall dependencies\nmake sync\n(After making changes) lint/test\nmake check # run tests linter and typechecker\nOr to run them individually:\nmake tests  # run tests\nmake mypy   # run typechecker\nmake lint   # run linter\nmake format-check # run style checker\nAcknowledgements\nWe'd like to acknowledge the excellent work of the open-source community, especially:\nPydantic\n(data validation) and\nPydanticAI\n(advanced agent framework)\nLiteLLM\n(unified interface for 100+ LLMs)\nMkDocs\nGriffe\nuv\nand\nruff\nWe're committed to continuing to build the Agents SDK as an open source framework so others in the community can expand on our approach.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 116",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 16,004"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/openai/openai-agents-python"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/openemr/openemr",
      "title": "openemr/openemr",
      "date": null,
      "executive_summary": [
        "The most popular open source electronic health records and medical practice management solution.",
        "---",
        "OpenEMR\nOpenEMR\nis a Free and Open Source electronic health records and medical practice management application. It features fully integrated electronic health records, practice management, scheduling, electronic billing, internationalization, free support, a vibrant community, and a whole lot more. It runs on Windows, Linux, Mac OS X, and many other platforms.\nContributing\nOpenEMR is a leader in healthcare open source software and comprises a large and diverse community of software developers, medical providers and educators with a very healthy mix of both volunteers and professionals.\nJoin us and learn how to start contributing today!\nAlready comfortable with git? Check out\nCONTRIBUTING.md\nfor quick setup instructions and requirements for contributing to OpenEMR by resolving a bug or adding an awesome feature üòä.\nSupport\nCommunity and Professional support can be found\nhere\n.\nExtensive documentation and forums can be found on the\nOpenEMR website\nthat can help you to become more familiar about the project üìñ.\nReporting Issues and Bugs\nReport these on the\nIssue Tracker\n. If you are unsure if it is an issue/bug, then always feel free to use the\nForum\nand\nChat\nto discuss about the issue ü™≤.\nReporting Security Vulnerabilities\nCheck out\nSECURITY.md\nAPI\nCheck out\nAPI_README.md\nDocker\nCheck out\nDOCKER_README.md\nFHIR\nCheck out\nFHIR_README.md\nFor Developers\nIf using OpenEMR directly from the code repository, then the following commands will build OpenEMR (Node.js version 22.* is required) :\ncomposer install --no-dev\nnpm install\nnpm run build\ncomposer dump-autoload -o\nContributors\nThis project exists thanks to all the people who have contributed.\n[Contribute]\n.\nSponsors\nThanks to our\nONC Certification Major Sponsors\n!\nLicense\nGNU GPL",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 115",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 4,282"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/openemr/openemr"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/DioxusLabs/dioxus",
      "title": "DioxusLabs/dioxus",
      "date": null,
      "executive_summary": [
        "Fullstack app framework for web, desktop, and mobile.",
        "---",
        "Website\n|\nExamples\n|\nGuide\n|\n‰∏≠Êñá\n|\nPT-BR\n|\nÊó•Êú¨Ë™û\n|\nT√ºrk√ße\n|\nÌïúÍµ≠Ïñ¥\n‚ú® Dioxus 0.7 is in alpha - test it out! ‚ú®\nBuild for web, desktop, and mobile, and more with a single codebase. Zero-config setup, integrated hot-reloading, and signals-based state management. Add backend functionality with Server Functions and bundle with our CLI.\nfn\napp\n(\n)\n->\nElement\n{\nlet\nmut\ncount =\nuse_signal\n(\n||\n0\n)\n;\nrsx\n!\n{\nh1\n{\n\"High-Five counter: {count}\"\n}\nbutton\n{\nonclick\n:\nmove |_| count +=\n1\n,\n\"Up high!\"\n}\nbutton\n{\nonclick\n:\nmove |_| count -=\n1\n,\n\"Down low!\"\n}\n}\n}\n‚≠êÔ∏è Unique features:\nCross-platform apps in three lines of code (web, desktop, mobile, server, and more)\nErgonomic state management\ncombines the best of React, Solid, and Svelte\nBuilt-in featureful, type-safe, fullstack web framework\nIntegrated bundler for deploying to the web, macOS, Linux, and Windows\nSubsecond Rust hot-patching and asset hot-reloading\nAnd more!\nTake a tour of Dioxus\n.\nInstant hot-reloading\nWith one command,\ndx serve\nand your app is running. Edit your markup, styles, and see changes in milliseconds. Use our experimental\ndx serve --hotpatch\nto update Rust code in real time.\nBuild Beautiful Apps\nDioxus apps are styled with HTML and CSS. Use the built-in TailwindCSS support or load your favorite CSS library. Easily call into native code (objective-c, JNI, Web-Sys) for a perfect native touch.\nTruly fullstack applications\nDioxus deeply integrates with\naxum\nto provide powerful fullstack capabilities for both clients and servers. Pick from a wide array of built-in batteries like WebSockets, SSE, Streaming, File Upload/Download, Server-Side-Rendering, Forms, Middleware, and Hot-Reload, or go fully custom and integrate your existing axum backend.\nExperimental Native Renderer\nRender using web-sys, webview, server-side-rendering, liveview, or even with our experimental WGPU-based renderer. Embed Dioxus in Bevy, WGPU, or even run on embedded Linux!\nFirst-party primitive components\nGet started quickly with a complete set of primitives modeled after shadcn/ui and Radix-Primitives.\nFirst-class Android and iOS support\nDioxus is the fastest way to build native mobile apps with Rust. Simply run\ndx serve --platform android\nand your app is running in an emulator or on device in seconds. Call directly into JNI and Native APIs.\nBundle for web, desktop, and mobile\nSimply run\ndx bundle\nand your app will be built and bundled with maximization optimizations. On the web, take advantage of\n.avif\ngeneration,\n.wasm\ncompression, minification\n, and more. Build WebApps weighing\nless than 50kb\nand desktop/mobile apps less than 5mb.\nFantastic documentation\nWe've put a ton of effort into building clean, readable, and comprehensive documentation. All html elements and listeners are documented with MDN docs, and our Docs runs continuous integration with Dioxus itself to ensure that the docs are always up to date. Check out the\nDioxus website\nfor guides, references, recipes, and more. Fun fact: we use the Dioxus website as a testbed for new Dioxus features -\ncheck it out!\nModular and Customizable\nBuild your own renderer, or use a community renderer like\nFreya\n. Use our modular components like RSX, VirtualDom, Blitz, Taffy, and Subsecond.\nCommunity\nDioxus is a community-driven project, with a very active\nDiscord\nand\nGitHub\ncommunity. We're always looking for help, and we're happy to answer questions and help you get started.\nOur SDK\nis community-run and we even have a\nGitHub organization\nfor the best Dioxus crates that receive free upgrades and support.\nFull-time core team\nDioxus has grown from a side project to a small team of fulltime engineers. Thanks to the generous support of FutureWei, Satellite.im, the GitHub Accelerator program, we're able to work on Dioxus full-time. Our long term goal is for Dioxus to become self-sustaining by providing paid high-quality enterprise tools. If your company is interested in adopting Dioxus and would like to work with us, please reach out!\nSupported Platforms\nWeb\nRender directly to the DOM using WebAssembly\nPre-render with SSR and rehydrate on the client\nSimple \"hello world\" at about 50kb, comparable to React\nBuilt-in dev server and hot reloading for quick iteration\nDesktop\nRender using Webview or - experimentally - with WGPU or\nFreya\n(Skia)\nZero-config setup. Simply `cargo run` or `dx serve` to build your app\nFull support for native system access without IPC\nSupports macOS, Linux, and Windows. Portable <3mb binaries\nMobile\nRender using Webview or - experimentally - with WGPU or Skia\nBuild .ipa and .apk files for iOS and Android\nCall directly into Java and Objective-C with minimal overhead\nFrom \"hello world\" to running on device in seconds\nServer-side Rendering\nSuspense, hydration, and server-side rendering\nQuickly drop in backend functionality with server functions\nExtractors, middleware, and routing integrations\nStatic-site generation and incremental regeneration\nRunning the examples\nThe examples in the main branch of this repository target the git version of dioxus and the CLI. If you are looking for examples that work with the latest stable release of dioxus, check out the\n0.6 branch\n.\nThe examples in the top level of this repository can be run with:\ncargo run --example\n<\nexample\n>\nHowever, we encourage you to download the dioxus-cli to test out features like hot-reloading. To install the most recent binary CLI, you can use cargo binstall.\ncargo binstall dioxus-cli@0.7.0-rc.1 --force\nIf this CLI is out-of-date, you can install it directly from git\ncargo install --git https://github.com/DioxusLabs/dioxus dioxus-cli --locked\nWith the CLI, you can also run examples with the web platform. You will need to disable the default desktop feature and enable the web feature with this command:\ndx serve --example\n<\nexample\n>\n--platform web -- --no-default-features\nContributing\nCheck out the website\nsection on contributing\n.\nReport issues on our\nissue tracker\n.\nJoin\nthe discord and ask questions!\nLicense\nThis project is licensed under either the\nMIT license\nor the\nApache-2 License\n.\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in Dioxus by you, shall be licensed as MIT or Apache-2, without any additional\nterms or conditions.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 110",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 30,962"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/DioxusLabs/dioxus"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/open-webui/open-webui",
      "title": "open-webui/open-webui",
      "date": null,
      "executive_summary": [
        "User-friendly AI Interface (Supports Ollama, OpenAI API, ...)",
        "---",
        "Open WebUI üëã\nOpen WebUI is an\nextensible\n, feature-rich, and user-friendly self-hosted AI platform designed to operate entirely offline.\nIt supports various LLM runners like\nOllama\nand\nOpenAI-compatible APIs\n, with\nbuilt-in inference engine\nfor RAG, making it a\npowerful AI deployment solution\n.\nPassionate about open-source AI?\nJoin our team ‚Üí\nTip\nLooking for an\nEnterprise Plan\n?\n‚Äì\nSpeak with Our Sales Team Today!\nGet\nenhanced capabilities\n, including\ncustom theming and branding\n,\nService Level Agreement (SLA) support\n,\nLong-Term Support (LTS) versions\n, and\nmore!\nFor more information, be sure to check out our\nOpen WebUI Documentation\n.\nKey Features of Open WebUI ‚≠ê\nüöÄ\nEffortless Setup\n: Install seamlessly using Docker or Kubernetes (kubectl, kustomize or helm) for a hassle-free experience with support for both\n:ollama\nand\n:cuda\ntagged images.\nü§ù\nOllama/OpenAI API Integration\n: Effortlessly integrate OpenAI-compatible APIs for versatile conversations alongside Ollama models. Customize the OpenAI API URL to link with\nLMStudio, GroqCloud, Mistral, OpenRouter, and more\n.\nüõ°Ô∏è\nGranular Permissions and User Groups\n: By allowing administrators to create detailed user roles and permissions, we ensure a secure user environment. This granularity not only enhances security but also allows for customized user experiences, fostering a sense of ownership and responsibility amongst users.\nüîÑ\nSCIM 2.0 Support\n: Enterprise-grade user and group provisioning through SCIM 2.0 protocol, enabling seamless integration with identity providers like Okta, Azure AD, and Google Workspace for automated user lifecycle management.\nüì±\nResponsive Design\n: Enjoy a seamless experience across Desktop PC, Laptop, and Mobile devices.\nüì±\nProgressive Web App (PWA) for Mobile\n: Enjoy a native app-like experience on your mobile device with our PWA, providing offline access on localhost and a seamless user interface.\n‚úíÔ∏èüî¢\nFull Markdown and LaTeX Support\n: Elevate your LLM experience with comprehensive Markdown and LaTeX capabilities for enriched interaction.\nüé§üìπ\nHands-Free Voice/Video Call\n: Experience seamless communication with integrated hands-free voice and video call features, allowing for a more dynamic and interactive chat environment.\nüõ†Ô∏è\nModel Builder\n: Easily create Ollama models via the Web UI. Create and add custom characters/agents, customize chat elements, and import models effortlessly through\nOpen WebUI Community\nintegration.\nüêç\nNative Python Function Calling Tool\n: Enhance your LLMs with built-in code editor support in the tools workspace. Bring Your Own Function (BYOF) by simply adding your pure Python functions, enabling seamless integration with LLMs.\nüìö\nLocal RAG Integration\n: Dive into the future of chat interactions with groundbreaking Retrieval Augmented Generation (RAG) support. This feature seamlessly integrates document interactions into your chat experience. You can load documents directly into the chat or add files to your document library, effortlessly accessing them using the\n#\ncommand before a query.\nüîç\nWeb Search for RAG\n: Perform web searches using providers like\nSearXNG\n,\nGoogle PSE\n,\nBrave Search\n,\nserpstack\n,\nserper\n,\nSerply\n,\nDuckDuckGo\n,\nTavilySearch\n,\nSearchApi\nand\nBing\nand inject the results directly into your chat experience.\nüåê\nWeb Browsing Capability\n: Seamlessly integrate websites into your chat experience using the\n#\ncommand followed by a URL. This feature allows you to incorporate web content directly into your conversations, enhancing the richness and depth of your interactions.\nüé®\nImage Generation Integration\n: Seamlessly incorporate image generation capabilities using options such as AUTOMATIC1111 API or ComfyUI (local), and OpenAI's DALL-E (external), enriching your chat experience with dynamic visual content.\n‚öôÔ∏è\nMany Models Conversations\n: Effortlessly engage with various models simultaneously, harnessing their unique strengths for optimal responses. Enhance your experience by leveraging a diverse set of models in parallel.\nüîê\nRole-Based Access Control (RBAC)\n: Ensure secure access with restricted permissions; only authorized individuals can access your Ollama, and exclusive model creation/pulling rights are reserved for administrators.\nüåêüåç\nMultilingual Support\n: Experience Open WebUI in your preferred language with our internationalization (i18n) support. Join us in expanding our supported languages! We're actively seeking contributors!\nüß©\nPipelines, Open WebUI Plugin Support\n: Seamlessly integrate custom logic and Python libraries into Open WebUI using\nPipelines Plugin Framework\n. Launch your Pipelines instance, set the OpenAI URL to the Pipelines URL, and explore endless possibilities.\nExamples\ninclude\nFunction Calling\n, User\nRate Limiting\nto control access,\nUsage Monitoring\nwith tools like Langfuse,\nLive Translation with LibreTranslate\nfor multilingual support,\nToxic Message Filtering\nand much more.\nüåü\nContinuous Updates\n: We are committed to improving Open WebUI with regular updates, fixes, and new features.\nWant to learn more about Open WebUI's features? Check out our\nOpen WebUI documentation\nfor a comprehensive overview!\nSponsors üôå\nEmerald\nTailscale\n‚Ä¢ Connect self-hosted AI to any device with Tailscale\nWarp\n‚Ä¢ The intelligent terminal for developers\nWe are incredibly grateful for the generous support of our sponsors. Their contributions help us to maintain and improve our project, ensuring we can continue to deliver quality work to our community. Thank you!\nHow to Install üöÄ\nInstallation via Python pip üêç\nOpen WebUI can be installed using pip, the Python package installer. Before proceeding, ensure you're using\nPython 3.11\nto avoid compatibility issues.\nInstall Open WebUI\n:\nOpen your terminal and run the following command to install Open WebUI:\npip install open-webui\nRunning Open WebUI\n:\nAfter installation, you can start Open WebUI by executing:\nopen-webui serve\nThis will start the Open WebUI server, which you can access at\nhttp://localhost:8080\nQuick Start with Docker üê≥\nNote\nPlease note that for certain Docker environments, additional configurations might be needed. If you encounter any connection issues, our detailed guide on\nOpen WebUI Documentation\nis ready to assist you.\nWarning\nWhen using Docker to install Open WebUI, make sure to include the\n-v open-webui:/app/backend/data\nin your Docker command. This step is crucial as it ensures your database is properly mounted and prevents any loss of data.\nTip\nIf you wish to utilize Open WebUI with Ollama included or CUDA acceleration, we recommend utilizing our official images tagged with either\n:cuda\nor\n:ollama\n. To enable CUDA, you must install the\nNvidia CUDA container toolkit\non your Linux/WSL system.\nInstallation with Default Configuration\nIf Ollama is on your computer\n, use this command:\ndocker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main\nIf Ollama is on a Different Server\n, use this command:\nTo connect to Ollama on another server, change the\nOLLAMA_BASE_URL\nto the server's URL:\ndocker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main\nTo run Open WebUI with Nvidia GPU support\n, use this command:\ndocker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda\nInstallation for OpenAI API Usage Only\nIf you're only using OpenAI API\n, use this command:\ndocker run -d -p 3000:8080 -e OPENAI_API_KEY=your_secret_key -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main\nInstalling Open WebUI with Bundled Ollama Support\nThis installation method uses a single container image that bundles Open WebUI with Ollama, allowing for a streamlined setup via a single command. Choose the appropriate command based on your hardware setup:\nWith GPU Support\n:\nUtilize GPU resources by running the following command:\ndocker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama\nFor CPU Only\n:\nIf you're not using a GPU, use this command instead:\ndocker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama\nBoth commands facilitate a built-in, hassle-free installation of both Open WebUI and Ollama, ensuring that you can get everything up and running swiftly.\nAfter installation, you can access Open WebUI at\nhttp://localhost:3000\n. Enjoy! üòÑ\nOther Installation Methods\nWe offer various installation alternatives, including non-Docker native installation methods, Docker Compose, Kustomize, and Helm. Visit our\nOpen WebUI Documentation\nor join our\nDiscord community\nfor comprehensive guidance.\nLook at the\nLocal Development Guide\nfor instructions on setting up a local development environment.\nTroubleshooting\nEncountering connection issues? Our\nOpen WebUI Documentation\nhas got you covered. For further assistance and to join our vibrant community, visit the\nOpen WebUI Discord\n.\nOpen WebUI: Server Connection Error\nIf you're experiencing connection issues, it‚Äôs often due to the WebUI docker container not being able to reach the Ollama server at 127.0.0.1:11434 (host.docker.internal:11434) inside the container . Use the\n--network=host\nflag in your docker command to resolve this. Note that the port changes from 3000 to 8080, resulting in the link:\nhttp://localhost:8080\n.\nExample Docker Command\n:\ndocker run -d --network=host -v open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://127.0.0.1:11434 --name open-webui --restart always ghcr.io/open-webui/open-webui:main\nKeeping Your Docker Installation Up-to-Date\nIn case you want to update your local Docker installation to the latest version, you can do it with\nWatchtower\n:\ndocker run --rm --volume /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --run-once open-webui\nIn the last part of the command, replace\nopen-webui\nwith your container name if it is different.\nCheck our Updating Guide available in our\nOpen WebUI Documentation\n.\nUsing the Dev Branch üåô\nWarning\nThe\n:dev\nbranch contains the latest unstable features and changes. Use it at your own risk as it may have bugs or incomplete features.\nIf you want to try out the latest bleeding-edge features and are okay with occasional instability, you can use the\n:dev\ntag like this:\ndocker run -d -p 3000:8080 -v open-webui:/app/backend/data --name open-webui --add-host=host.docker.internal:host-gateway --restart always ghcr.io/open-webui/open-webui:dev\nOffline Mode\nIf you are running Open WebUI in an offline environment, you can set the\nHF_HUB_OFFLINE\nenvironment variable to\n1\nto prevent attempts to download models from the internet.\nexport\nHF_HUB_OFFLINE=1\nWhat's Next? üåü\nDiscover upcoming features on our roadmap in the\nOpen WebUI Documentation\n.\nLicense üìú\nThis project contains code under multiple licenses. The current codebase includes components licensed under the Open WebUI License with an additional requirement to preserve the \"Open WebUI\" branding, as well as prior contributions under their respective original licenses. For a detailed record of license changes and the applicable terms for each section of the code, please refer to\nLICENSE_HISTORY\n. For complete and updated licensing details, please see the\nLICENSE\nand\nLICENSE_HISTORY\nfiles.\nSupport üí¨\nIf you have any questions, suggestions, or need assistance, please open an issue or join our\nOpen WebUI Discord community\nto connect with us! ü§ù\nStar History\nCreated by\nTimothy Jaeryang Baek\n- Let's make Open WebUI even more amazing together! üí™",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 106",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 111,984"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/open-webui/open-webui"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/78/xiaozhi-esp32",
      "title": "78/xiaozhi-esp32",
      "date": null,
      "executive_summary": [
        "An MCP-based chatbot | ‰∏Ä‰∏™Âü∫‰∫éMCPÁöÑËÅäÂ§©Êú∫Âô®‰∫∫",
        "---",
        "An MCP-based Chatbot\nÔºà‰∏≠Êñá |\nEnglish\n|\nÊó•Êú¨Ë™û\nÔºâ\n‰ªãÁªç\nüëâ\n‰∫∫Á±ªÔºöÁªô AI Ë£ÖÊëÑÂÉèÂ§¥ vs AIÔºöÂΩìÂú∫ÂèëÁé∞‰∏ª‰∫∫‰∏âÂ§©Ê≤°Ê¥óÂ§¥„Äêbilibili„Äë\nüëâ\nÊâãÂ∑•ÊâìÈÄ†‰Ω†ÁöÑ AI Â•≥ÂèãÔºåÊñ∞ÊâãÂÖ•Èó®ÊïôÁ®ã„Äêbilibili„Äë\nÂ∞èÊô∫ AI ËÅäÂ§©Êú∫Âô®‰∫∫‰Ωú‰∏∫‰∏Ä‰∏™ËØ≠Èü≥‰∫§‰∫íÂÖ•Âè£ÔºåÂà©Áî® Qwen / DeepSeek Á≠âÂ§ßÊ®°ÂûãÁöÑ AI ËÉΩÂäõÔºåÈÄöËøá MCP ÂçèËÆÆÂÆûÁé∞Â§öÁ´ØÊéßÂà∂„ÄÇ\nÁâàÊú¨ËØ¥Êòé\nÂΩìÂâç v2 ÁâàÊú¨‰∏é v1 ÁâàÊú¨ÂàÜÂå∫Ë°®‰∏çÂÖºÂÆπÔºåÊâÄ‰ª•Êó†Ê≥ï‰ªé v1 ÁâàÊú¨ÈÄöËøá OTA ÂçáÁ∫ßÂà∞ v2 ÁâàÊú¨„ÄÇÂàÜÂå∫Ë°®ËØ¥ÊòéÂèÇËßÅ\npartitions/v2/README.md\n„ÄÇ\n‰ΩøÁî® v1 ÁâàÊú¨ÁöÑÊâÄÊúâÁ°¨‰ª∂ÔºåÂèØ‰ª•ÈÄöËøáÊâãÂä®ÁÉßÂΩïÂõ∫‰ª∂Êù•ÂçáÁ∫ßÂà∞ v2 ÁâàÊú¨„ÄÇ\nv1 ÁöÑÁ®≥ÂÆöÁâàÊú¨‰∏∫ 1.9.2ÔºåÂèØ‰ª•ÈÄöËøá\ngit checkout v1\nÊù•ÂàáÊç¢Âà∞ v1 ÁâàÊú¨ÔºåËØ•ÂàÜÊîØ‰ºöÊåÅÁª≠Áª¥Êä§Âà∞ 2026 Âπ¥ 2 Êúà„ÄÇ\nÂ∑≤ÂÆûÁé∞ÂäüËÉΩ\nWi-Fi / ML307 Cat.1 4G\nÁ¶ªÁ∫øËØ≠Èü≥Âî§ÈÜí\nESP-SR\nÊîØÊåÅ‰∏§ÁßçÈÄö‰ø°ÂçèËÆÆÔºà\nWebsocket\nÊàñ MQTT+UDPÔºâ\nÈááÁî® OPUS Èü≥È¢ëÁºñËß£Á†Å\nÂü∫‰∫éÊµÅÂºè ASR + LLM + TTS Êû∂ÊûÑÁöÑËØ≠Èü≥‰∫§‰∫í\nÂ£∞Á∫πËØÜÂà´ÔºåËØÜÂà´ÂΩìÂâçËØ¥ËØù‰∫∫ÁöÑË∫´‰ªΩ\n3D Speaker\nOLED / LCD ÊòæÁ§∫Â±èÔºåÊîØÊåÅË°®ÊÉÖÊòæÁ§∫\nÁîµÈáèÊòæÁ§∫‰∏éÁîµÊ∫êÁÆ°ÁêÜ\nÊîØÊåÅÂ§öËØ≠Ë®ÄÔºà‰∏≠Êñá„ÄÅËã±Êñá„ÄÅÊó•ÊñáÔºâ\nÊîØÊåÅ ESP32-C3„ÄÅESP32-S3„ÄÅESP32-P4 ËäØÁâáÂπ≥Âè∞\nÈÄöËøáËÆæÂ§áÁ´Ø MCP ÂÆûÁé∞ËÆæÂ§áÊéßÂà∂ÔºàÈü≥Èáè„ÄÅÁÅØÂÖâ„ÄÅÁîµÊú∫„ÄÅGPIO Á≠âÔºâ\nÈÄöËøá‰∫ëÁ´Ø MCP Êâ©Â±ïÂ§ßÊ®°ÂûãËÉΩÂäõÔºàÊô∫ËÉΩÂÆ∂Â±ÖÊéßÂà∂„ÄÅPCÊ°åÈù¢Êìç‰Ωú„ÄÅÁü•ËØÜÊêúÁ¥¢„ÄÅÈÇÆ‰ª∂Êî∂ÂèëÁ≠âÔºâ\nËá™ÂÆö‰πâÂî§ÈÜíËØç„ÄÅÂ≠ó‰Ωì„ÄÅË°®ÊÉÖ‰∏éËÅäÂ§©ËÉåÊôØÔºåÊîØÊåÅÁΩëÈ°µÁ´ØÂú®Á∫ø‰øÆÊîπ (\nËá™ÂÆö‰πâAssetsÁîüÊàêÂô®\n)\nÁ°¨‰ª∂\nÈù¢ÂåÖÊùøÊâãÂ∑•Âà∂‰ΩúÂÆûË∑µ\nËØ¶ËßÅÈ£û‰π¶ÊñáÊ°£ÊïôÁ®ãÔºö\nüëâ\n„ÄäÂ∞èÊô∫ AI ËÅäÂ§©Êú∫Âô®‰∫∫ÁôæÁßëÂÖ®‰π¶„Äã\nÈù¢ÂåÖÊùøÊïàÊûúÂõæÂ¶Ç‰∏ãÔºö\nÊîØÊåÅ 70 Â§ö‰∏™ÂºÄÊ∫êÁ°¨‰ª∂Ôºà‰ªÖÂ±ïÁ§∫ÈÉ®ÂàÜÔºâ\nÁ´ãÂàõ¬∑ÂÆûÊàòÊ¥æ ESP32-S3 ÂºÄÂèëÊùø\n‰πêÈë´ ESP32-S3-BOX3\nM5Stack CoreS3\nM5Stack AtomS3R + Echo Base\nÁ•ûÂ•áÊåâÈíÆ 2.4\nÂæÆÈõ™ÁîµÂ≠ê ESP32-S3-Touch-AMOLED-1.8\nLILYGO T-Circle-S3\nËôæÂì• Mini C3\nÁíÄÁí®¬∑AI ÂêäÂù†\nÊó†ÂêçÁßëÊäÄ Nologo-ÊòüÊô∫-1.54TFT\nSenseCAP Watcher\nESP-HI Ë∂Ö‰ΩéÊàêÊú¨Êú∫Âô®Áãó\nËΩØ‰ª∂\nÂõ∫‰ª∂ÁÉßÂΩï\nÊñ∞ÊâãÁ¨¨‰∏ÄÊ¨°Êìç‰ΩúÂª∫ËÆÆÂÖà‰∏çË¶ÅÊê≠Âª∫ÂºÄÂèëÁéØÂ¢ÉÔºåÁõ¥Êé•‰ΩøÁî®ÂÖçÂºÄÂèëÁéØÂ¢ÉÁÉßÂΩïÁöÑÂõ∫‰ª∂„ÄÇ\nÂõ∫‰ª∂ÈªòËÆ§Êé•ÂÖ•\nxiaozhi.me\nÂÆòÊñπÊúçÂä°Âô®Ôºå‰∏™‰∫∫Áî®Êà∑Ê≥®ÂÜåË¥¶Âè∑ÂèØ‰ª•ÂÖçË¥π‰ΩøÁî® Qwen ÂÆûÊó∂Ê®°Âûã„ÄÇ\nüëâ\nÊñ∞ÊâãÁÉßÂΩïÂõ∫‰ª∂ÊïôÁ®ã\nÂºÄÂèëÁéØÂ¢É\nCursor Êàñ VSCode\nÂÆâË£Ö ESP-IDF Êèí‰ª∂ÔºåÈÄâÊã© SDK ÁâàÊú¨ 5.4 Êàñ‰ª•‰∏ä\nLinux ÊØî Windows Êõ¥Â•ΩÔºåÁºñËØëÈÄüÂ∫¶Âø´Ôºå‰πüÂÖçÂéªÈ©±Âä®ÈóÆÈ¢òÁöÑÂõ∞Êâ∞\nÊú¨È°πÁõÆ‰ΩøÁî® Google C++ ‰ª£Á†ÅÈ£éÊ†ºÔºåÊèê‰∫§‰ª£Á†ÅÊó∂ËØ∑Á°Æ‰øùÁ¨¶ÂêàËßÑËåÉ\nÂºÄÂèëËÄÖÊñáÊ°£\nËá™ÂÆö‰πâÂºÄÂèëÊùøÊåáÂçó\n- Â≠¶‰π†Â¶Ç‰Ωï‰∏∫Â∞èÊô∫ AI ÂàõÂª∫Ëá™ÂÆö‰πâÂºÄÂèëÊùø\nMCP ÂçèËÆÆÁâ©ËÅîÁΩëÊéßÂà∂Áî®Ê≥ïËØ¥Êòé\n- ‰∫ÜËß£Â¶Ç‰ΩïÈÄöËøá MCP ÂçèËÆÆÊéßÂà∂Áâ©ËÅîÁΩëËÆæÂ§á\nMCP ÂçèËÆÆ‰∫§‰∫íÊµÅÁ®ã\n- ËÆæÂ§áÁ´Ø MCP ÂçèËÆÆÁöÑÂÆûÁé∞ÊñπÂºè\nMQTT + UDP Ê∑∑ÂêàÈÄö‰ø°ÂçèËÆÆÊñáÊ°£\n‰∏Ä‰ªΩËØ¶ÁªÜÁöÑ WebSocket ÈÄö‰ø°ÂçèËÆÆÊñáÊ°£\nÂ§ßÊ®°ÂûãÈÖçÁΩÆ\nÂ¶ÇÊûú‰Ω†Â∑≤ÁªèÊã•Êúâ‰∏Ä‰∏™Â∞èÊô∫ AI ËÅäÂ§©Êú∫Âô®‰∫∫ËÆæÂ§áÔºåÂπ∂‰∏îÂ∑≤Êé•ÂÖ•ÂÆòÊñπÊúçÂä°Âô®ÔºåÂèØ‰ª•ÁôªÂΩï\nxiaozhi.me\nÊéßÂà∂Âè∞ËøõË°åÈÖçÁΩÆ„ÄÇ\nüëâ\nÂêéÂè∞Êìç‰ΩúËßÜÈ¢ëÊïôÁ®ãÔºàÊóßÁâàÁïåÈù¢Ôºâ\nÁõ∏ÂÖ≥ÂºÄÊ∫êÈ°πÁõÆ\nÂú®‰∏™‰∫∫ÁîµËÑë‰∏äÈÉ®ÁΩ≤ÊúçÂä°Âô®ÔºåÂèØ‰ª•ÂèÇËÄÉ‰ª•‰∏ãÁ¨¨‰∏âÊñπÂºÄÊ∫êÁöÑÈ°πÁõÆÔºö\nxinnan-tech/xiaozhi-esp32-server\nPython ÊúçÂä°Âô®\njoey-zhou/xiaozhi-esp32-server-java\nJava ÊúçÂä°Âô®\nAnimeAIChat/xiaozhi-server-go\nGolang ÊúçÂä°Âô®\n‰ΩøÁî®Â∞èÊô∫ÈÄö‰ø°ÂçèËÆÆÁöÑÁ¨¨‰∏âÊñπÂÆ¢Êà∑Á´ØÈ°πÁõÆÔºö\nhuangjunsen0406/py-xiaozhi\nPython ÂÆ¢Êà∑Á´Ø\nTOM88812/xiaozhi-android-client\nAndroid ÂÆ¢Êà∑Á´Ø\n100askTeam/xiaozhi-linux\nÁôæÈóÆÁßëÊäÄÊèê‰æõÁöÑ Linux ÂÆ¢Êà∑Á´Ø\n78/xiaozhi-sf32\nÊÄùÊæàÁßëÊäÄÁöÑËìùÁâôËäØÁâáÂõ∫‰ª∂\nQuecPython/solution-xiaozhiAI\nÁßªËøúÊèê‰æõÁöÑ QuecPython Âõ∫‰ª∂\nÂÖ≥‰∫éÈ°πÁõÆ\nËøôÊòØ‰∏Ä‰∏™Áî±ËôæÂì•ÂºÄÊ∫êÁöÑ ESP32 È°πÁõÆÔºå‰ª• MIT ËÆ∏ÂèØËØÅÂèëÂ∏ÉÔºåÂÖÅËÆ∏‰ªª‰Ωï‰∫∫ÂÖçË¥π‰ΩøÁî®Ôºå‰øÆÊîπÊàñÁî®‰∫éÂïÜ‰∏öÁî®ÈÄî„ÄÇ\nÊàë‰ª¨Â∏åÊúõÈÄöËøáËøô‰∏™È°πÁõÆÔºåËÉΩÂ§üÂ∏ÆÂä©Â§ßÂÆ∂‰∫ÜËß£ AI Á°¨‰ª∂ÂºÄÂèëÔºåÂ∞ÜÂΩì‰∏ãÈ£ûÈÄüÂèëÂ±ïÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂ∫îÁî®Âà∞ÂÆûÈôÖÁöÑÁ°¨‰ª∂ËÆæÂ§á‰∏≠„ÄÇ\nÂ¶ÇÊûú‰Ω†Êúâ‰ªª‰ΩïÊÉ≥Ê≥ïÊàñÂª∫ËÆÆÔºåËØ∑ÈöèÊó∂ÊèêÂá∫ Issues ÊàñÂä†ÂÖ• QQ Áæ§Ôºö1011329060\nStar History",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 102",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 19,237"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/78/xiaozhi-esp32"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/FlowiseAI/Flowise",
      "title": "FlowiseAI/Flowise",
      "date": null,
      "executive_summary": [
        "Build AI Agents, Visually",
        "---",
        "English |\nÁπÅÈ´î‰∏≠Êñá\n|\nÁÆÄ‰Ωì‰∏≠Êñá\n|\nÊó•Êú¨Ë™û\n|\nÌïúÍµ≠Ïñ¥\nBuild AI Agents, Visually\nüìö Table of Contents\n‚ö° Quick Start\nüê≥ Docker\nüë®‚Äçüíª Developers\nüå± Env Variables\nüìñ Documentation\nüåê Self Host\n‚òÅÔ∏è Flowise Cloud\nüôã Support\nüôå Contributing\nüìÑ License\n‚ö°Quick Start\nDownload and Install\nNodeJS\n>= 18.15.0\nInstall Flowise\nnpm install -g flowise\nStart Flowise\nnpx flowise start\nOpen\nhttp://localhost:3000\nüê≥ Docker\nDocker Compose\nClone the Flowise project\nGo to\ndocker\nfolder at the root of the project\nCopy\n.env.example\nfile, paste it into the same location, and rename to\n.env\nfile\ndocker compose up -d\nOpen\nhttp://localhost:3000\nYou can bring the containers down by\ndocker compose stop\nDocker Image\nBuild the image locally:\ndocker build --no-cache -t flowise\n.\nRun image:\ndocker run -d --name flowise -p 3000:3000 flowise\nStop image:\ndocker stop flowise\nüë®‚Äçüíª Developers\nFlowise has 3 different modules in a single mono repository.\nserver\n: Node backend to serve API logics\nui\n: React frontend\ncomponents\n: Third-party nodes integrations\napi-documentation\n: Auto-generated swagger-ui API docs from express\nPrerequisite\nInstall\nPNPM\nnpm i -g pnpm\nSetup\nClone the repository:\ngit clone https://github.com/FlowiseAI/Flowise.git\nGo into repository folder:\ncd\nFlowise\nInstall all dependencies of all modules:\npnpm install\nBuild all the code:\npnpm build\nExit code 134 (JavaScript heap out of memory)\nIf you get this error when running the above `build` script, try increasing the Node.js heap size and run the script again:\n#\nmacOS / Linux / Git Bash\nexport\nNODE_OPTIONS=\n\"\n--max-old-space-size=4096\n\"\n#\nWindows PowerShell\n$env\n:NODE_OPTIONS=\n\"\n--max-old-space-size=4096\n\"\n#\nWindows CMD\nset\nNODE_OPTIONS=--max-old-space-size=4096\nThen run:\npnpm build\nStart the app:\npnpm start\nYou can now access the app on\nhttp://localhost:3000\nFor development build:\nCreate\n.env\nfile and specify the\nVITE_PORT\n(refer to\n.env.example\n) in\npackages/ui\nCreate\n.env\nfile and specify the\nPORT\n(refer to\n.env.example\n) in\npackages/server\nRun:\npnpm dev\nAny code changes will reload the app automatically on\nhttp://localhost:8080\nüå± Env Variables\nFlowise supports different environment variables to configure your instance. You can specify the following variables in the\n.env\nfile inside\npackages/server\nfolder. Read\nmore\nüìñ Documentation\nYou can view the Flowise Docs\nhere\nüåê Self Host\nDeploy Flowise self-hosted in your existing infrastructure, we support various\ndeployments\nAWS\nAzure\nDigital Ocean\nGCP\nAlibaba Cloud\nOthers\nRailway\nRender\nHuggingFace Spaces\nElestio\nSealos\nRepoCloud\n‚òÅÔ∏è Flowise Cloud\nGet Started with\nFlowise Cloud\n.\nüôã Support\nFeel free to ask any questions, raise problems, and request new features in\nDiscussion\n.\nüôå Contributing\nThanks go to these awesome contributors\nSee\nContributing Guide\n. Reach out to us at\nDiscord\nif you have any questions or issues.\nüìÑ License\nSource code in this repository is made available under the\nApache License Version 2.0\n.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 98",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 45,125"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/FlowiseAI/Flowise"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/PixelGuys/Cubyz",
      "title": "PixelGuys/Cubyz",
      "date": null,
      "executive_summary": [
        "Voxel sandbox game with a large render distance, procedurally generated content and some cool graphical effects.",
        "---",
        "Cubyz\nCubyz is a 3D voxel sandbox game (inspired by Minecraft).\nCubyz has a bunch of interesting/unique features such as:\nLevel of Detail (‚Üí This enables far view distances.)\n3D Chunks (‚Üí There is no height or depth limit.)\nProcedural Crafting (‚Üí You can craft anything you want, and the game will figure out what kind of tool you tried to make.)\nAbout\nCubyz is written in\nZig\n, a rather small language with some cool features and a focus on readability.\nWindows and Linux are supported. Mac is not supported, as it does not have OpenGL 4.3.\nCheck out the\nDiscord server\nfor more information and announcements.\nThere are also some devlogs on\nYouTube\n.\nHistory\nUntil recently (the Zig rewrite was started in August 2022) Cubyz was written in Java. You can still see the code in the\nCubyz-Java\nrepository and play it using the\nJava Launcher\n.\n// TODO: Move this over to a separate repository\nOriginally Cubyz was created on August 22, 2018 by\nzenith391\nand\nZaUserA\n. Back then, it was called \"Cubz\".\nHowever, both of them lost interest at some point, and now Cubyz is maintained by\nIntegratedQuantum\n.\nRun Cubyz\nThis section is about compiling a dev version, if you just want a precompiled version, go to\nreleases\nThe Easy Way (no tools needed)\nDownload the latest\nsource code\nExtract the zip file\nGo into the extraced folder and double click the\nrun_linux.sh\nor\nrun_windows.bat\ndepending on your operating system.\nCongratulations: You just compiled your first program!\nIt doesn't work?\nIf it doesn't work and keeps running for more than 10 minutes without doing anything it can help to kill and restart the process. A few people seem to experience this, and I have not found the cause. It might also help to delete the\nzig-cache\nfolder.\nIf you see an error message in the terminal, please report it in the\nIssues\ntab or on the\nDiscord server\n.\nOtherwise you can always ask for help on the Discord server. If you are unable to get it compiling on your machine, you can also ask on the Discord server and we may compile a release for you.\nNote for Linux Users:\nI also had to install a few\n-dev\npackages for the compilation to work:\nsudo apt install libgl-dev libasound2-dev libx11-dev libxcursor-dev libxrandr-dev libxinerama-dev libxext-dev libxi-dev\nThe Better Way\nInstall Git\nClone this repository\ngit clone https://github.com/pixelguys/Cubyz\nRun\nrun_linux.sh\nor\nrun_windows.bat\n, if you already have Zig installed on your computer (it must be a compatible version) you can also just use\nzig build run\nWhen you want to update your local version you can use\ngit pull\n. This keeps everything in one place, avoiding repeatedly downloading the compiler on every update.\nContributing\nCode\nCheck out the\nContributing Guidelines\nGameplay Additions\nCheck out the\nGame Design Principles\nTextures\nIf you want to add new textures, make sure they fit the style of the game. It's recommended that you have baseline skills in pixel art before attempting to make textures. A great collection of tutorials can be found\nhere\nIf any of the following points are ignored, your texture will be rejected:\nResolution is 16 x 16\nLighting direction is top-left for items and blocks.\nKeep colour palettes small. Do not use near-duplicate colours, do not use noise, filters, or brushes that create unnecessary amounts of colours. Most blocks can be textured with ~4-6 colours.\nReference other block textures to see how colours & contrast is used. Test your textures ingame alongside other blocks.\nBlocks should tile smoothly. Avoid creating seams or repetitive patterns.\nUse hue shifting conservatively. Take the material into account when choosing colours.\nItems have full, coloured, 1-pixel outlines. It should be shaded so that the side in light (top left) is brighter, while the side in shadow (bottom right) is darker.\nItems should have higher contrast than their block counterparts.\nYour texture may be edited or replaced to ensure a consistent art style throughout the game.\nFor further information, ask\ncareeoki\non\nDiscord\n. She has made a majority of the art for Cubyz.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 89",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 1,150"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/PixelGuys/Cubyz"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/chen08209/FlClash",
      "title": "chen08209/FlClash",
      "date": null,
      "executive_summary": [
        "A multi-platform proxy client based on ClashMeta,simple and easy to use, open-source and ad-free.",
        "---",
        "ÁÆÄ‰Ωì‰∏≠Êñá\nFlClash\nA multi-platform proxy client based on ClashMeta, simple and easy to use, open-source and ad-free.\non Desktop:\non Mobile:\nFeatures\n‚úàÔ∏è\nMulti-platform: Android, Windows, macOS and Linux\nüíª Adaptive multiple screen sizes, Multiple color themes available\nüí° Based on Material You Design,\nSurfboard\n-like UI\n‚òÅÔ∏è Supports data sync via WebDAV\n‚ú® Support subscription link, Dark mode\nUse\nLinux\n‚ö†Ô∏è\nMake sure to install the following dependencies before using them\nsudo apt-get install libayatana-appindicator3-dev\n sudo apt-get install libkeybinder-3.0-dev\nAndroid\nSupport the following actions\ncom.follow.clash.action.START\n \n com.follow.clash.action.STOP\n \n com.follow.clash.action.TOGGLE\nDownload\nBuild\nUpdate submodules\ngit submodule update --init --recursive\nInstall\nFlutter\nand\nGolang\nenvironment\nBuild Application\nandroid\nInstall\nAndroid SDK\n,\nAndroid NDK\nSet\nANDROID_NDK\nenvironment variables\nRun Build script\ndart .\n\\s\netup.dart android\nwindows\nYou need a windows client\nInstall\nGcc\nÔºå\nInno Setup\nRun build script\ndart .\n\\s\netup.dart windows --arch\n<\narm64\n|\namd\n64>\nlinux\nYou need a linux client\nRun build script\ndart .\n\\s\netup.dart linux --arch\n<\narm64\n|\namd\n64>\nmacOS\nYou need a macOS client\nRun build script\ndart .\n\\s\netup.dart macos --arch\n<\narm64\n|\namd\n64>\nStar\nThe easiest way to support developers is to click on the star (‚≠ê) at the top of the page.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 72",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 22,984"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/chen08209/FlClash"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/WECENG/ticket-purchase",
      "title": "WECENG/ticket-purchase",
      "date": null,
      "executive_summary": [
        "Â§ßÈ∫¶Ëá™Âä®Êä¢Á•®ÔºåÊîØÊåÅ‰∫∫Âëò„ÄÅÂüéÂ∏Ç„ÄÅÊó•ÊúüÂú∫Ê¨°„ÄÅ‰ª∑Ê†ºÈÄâÊã©",
        "---",
        "Â§ßÈ∫¶Êä¢Á•®ËÑöÊú¨ V1.0\nÁâπÂæÅ\nËá™Âä®Êó†Âª∂Êó∂Êä¢Á•®\nÊîØÊåÅ‰∫∫Âëò„ÄÅÂüéÂ∏Ç„ÄÅÊó•ÊúüÂú∫Ê¨°„ÄÅ‰ª∑Ê†ºÈÄâÊã©\nÂäüËÉΩ‰ªãÁªç\nÈÄöËøáseleniumÊâìÂºÄÈ°µÈù¢ËøõË°åÁôªÂΩïÔºåÊ®°ÊãüÁî®Êà∑Ë¥≠Á•®ÊµÅÁ®ãËá™Âä®Ë¥≠Á•®\nÂÖ∂ÊµÅÁ®ãÂõæÂ¶Ç‰∏ã:\nÂáÜÂ§áÂ∑•‰Ωú\n1. ÈÖçÁΩÆÁéØÂ¢É\n1.1ÂÆâË£Öpython3ÁéØÂ¢É\nWindows\nËÆøÈóÆPythonÂÆòÊñπÁΩëÁ´ôÔºö\nhttps://www.python.org/downloads/windows/\n‰∏ãËΩΩÊúÄÊñ∞ÁöÑPython 3.9+ÁâàÊú¨ÁöÑÂÆâË£ÖÁ®ãÂ∫è„ÄÇ\nËøêË°åÂÆâË£ÖÁ®ãÂ∫è„ÄÇ\nÂú®ÂÆâË£ÖÁ®ãÂ∫è‰∏≠ÔºåÁ°Æ‰øùÂãæÈÄâ \"Add Python X.X to PATH\" ÈÄâÈ°πÔºåËøôÂ∞ÜËá™Âä®Â∞ÜPythonÊ∑ªÂä†Âà∞Á≥ªÁªüÁéØÂ¢ÉÂèòÈáè‰∏≠ÔºåÊñπ‰æøÂú®ÂëΩ‰ª§Ë°å‰∏≠‰ΩøÁî®Python„ÄÇ\nÂÆåÊàêÂÆâË£ÖÂêéÔºå‰Ω†ÂèØ‰ª•Âú®ÂëΩ‰ª§ÊèêÁ§∫Á¨¶ÊàñPowerShell‰∏≠ËæìÂÖ•\npython3\nÊù•ÂêØÂä®PythonËß£ÈáäÂô®„ÄÇ\nmacOS\n‰Ω†ÂèØ‰ª•‰ΩøÁî®HomebrewÊù•ÂÆâË£ÖPython 3„ÄÇ\nÂÆâË£ÖHomebrewÔºàÂ¶ÇÊûúÊú™ÂÆâË£ÖÔºâÔºöÊâìÂºÄÁªàÁ´ØÂπ∂ËøêË°å‰ª•‰∏ãÂëΩ‰ª§Ôºö\n/bin/bash -c\n\"\n$(\ncurl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh\n)\n\"\nÂÆâË£ÖPython 3ÔºöËøêË°å‰ª•‰∏ãÂëΩ‰ª§Êù•ÂÆâË£ÖPython 3Ôºö\nbrew install python@3\n1.2 ÂÆâË£ÖÊâÄÈúÄË¶ÅÁöÑÁéØÂ¢É\nÂú®ÂëΩ‰ª§Á™óÂè£ËæìÂÖ•Â¶Ç‰∏ãÊåá‰ª§\npip3 install selenium\n1.3 ‰∏ãËΩΩgoogle chromeÊµèËßàÂô®\n‰∏ãËΩΩÂú∞ÂùÄ:\nhttps://www.google.cn/intl/zh-CN/chrome/?brand=YTUH&gclid=Cj0KCQjwj5mpBhDJARIsAOVjBdoV_1sBwdqKGHV3rUU1vJmNKZdy5QNzbRT8F5O0-_jq1WHXurE8a7MaAkWrEALw_wcB&gclsrc=aw.ds\n2. ‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂\nÂú®ËøêË°åÁ®ãÂ∫è‰πãÂâçÔºåÈúÄË¶ÅÂÖà‰øÆÊîπ\nconfig.json\nÊñá‰ª∂„ÄÇËØ•Êñá‰ª∂Áî®‰∫éÊåáÂÆöÁî®Êà∑ÈúÄË¶ÅÊä¢Á•®ÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØÔºåÂåÖÊã¨ÊºîÂî±‰ºöÁöÑÂú∫Ê¨°„ÄÅËßÇÊºîÁöÑ‰∫∫Âëò„ÄÅÂüéÂ∏Ç„ÄÅÊó•Êúü„ÄÅ‰ª∑Ê†ºÁ≠â„ÄÇÊñá‰ª∂ÁªìÊûúÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö\n2.1 Êñá‰ª∂ÂÜÖÂÆπËØ¥Êòé\nindex_url\n‰∏∫Â§ßÈ∫¶ÁΩëÁöÑÂú∞ÂùÄÔºå\nÊó†ÈúÄ‰øÆÊîπ\nlogin_url\n‰∏∫Â§ßÈ∫¶ÁΩëÁöÑÁôªÂΩïÂú∞ÂùÄÔºå\nÊó†ÈúÄ‰øÆÊîπ\ntarget_url\n‰∏∫Áî®Êà∑ÈúÄË¶ÅÊä¢ÁöÑÊºîÂî±‰ºöÁ•®ÁöÑÁõÆÊ†áÂú∞ÂùÄÔºå\nÂæÖ‰øÆÊîπ\nusers\n‰∏∫ËßÇÊºî‰∫∫ÁöÑÂßìÂêçÔºå\nËßÇÊºî‰∫∫ÈúÄË¶ÅÁî®Êà∑Âú®ÊâãÊú∫Â§ßÈ∫¶APP‰∏≠ÂÖàÂ°´ÂÜôÂ•ΩÔºåÁÑ∂ÂêéÂÜçÂ°´ÂÖ•ËØ•ÈÖçÁΩÆÊñá‰ª∂‰∏≠\nÔºå\nÂæÖ‰øÆÊîπ\ncity\n‰∏∫ÂüéÂ∏ÇÔºå\nÂ¶ÇÊûúÁî®Êà∑ÈúÄË¶ÅÊä¢ÁöÑÊºîÂî±‰ºöÁ•®ÈúÄË¶ÅÈÄâÊã©ÂüéÂ∏ÇÔºåËØ∑ÊääÂüéÂ∏ÇÂ°´ÂÖ•Ê≠§Â§Ñ„ÄÇÂ¶ÇÊó†ÈúÄÈÄâÊã©ÔºåÂàô‰∏çÂ°´\ndate\n‰∏∫Âú∫Ê¨°Êó•ÊúüÔºå\nÂæÖ‰øÆÊîπÔºåÂèØÂ§öÈÄâ\nprice\n‰∏∫Á•®Ê°£ÁöÑ‰ª∑Ê†ºÔºå\nÂæÖ‰øÆÊîπÔºåÂèØÂ§öÈÄâ\nif_commit_order\n‰∏∫ÊòØÂê¶Ë¶ÅËá™Âä®Êèê‰∫§ËÆ¢ÂçïÔºå\nÊîπÊàê true\nif_listen‰∏∫ÊòØÂê¶ÂõûÊµÅÁõëÂê¨Ôºå\nÊîπÊàêtrue\n2.2 Á§∫‰æãËØ¥Êòé\nËøõÂÖ•Â§ßÈ∫¶ÁΩë\nhttps://www.damai.cn/ÔºåÈÄâÊã©‰Ω†ÈúÄË¶ÅÊä¢Á•®ÁöÑÊºîÂî±‰ºö„ÄÇÂÅáËÆæÂ¶Ç‰∏ãÂõæÊâÄÁ§∫Ôºö\nÊé•‰∏ãÊù•ÊåâÁÖß‰∏ãÂõæÁöÑÊ†áÊ≥®ÂØπÈÖçÁΩÆÊñá‰ª∂ËøõË°å‰øÆÊîπÔºö\nÊúÄÁªà\nconfig.json\nÁöÑÊñá‰ª∂ÂÜÖÂÆπÂ¶Ç‰∏ãÔºö\n{\n\"index_url\"\n:\n\"\nhttps://www.damai.cn/\n\"\n,\n\"login_url\"\n:\n\"\nhttps://passport.damai.cn/login?ru=https%3A%2F%2Fwww.damai.cn%2F\n\"\n,\n\"target_url\"\n:\n\"\nhttps://detail.damai.cn/item.htm?spm=a2oeg.home.card_0.ditem_1.591b23e1JQGWHg&id=740680932762\n\"\n,\n\"users\"\n: [\n\"\nÂêçÂ≠ó1\n\"\n,\n\"\nÂêçÂ≠ó2\n\"\n],\n\"city\"\n:\n\"\nÂπøÂ∑û\n\"\n,\n\"date\"\n:\n\"\n2023-10-28\n\"\n,\n\"price\"\n:\n\"\n1039\n\"\n,\n\"if_listen\"\n:\ntrue\n,\n\"if_commit_order\"\n:\ntrue\n}\n3.ËøêË°åÁ®ãÂ∫è\nËøêË°åÁ®ãÂ∫èÂºÄÂßãÊä¢Á•®ÔºåËøõÂÖ•ÂëΩ‰ª§Á™óÂè£ÔºåÊâßË°åÂ¶Ç‰∏ãÂëΩ‰ª§Ôºö\ncd\ndamai\npython3 damai.py\nÂ§ßÈ∫¶appÊä¢Á•®\nÂ§ßÈ∫¶appÊä¢Á•®ËÑöÊú¨ÈúÄË¶Å‰æùËµñappiumÔºåÂõ†Ê≠§ÈúÄË¶ÅÁé∞Âú®ÂÆâË£Öappium server&clientÁéØÂ¢ÉÔºåÊ≠•È™§Â¶Ç‰∏ãÔºö\nappium server\n‰∏ãËΩΩ\nÂÖàÂÆâË£ÖÂ•ΩnodeÁéØÂ¢ÉÔºàÂÖ∑Â§ánpmÔºânodeÁâàÊú¨Âè∑18.0.0\nÂÖà‰∏ãËΩΩÂπ∂ÂÆâË£ÖÂ•Ωandroid sdkÔºåÂπ∂ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáèÔºàappium serverËøêË°åÈúÄ‰æùËµñandroid sdk)\n‰∏ãËΩΩappium\nnpm install -g appium\nÊü•ÁúãappiumÊòØÂê¶ÂÆâË£ÖÊàêÂäü\nappium -v\n‰∏ãËΩΩUiAutomator2È©±Âä®\nnpm install appium-uiautomator2-driver\n‚Äã\t\tÂèØËÉΩ‰ºöÈÅáÂà∞Â¶Ç‰∏ãÈîôËØØÔºö\n‚ûú  xcode git:(master) ‚úó npm install appium-uiautomator2-driver\n\nnpm ERR! code 1\nnpm ERR! path /Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/appium-chromedriver\nnpm ERR! command failed\nnpm ERR! command sh -c node install-npm.js\nnpm ERR! [11:57:54] Error installing Chromedriver: Request failed with status code 404\nnpm ERR! [11:57:54] AxiosError: Request failed with status code 404\nnpm ERR!     at settle (/Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/axios/lib/core/settle.js:19:12)\nnpm ERR!     at IncomingMessage.handleStreamEnd (/Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver/node_modules/axios/lib/adapters/http.js:572:11)\nnpm ERR!     at IncomingMessage.emit (node:events:539:35)\nnpm ERR!     at endReadableNT (node:internal/streams/readable:1344:12)\nnpm ERR!     at processTicksAndRejections (node:internal/process/task_queues:82:21)\nnpm ERR! [11:57:54] Downloading Chromedriver can be skipped by setting the'APPIUM_SKIP_CHROMEDRIVER_INSTALL' environment variable.\n\nnpm ERR! A complete log of this run can be found in:\nnpm ERR!     /Users/chenweicheng/.npm/_logs/2023-10-26T03_57_35_950Z-debug-0.log\n‚Äã\t\tËß£ÂÜ≥ÂäûÊ≥ïÔºàÊ∑ªÂä†ÁéØÂ¢ÉÂèòÈáèÔºåÈîôËØØÂéüÂõ†ÊòØÊ≤°ÊúâÊâæÂà∞chromeÊµèËßàÂô®È©±Âä®ÔºåÂøΩÁï•Âç≥ÂèØÔºâ\nexport\nAPPIUM_SKIP_CHROMEDRIVER_INSTALL=true\nÂêØÂä®\nÂêØÂä®appium serverÂπ∂‰ΩøÁî®uiautomator2È©±Âä®\nappium --use-plugins uiautomator2\nÂêØÂä®ÊàêÂäüÂ∞ÜÂá∫Áé∞Â¶Ç‰∏ã‰ø°ÊÅØÔºö\n[Appium] Welcome to Appium v2.2.1 (REV 2176894a5be5da17a362bf3f20678641a78f4b69)\n[Appium] Non-default server args:\n[Appium] {\n[Appium]   usePlugins: [\n[Appium]     'uiautomator2'\n[Appium]   ]\n[Appium] }\n[Appium] Attempting to load driver uiautomator2...\n[Appium] Requiring driver at /Users/chenweicheng/Documents/xcode/node_modules/appium-uiautomator2-driver\n[Appium] Appium REST http interface listener started on http://0.0.0.0:4723\n[Appium] You can provide the following URLs in your client code to connect to this server:\n[Appium] \thttp://127.0.0.1:4723/ (only accessible from the same host)\n[Appium] \thttp://172.31.102.45:4723/\n[Appium] \thttp://198.18.0.1:4723/\n[Appium] Available drivers:\n[Appium]   - uiautomator2@2.32.3 (automationName 'UiAutomator2')\n[Appium] No plugins have been installed. Use the \"appium plugin\" command to install the one(s) you want to use.\nÂÖ∂‰∏≠\n[Appium] \thttp://127.0.0.1:4723/ (only accessible from the same host) [Appium] \thttp://172.31.102.45:4723/ [Appium] \thttp://198.18.0.1:4723/\n‰∏∫appium serverËøûÊé•Âú∞ÂùÄ\nappium client\nÂÖà‰∏ãËΩΩÂπ∂ÂÆâË£ÖÂ•Ωpython3Âíåpip3\nÂÆâË£Ö\npip3 install appium-python-client\nÂú®‰ª£Á†Å‰∏≠ÂºïÂÖ•Âπ∂‰ΩøÁî®appium\nfrom\nappium\nimport\nwebdriver\nfrom\nappium\n.\noptions\n.\ncommon\n.\nbase\nimport\nAppiumOptions\ndevice_app_info\n=\nAppiumOptions\n()\ndevice_app_info\n.\nset_capability\n(\n'platformName'\n,\n'Android'\n)\ndevice_app_info\n.\nset_capability\n(\n'platformVersion'\n,\n'10'\n)\ndevice_app_info\n.\nset_capability\n(\n'deviceName'\n,\n'YourDeviceName'\n)\ndevice_app_info\n.\nset_capability\n(\n'appPackage'\n,\n'cn.damai'\n)\ndevice_app_info\n.\nset_capability\n(\n'appActivity'\n,\n'.launcher.splash.SplashMainActivity'\n)\ndevice_app_info\n.\nset_capability\n(\n'unicodeKeyboard'\n,\nTrue\n)\ndevice_app_info\n.\nset_capability\n(\n'resetKeyboard'\n,\nTrue\n)\ndevice_app_info\n.\nset_capability\n(\n'noReset'\n,\nTrue\n)\ndevice_app_info\n.\nset_capability\n(\n'newCommandTimeout'\n,\n6000\n)\ndevice_app_info\n.\nset_capability\n(\n'automationName'\n,\n'UiAutomator2'\n)\n# ËøûÊé•appium serverÔºåserverÂú∞ÂùÄÊü•ÁúãappiumÂêØÂä®‰ø°ÊÅØ\ndriver\n=\nwebdriver\n.\nRemote\n(\n'http://127.0.0.1:4723'\n,\noptions\n=\ndevice_app_info\n)\nÂêØÂä®ËÑöÊú¨Á®ãÂ∫è\ncd\ndamai_appium\npython3 damai_appium.py",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 70",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 4,347"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/WECENG/ticket-purchase"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/zed-industries/zed",
      "title": "zed-industries/zed",
      "date": null,
      "executive_summary": [
        "Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.",
        "---",
        "Zed\nWelcome to Zed, a high-performance, multiplayer code editor from the creators of\nAtom\nand\nTree-sitter\n.\nInstallation\nOn macOS and Linux you can\ndownload Zed directly\nor\ninstall Zed via your local package manager\n.\nOther platforms are not yet available:\nWindows (\ntracking issue\n)\nWeb (\ntracking issue\n)\nDeveloping Zed\nBuilding Zed for macOS\nBuilding Zed for Linux\nBuilding Zed for Windows\nRunning Collaboration Locally\nContributing\nSee\nCONTRIBUTING.md\nfor ways you can contribute to Zed.\nAlso... we're hiring! Check out our\njobs\npage for open roles.\nLicensing\nLicense information for third party dependencies must be correctly provided for CI to pass.\nWe use\ncargo-about\nto automatically comply with open source licenses. If CI is failing, check the following:\nIs it showing a\nno license specified\nerror for a crate you've created? If so, add\npublish = false\nunder\n[package]\nin your crate's Cargo.toml.\nIs the error\nfailed to satisfy license requirements\nfor a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license's requirements. If you're unsure, ask a lawyer. Once you've verified that this system is acceptable add the license's SPDX identifier to the\naccepted\narray in\nscript/licenses/zed-licenses.toml\n.\nIs\ncargo-about\nunable to find the license for a dependency? If so, add a clarification field at the end of\nscript/licenses/zed-licenses.toml\n, as specified in the\ncargo-about book\n.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 68",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 66,897"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/zed-industries/zed"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/rustdesk/rustdesk",
      "title": "rustdesk/rustdesk",
      "date": null,
      "executive_summary": [
        "An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.",
        "---",
        "Build\n‚Ä¢\nDocker\n‚Ä¢\nStructure\n‚Ä¢\nSnapshot\n[\n–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞\n] | [\nƒçesky\n] | [\n‰∏≠Êñá\n] | [\nMagyar\n] | [\nEspa√±ol\n] | [\nŸÅÿßÿ±ÿ≥€å\n] | [\nFran√ßais\n] | [\nDeutsch\n] | [\nPolski\n] | [\nIndonesian\n] | [\nSuomi\n] | [\n‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç\n] | [\nÊó•Êú¨Ë™û\n] | [\nNederlands\n] | [\nItaliano\n] | [\n–†—É—Å—Å–∫–∏–π\n] | [\nPortugu√™s (Brasil)\n] | [\nEsperanto\n] | [\nÌïúÍµ≠Ïñ¥\n] | [\nÿßŸÑÿπÿ±ÿ®Ÿä\n] | [\nTi·∫øng Vi·ªát\n] | [\nDansk\n] | [\nŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨\n] | [\nT√ºrk√ße\n] | [\nNorsk\n]\nWe need your help to translate this README,\nRustDesk UI\nand\nRustDesk Doc\nto your native language\nCaution\nMisuse Disclaimer:\nThe developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.\nChat with us:\nDiscord\n|\nTwitter\n|\nReddit\n|\nYouTube\nYet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server,\nset up your own\n, or\nwrite your own rendezvous/relay server\n.\nRustDesk welcomes contribution from everyone. See\nCONTRIBUTING.md\nfor help getting started.\nFAQ\nBINARY DOWNLOAD\nNIGHTLY BUILD\nDependencies\nDesktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our\nCI\nfor building Flutter version.\nPlease download Sciter dynamic library yourself.\nWindows\n|\nLinux\n|\nmacOS\nRaw Steps to build\nPrepare your Rust development env and C++ build env\nInstall\nvcpkg\n, and set\nVCPKG_ROOT\nenv variable correctly\nWindows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static\nLinux/macOS: vcpkg install libvpx libyuv opus aom\nrun\ncargo run\nBuild\nHow to Build on Linux\nUbuntu 18 (Debian 10)\nsudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \\\n        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \\\n        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev\nopenSUSE Tumbleweed\nsudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel\nFedora 28 (CentOS 8)\nsudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel\nArch (Manjaro)\nsudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire\nInstall vcpkg\ngit clone https://github.com/microsoft/vcpkg\ncd\nvcpkg\ngit checkout 2023.04.15\ncd\n..\nvcpkg/bootstrap-vcpkg.sh\nexport\nVCPKG_ROOT=\n$HOME\n/vcpkg\nvcpkg/vcpkg install libvpx libyuv opus aom\nFix libvpx (For Fedora)\ncd\nvcpkg/buildtrees/libvpx/src\ncd\n*\n./configure\nsed -i\n'\ns/CFLAGS+=-I/CFLAGS+=-fPIC -I/g\n'\nMakefile\nsed -i\n'\ns/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g\n'\nMakefile\nmake\ncp libvpx.a\n$HOME\n/vcpkg/installed/x64-linux/lib/\ncd\nBuild\ncurl --proto\n'\n=https\n'\n--tlsv1.2 -sSf https://sh.rustup.rs\n|\nsh\nsource\n$HOME\n/.cargo/env\ngit clone --recurse-submodules https://github.com/rustdesk/rustdesk\ncd\nrustdesk\nmkdir -p target/debug\nwget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so\nmv libsciter-gtk.so target/debug\nVCPKG_ROOT=\n$HOME\n/vcpkg cargo run\nHow to build with Docker\nBegin by cloning the repository and building the Docker container:\ngit clone https://github.com/rustdesk/rustdesk\ncd\nrustdesk\ngit submodule update --init --recursive\ndocker build -t\n\"\nrustdesk-builder\n\"\n.\nThen, each time you need to build the application, run the following command:\ndocker run --rm -it -v\n$PWD\n:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID=\n\"\n$(\nid -u\n)\n\"\n-e PGID=\n\"\n$(\nid -g\n)\n\"\nrustdesk-builder\nNote that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the\n<OPTIONAL-ARGS>\nposition. For instance, if you wanted to build an optimized release version, you would run the command above followed by\n--release\n. The resulting executable will be available in the target folder on your system, and can be run with:\ntarget/debug/rustdesk\nOr, if you're running a release executable:\ntarget/release/rustdesk\nPlease ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as\ninstall\nor\nrun\nare not currently supported via this method as they would install or run the program inside the container instead of the host.\nFile Structure\nlibs/hbb_common\n: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions\nlibs/scrap\n: screen capture\nlibs/enigo\n: platform specific keyboard/mouse control\nlibs/clipboard\n: file copy and paste implementation for Windows, Linux, macOS.\nsrc/ui\n: obsolete Sciter UI (deprecated)\nsrc/server\n: audio/clipboard/input/video services, and network connections\nsrc/client.rs\n: start a peer connection\nsrc/rendezvous_mediator.rs\n: Communicate with\nrustdesk-server\n, wait for remote direct (TCP hole punching) or relayed connection\nsrc/platform\n: platform specific code\nflutter\n: Flutter code for desktop and mobile\nflutter/web/js\n: JavaScript for Flutter web client\nScreenshots",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 67",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 99,567"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/rustdesk/rustdesk"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/samber/lo",
      "title": "samber/lo",
      "date": null,
      "executive_summary": [
        "üí• A Lodash-style Go library based on Go 1.18+ Generics (map, filter, contains, find...)",
        "---",
        "lo - Iterate over slices, maps, channels...\n‚ú®\nsamber/lo\nis a Lodash-style Go library based on Go 1.18+ Generics.\nA utility library based on Go 1.18+ generics that makes it easier to work with slices, maps, strings, channels, and functions. It provides dozens of handy methods to simplify common coding tasks and improve code readability. It may look like\nLodash\nin some aspects.\n5 to 10 helpers may overlap with those from the Go standard library, in packages\nslices\nand\nmaps\n. I feel this library is legitimate and offers many more valuable abstractions.\nSee also:\nsamber/do\n: A dependency injection toolkit based on Go 1.18+ Generics\nsamber/mo\n: Monads based on Go 1.18+ Generics (Option, Result, Either...)\nüíñ Support This Project\nI‚Äôm going all-in on open-source for the coming months.\nHelp sustain development: Become an\nindividual sponsor\nor join as a\ncorporate sponsor\n.\nWhy this name?\nI wanted a\nshort name\n, similar to \"Lodash\", and no Go package uses this name.\nüöÄ Install\ngo get github.com/samber/lo@v1\nThis library is v1 and follows SemVer strictly.\nNo breaking changes will be made to exported APIs before v2.0.0.\nThis library has no dependencies outside the Go standard library.\nüí° Usage\nYou can import\nlo\nusing:\nimport\n(\n\"github.com/samber/lo\"\nlop\n\"github.com/samber/lo/parallel\"\nlom\n\"github.com/samber/lo/mutable\"\nloi\n\"github.com/samber/lo/it\"\n)\nThen use one of the helpers below:\nnames\n:=\nlo\n.\nUniq\n([]\nstring\n{\n\"Samuel\"\n,\n\"John\"\n,\n\"Samuel\"\n})\n// []string{\"Samuel\", \"John\"}\nTips for lazy developers\nI cannot recommend it, but in case you are too lazy for repeating\nlo.\neverywhere, you can import the entire library into the namespace.\nimport\n(\n    .\n\"github.com/samber/lo\"\n)\nI take no responsibility for this junk. üòÅ üí©\nü§† Spec\nGoDoc:\ngodoc.org/github.com/samber/lo\nDocumentation:\nlo.samber.dev\nSupported helpers for slices:\nFilter\nMap\nUniqMap\nFilterMap\nFlatMap\nReduce\nReduceRight\nForEach\nForEachWhile\nTimes\nUniq\nUniqBy\nGroupBy\nGroupByMap\nChunk\nPartitionBy\nFlatten\nInterleave\nShuffle\nReverse\nFill\nRepeat\nRepeatBy\nKeyBy\nSliceToMap / Associate\nFilterSliceToMap\nKeyify\nDrop\nDropRight\nDropWhile\nDropRightWhile\nDropByIndex\nReject\nRejectMap\nFilterReject\nCount\nCountBy\nCountValues\nCountValuesBy\nSubset\nSlice\nReplace\nReplaceAll\nCompact\nIsSorted\nIsSortedByKey\nSplice\nCut\nCutPrefix\nCutSuffix\nTrim\nTrimLeft\nTrimPrefix\nTrimRight\nTrimSuffix\nSupported helpers for maps:\nKeys\nUniqKeys\nHasKey\nValueOr\nValues\nUniqValues\nPickBy\nPickByKeys\nPickByValues\nOmitBy\nOmitByKeys\nOmitByValues\nEntries / ToPairs\nFromEntries / FromPairs\nInvert\nAssign (merge of maps)\nChunkEntries\nMapKeys\nMapValues\nMapEntries\nMapToSlice\nFilterMapToSlice\nFilterKeys\nFilterValues\nSupported math helpers:\nRange / RangeFrom / RangeWithSteps\nClamp\nSum\nSumBy\nProduct\nProductBy\nMean\nMeanBy\nMode\nSupported helpers for strings:\nRandomString\nSubstring\nChunkString\nRuneLength\nPascalCase\nCamelCase\nKebabCase\nSnakeCase\nWords\nCapitalize\nEllipsis\nSupported helpers for tuples:\nT2 -> T9\nUnpack2 -> Unpack9\nZip2 -> Zip9\nZipBy2 -> ZipBy9\nUnzip2 -> Unzip9\nUnzipBy2 -> UnzipBy9\nCrossJoin2 -> CrossJoin2\nCrossJoinBy2 -> CrossJoinBy2\nSupported helpers for time and duration:\nDuration\nDuration0 -> Duration10\nSupported helpers for channels:\nChannelDispatcher\nSliceToChannel\nChannelToSlice\nGenerator\nBuffer\nBufferWithContext\nBufferWithTimeout\nFanIn\nFanOut\nSupported intersection helpers:\nContains\nContainsBy\nEvery\nEveryBy\nSome\nSomeBy\nNone\nNoneBy\nIntersect\nDifference\nUnion\nWithout\nWithoutBy\nWithoutEmpty\nWithoutNth\nElementsMatch\nElementsMatchBy\nSupported search helpers:\nIndexOf\nLastIndexOf\nHasPrefix\nHasSuffix\nFind\nFindIndexOf\nFindLastIndexOf\nFindOrElse\nFindKey\nFindKeyBy\nFindUniques\nFindUniquesBy\nFindDuplicates\nFindDuplicatesBy\nMin\nMinIndex\nMinBy\nMinIndexBy\nEarliest\nEarliestBy\nMax\nMaxIndex\nMaxBy\nMaxIndexBy\nLatest\nLatestBy\nFirst\nFirstOrEmpty\nFirstOr\nLast\nLastOrEmpty\nLastOr\nNth\nNthOr\nNthOrEmpty\nSample\nSampleBy\nSamples\nSamplesBy\nConditional helpers:\nTernary\nTernaryF\nIf / ElseIf / Else\nSwitch / Case / Default\nType manipulation helpers:\nIsNil\nIsNotNil\nToPtr\nNil\nEmptyableToPtr\nFromPtr\nFromPtrOr\nToSlicePtr\nFromSlicePtr\nFromSlicePtrOr\nToAnySlice\nFromAnySlice\nEmpty\nIsEmpty\nIsNotEmpty\nCoalesce\nCoalesceOrEmpty\nCoalesceSlice\nCoalesceSliceOrEmpty\nCoalesceMap\nCoalesceMapOrEmpty\nFunction helpers:\nPartial\nPartial2 -> Partial5\nConcurrency helpers:\nAttempt\nAttemptWhile\nAttemptWithDelay\nAttemptWhileWithDelay\nDebounce\nDebounceBy\nThrottle\nThrottleWithCount\nThrottleBy\nThrottleByWithCount\nSynchronize\nAsync\nAsync{0->6}\nTransaction\nWaitFor\nWaitForWithContext\nError handling:\nValidate\nMust\nTry\nTry1 -> Try6\nTryOr\nTryOr1 -> TryOr6\nTryCatch\nTryWithErrorValue\nTryCatchWithErrorValue\nErrorsAs\nAssert\nAssertf\nConstraints:\nClonable\nFilter\nIterates over a collection and returns a slice of all the elements the predicate function returns\ntrue\nfor.\neven\n:=\nlo\n.\nFilter\n([]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n},\nfunc\n(\nx\nint\n,\nindex\nint\n)\nbool\n{\nreturn\nx\n%\n2\n==\n0\n})\n// []int{2, 4}\n[\nplay\n]\nMutable: like\nlo.Filter()\n, but the slice is updated in place.\nimport\nlom\n\"github.com/samber/lo/mutable\"\nlist\n:=\n[]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n}\nnewList\n:=\nlom\n.\nFilter\n(\nlist\n,\nfunc\n(\nx\nint\n)\nbool\n{\nreturn\nx\n%\n2\n==\n0\n})\nlist\n// []int{2, 4, 3, 4}\nnewList\n// []int{2, 4}\nMap\nManipulates a slice of one type and transforms it into a slice of another type:\nimport\n\"github.com/samber/lo\"\nlo\n.\nMap\n([]\nint64\n{\n1\n,\n2\n,\n3\n,\n4\n},\nfunc\n(\nx\nint64\n,\nindex\nint\n)\nstring\n{\nreturn\nstrconv\n.\nFormatInt\n(\nx\n,\n10\n)\n})\n// []string{\"1\", \"2\", \"3\", \"4\"}\n[\nplay\n]\nParallel processing: like\nlo.Map()\n, but the mapper function is called in a goroutine. Results are returned in the same order.\nimport\nlop\n\"github.com/samber/lo/parallel\"\nlop\n.\nMap\n([]\nint64\n{\n1\n,\n2\n,\n3\n,\n4\n},\nfunc\n(\nx\nint64\n,\n_\nint\n)\nstring\n{\nreturn\nstrconv\n.\nFormatInt\n(\nx\n,\n10\n)\n})\n// []string{\"1\", \"2\", \"3\", \"4\"}\n[\nplay\n]\nMutable: like\nlo.Map()\n, but the slice is updated in place.\nimport\nlom\n\"github.com/samber/lo/mutable\"\nlist\n:=\n[]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n}\nlom\n.\nMap\n(\nlist\n,\nfunc\n(\nx\nint\n)\nint\n{\nreturn\nx\n*\n2\n})\n// []int{2, 4, 6, 8}\n[\nplay\n]\nUniqMap\nManipulates a slice and transforms it to a slice of another type with unique values.\ntype\nUser\nstruct\n{\nName\nstring\nAge\nint\n}\nusers\n:=\n[]\nUser\n{{\nName\n:\n\"Alex\"\n,\nAge\n:\n10\n}, {\nName\n:\n\"Alex\"\n,\nAge\n:\n12\n}, {\nName\n:\n\"Bob\"\n,\nAge\n:\n11\n}, {\nName\n:\n\"Alice\"\n,\nAge\n:\n20\n}}\nnames\n:=\nlo\n.\nUniqMap\n(\nusers\n,\nfunc\n(\nu\nUser\n,\nindex\nint\n)\nstring\n{\nreturn\nu\n.\nName\n})\n// []string{\"Alex\", \"Bob\", \"Alice\"}\n[\nplay\n]\nFilterMap\nReturns a slice obtained after both filtering and mapping using the given callback function.\nThe callback function should return two values: the result of the mapping operation and whether the result element should be included or not.\nmatching\n:=\nlo\n.\nFilterMap\n([]\nstring\n{\n\"cpu\"\n,\n\"gpu\"\n,\n\"mouse\"\n,\n\"keyboard\"\n},\nfunc\n(\nx\nstring\n,\n_\nint\n) (\nstring\n,\nbool\n) {\nif\nstrings\n.\nHasSuffix\n(\nx\n,\n\"pu\"\n) {\nreturn\n\"xpu\"\n,\ntrue\n}\nreturn\n\"\"\n,\nfalse\n})\n// []string{\"xpu\", \"xpu\"}\n[\nplay\n]\nFlatMap\nManipulates a slice and transforms and flattens it to a slice of another type. The transform function can either return a slice or a\nnil\n, and in the\nnil\ncase no value is added to the final slice.\nlo\n.\nFlatMap\n([]\nint64\n{\n0\n,\n1\n,\n2\n},\nfunc\n(\nx\nint64\n,\n_\nint\n) []\nstring\n{\nreturn\n[]\nstring\n{\nstrconv\n.\nFormatInt\n(\nx\n,\n10\n),\nstrconv\n.\nFormatInt\n(\nx\n,\n10\n),\n    }\n})\n// []string{\"0\", \"0\", \"1\", \"1\", \"2\", \"2\"}\n[\nplay\n]\nReduce\nReduces a collection to a single value. The value is calculated by accumulating the result of running each element in the collection through an accumulator function. Each successive invocation is supplied with the return value returned by the previous call.\nsum\n:=\nlo\n.\nReduce\n([]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n},\nfunc\n(\nagg\nint\n,\nitem\nint\n,\n_\nint\n)\nint\n{\nreturn\nagg\n+\nitem\n},\n0\n)\n// 10\n[\nplay\n]\nReduceRight\nLike\nlo.Reduce\nexcept that it iterates over elements of collection from right to left.\nresult\n:=\nlo\n.\nReduceRight\n([][]\nint\n{{\n0\n,\n1\n}, {\n2\n,\n3\n}, {\n4\n,\n5\n}},\nfunc\n(\nagg\n[]\nint\n,\nitem\n[]\nint\n,\n_\nint\n) []\nint\n{\nreturn\nappend\n(\nagg\n,\nitem\n...\n)\n}, []\nint\n{})\n// []int{4, 5, 2, 3, 0, 1}\n[\nplay\n]\nForEach\nIterates over elements of a collection and invokes the function over each element.\nimport\n\"github.com/samber/lo\"\nlo\n.\nForEach\n([]\nstring\n{\n\"hello\"\n,\n\"world\"\n},\nfunc\n(\nx\nstring\n,\n_\nint\n) {\nprintln\n(\nx\n)\n})\n// prints \"hello\\nworld\\n\"\n[\nplay\n]\nParallel processing: like\nlo.ForEach()\n, but the callback is called as a goroutine.\nimport\nlop\n\"github.com/samber/lo/parallel\"\nlop\n.\nForEach\n([]\nstring\n{\n\"hello\"\n,\n\"world\"\n},\nfunc\n(\nx\nstring\n,\n_\nint\n) {\nprintln\n(\nx\n)\n})\n// prints \"hello\\nworld\\n\" or \"world\\nhello\\n\"\nForEachWhile\nIterates over collection elements and invokes iteratee for each element collection return value decide to continue or break, like do while().\nlist\n:=\n[]\nint64\n{\n1\n,\n2\n,\n-\n42\n,\n4\n}\nlo\n.\nForEachWhile\n(\nlist\n,\nfunc\n(\nx\nint64\n,\n_\nint\n)\nbool\n{\nif\nx\n<\n0\n{\nreturn\nfalse\n}\nfmt\n.\nPrintln\n(\nx\n)\nreturn\ntrue\n})\n// 1\n// 2\n[\nplay\n]\nTimes\nTimes invokes the iteratee n times, returning a slice of the results of each invocation. The iteratee is invoked with index as argument.\nimport\n\"github.com/samber/lo\"\nlo\n.\nTimes\n(\n3\n,\nfunc\n(\ni\nint\n)\nstring\n{\nreturn\nstrconv\n.\nFormatInt\n(\nint64\n(\ni\n),\n10\n)\n})\n// []string{\"0\", \"1\", \"2\"}\n[\nplay\n]\nParallel processing: like\nlo.Times()\n, but callback is called in goroutine.\nimport\nlop\n\"github.com/samber/lo/parallel\"\nlop\n.\nTimes\n(\n3\n,\nfunc\n(\ni\nint\n)\nstring\n{\nreturn\nstrconv\n.\nFormatInt\n(\nint64\n(\ni\n),\n10\n)\n})\n// []string{\"0\", \"1\", \"2\"}\nUniq\nReturns a duplicate-free version of a slice, in which only the first occurrence of each element is kept. The order of result values is determined by the order they occur in the slice.\nuniqValues\n:=\nlo\n.\nUniq\n([]\nint\n{\n1\n,\n2\n,\n2\n,\n1\n})\n// []int{1, 2}\n[\nplay\n]\nUniqBy\nReturns a duplicate-free version of a slice, in which only the first occurrence of each element is kept. The order of result values is determined by the order they occur in the slice. It accepts\niteratee\nwhich is invoked for each element in the slice to generate the criterion by which uniqueness is computed.\nuniqValues\n:=\nlo\n.\nUniqBy\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n},\nfunc\n(\ni\nint\n)\nint\n{\nreturn\ni\n%\n3\n})\n// []int{0, 1, 2}\n[\nplay\n]\nGroupBy\nReturns an object composed of keys generated from the results of running each element of collection through iteratee.\nimport\nlo\n\"github.com/samber/lo\"\ngroups\n:=\nlo\n.\nGroupBy\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n},\nfunc\n(\ni\nint\n)\nint\n{\nreturn\ni\n%\n3\n})\n// map[int][]int{0: []int{0, 3}, 1: []int{1, 4}, 2: []int{2, 5}}\n[\nplay\n]\nParallel processing: like\nlo.GroupBy()\n, but callback is called in goroutine.\nimport\nlop\n\"github.com/samber/lo/parallel\"\nlop\n.\nGroupBy\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n},\nfunc\n(\ni\nint\n)\nint\n{\nreturn\ni\n%\n3\n})\n// map[int][]int{0: []int{0, 3}, 1: []int{1, 4}, 2: []int{2, 5}}\nGroupByMap\nReturns an object composed of keys generated from the results of running each element of collection through iteratee.\nimport\nlo\n\"github.com/samber/lo\"\ngroups\n:=\nlo\n.\nGroupByMap\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n},\nfunc\n(\ni\nint\n) (\nint\n,\nint\n) {\nreturn\ni\n%\n3\n,\ni\n*\n2\n})\n// map[int][]int{0: []int{0, 6}, 1: []int{2, 8}, 2: []int{4, 10}}\n[\nplay\n]\nChunk\nReturns a slice of elements split into groups of length size. If the slice can't be split evenly, the final chunk will be the remaining elements.\nlo\n.\nChunk\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n},\n2\n)\n// [][]int{{0, 1}, {2, 3}, {4, 5}}\nlo\n.\nChunk\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n,\n6\n},\n2\n)\n// [][]int{{0, 1}, {2, 3}, {4, 5}, {6}}\nlo\n.\nChunk\n([]\nint\n{},\n2\n)\n// [][]int{}\nlo\n.\nChunk\n([]\nint\n{\n0\n},\n2\n)\n// [][]int{{0}}\n[\nplay\n]\nPartitionBy\nReturns a slice of elements split into groups. The order of grouped values is determined by the order they occur in collection. The grouping is generated from the results of running each element of collection through iteratee.\nimport\nlo\n\"github.com/samber/lo\"\npartitions\n:=\nlo\n.\nPartitionBy\n([]\nint\n{\n-\n2\n,\n-\n1\n,\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n},\nfunc\n(\nx\nint\n)\nstring\n{\nif\nx\n<\n0\n{\nreturn\n\"negative\"\n}\nelse\nif\nx\n%\n2\n==\n0\n{\nreturn\n\"even\"\n}\nreturn\n\"odd\"\n})\n// [][]int{{-2, -1}, {0, 2, 4}, {1, 3, 5}}\n[\nplay\n]\nParallel processing: like\nlo.PartitionBy()\n, but callback is called in goroutine. Results are returned in the same order.\nimport\nlop\n\"github.com/samber/lo/parallel\"\npartitions\n:=\nlop\n.\nPartitionBy\n([]\nint\n{\n-\n2\n,\n-\n1\n,\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n},\nfunc\n(\nx\nint\n)\nstring\n{\nif\nx\n<\n0\n{\nreturn\n\"negative\"\n}\nelse\nif\nx\n%\n2\n==\n0\n{\nreturn\n\"even\"\n}\nreturn\n\"odd\"\n})\n// [][]int{{-2, -1}, {0, 2, 4}, {1, 3, 5}}\nFlatten\nReturns a slice a single level deep.\nflat\n:=\nlo\n.\nFlatten\n([][]\nint\n{{\n0\n,\n1\n}, {\n2\n,\n3\n,\n4\n,\n5\n}})\n// []int{0, 1, 2, 3, 4, 5}\n[\nplay\n]\nInterleave\nRound-robin alternating input slices and sequentially appending value at index into result.\ninterleaved\n:=\nlo\n.\nInterleave\n([]\nint\n{\n1\n,\n4\n,\n7\n}, []\nint\n{\n2\n,\n5\n,\n8\n}, []\nint\n{\n3\n,\n6\n,\n9\n})\n// []int{1, 2, 3, 4, 5, 6, 7, 8, 9}\ninterleaved\n:=\nlo\n.\nInterleave\n([]\nint\n{\n1\n}, []\nint\n{\n2\n,\n5\n,\n8\n}, []\nint\n{\n3\n,\n6\n}, []\nint\n{\n4\n,\n7\n,\n9\n,\n10\n})\n// []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n[\nplay\n]\nShuffle\nReturns a slice of shuffled values. Uses the Fisher-Yates shuffle algorithm.\n‚ö†Ô∏è\nThis helper is\nmutable\n.\nimport\nlom\n\"github.com/samber/lo/mutable\"\nlist\n:=\n[]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}\nlom\n.\nShuffle\n(\nlist\n)\nlist\n// []int{1, 4, 0, 3, 5, 2}\n[\nplay\n]\nReverse\nReverses a slice so that the first element becomes the last, the second element becomes the second to last, and so on.\n‚ö†Ô∏è\nThis helper is\nmutable\n.\nimport\nlom\n\"github.com/samber/lo/mutable\"\nlist\n:=\n[]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}\nlom\n.\nReverse\n(\nlist\n)\nlist\n// []int{5, 4, 3, 2, 1, 0}\n[\nplay\n]\nFill\nFills elements of a slice with\ninitial\nvalue.\ntype\nfoo\nstruct\n{\nbar\nstring\n}\nfunc\n(\nf\nfoo\n)\nClone\n()\nfoo\n{\nreturn\nfoo\n{\nf\n.\nbar\n}\n}\ninitializedSlice\n:=\nlo\n.\nFill\n([]\nfoo\n{\nfoo\n{\n\"a\"\n},\nfoo\n{\n\"a\"\n}},\nfoo\n{\n\"b\"\n})\n// []foo{foo{\"b\"}, foo{\"b\"}}\n[\nplay\n]\nRepeat\nBuilds a slice with N copies of initial value.\ntype\nfoo\nstruct\n{\nbar\nstring\n}\nfunc\n(\nf\nfoo\n)\nClone\n()\nfoo\n{\nreturn\nfoo\n{\nf\n.\nbar\n}\n}\nslice\n:=\nlo\n.\nRepeat\n(\n2\n,\nfoo\n{\n\"a\"\n})\n// []foo{foo{\"a\"}, foo{\"a\"}}\n[\nplay\n]\nRepeatBy\nBuilds a slice with values returned by N calls of callback.\nslice\n:=\nlo\n.\nRepeatBy\n(\n0\n,\nfunc\n(\ni\nint\n)\nstring\n{\nreturn\nstrconv\n.\nFormatInt\n(\nint64\n(\nmath\n.\nPow\n(\nfloat64\n(\ni\n),\n2\n)),\n10\n)\n})\n// []string{}\nslice\n:=\nlo\n.\nRepeatBy\n(\n5\n,\nfunc\n(\ni\nint\n)\nstring\n{\nreturn\nstrconv\n.\nFormatInt\n(\nint64\n(\nmath\n.\nPow\n(\nfloat64\n(\ni\n),\n2\n)),\n10\n)\n})\n// []string{\"0\", \"1\", \"4\", \"9\", \"16\"}\n[\nplay\n]\nKeyBy\nTransforms a slice or a slice of structs to a map based on a pivot callback.\nm\n:=\nlo\n.\nKeyBy\n([]\nstring\n{\n\"a\"\n,\n\"aa\"\n,\n\"aaa\"\n},\nfunc\n(\nstr\nstring\n)\nint\n{\nreturn\nlen\n(\nstr\n)\n})\n// map[int]string{1: \"a\", 2: \"aa\", 3: \"aaa\"}\ntype\nCharacter\nstruct\n{\ndir\nstring\ncode\nint\n}\ncharacters\n:=\n[]\nCharacter\n{\n    {\ndir\n:\n\"left\"\n,\ncode\n:\n97\n},\n    {\ndir\n:\n\"right\"\n,\ncode\n:\n100\n},\n}\nresult\n:=\nlo\n.\nKeyBy\n(\ncharacters\n,\nfunc\n(\nchar\nCharacter\n)\nstring\n{\nreturn\nstring\n(\nrune\n(\nchar\n.\ncode\n))\n})\n//map[a:{dir:left code:97} d:{dir:right code:100}]\n[\nplay\n]\nSliceToMap (alias: Associate)\nReturns a map containing key-value pairs provided by transform function applied to elements of the given slice.\nIf any of two pairs have the same key the last one gets added to the map.\nThe order of keys in returned map is not specified and is not guaranteed to be the same from the original slice.\nin\n:=\n[]\n*\nfoo\n{{\nbaz\n:\n\"apple\"\n,\nbar\n:\n1\n}, {\nbaz\n:\n\"banana\"\n,\nbar\n:\n2\n}}\naMap\n:=\nlo\n.\nSliceToMap\n(\nin\n,\nfunc\n(\nf\n*\nfoo\n) (\nstring\n,\nint\n) {\nreturn\nf\n.\nbaz\n,\nf\n.\nbar\n})\n// map[string][int]{ \"apple\":1, \"banana\":2 }\n[\nplay\n]\nFilterSliceToMap\nReturns a map containing key-value pairs provided by transform function applied to elements of the given slice.\nIf any of two pairs have the same key the last one gets added to the map.\nThe order of keys in returned map is not specified and is not guaranteed to be the same from the original slice.\nThe third return value of the transform function is a boolean that indicates whether the key-value pair should be included in the map.\nlist\n:=\n[]\nstring\n{\n\"a\"\n,\n\"aa\"\n,\n\"aaa\"\n}\nresult\n:=\nlo\n.\nFilterSliceToMap\n(\nlist\n,\nfunc\n(\nstr\nstring\n) (\nstring\n,\nint\n,\nbool\n) {\nreturn\nstr\n,\nlen\n(\nstr\n),\nlen\n(\nstr\n)\n>\n1\n})\n// map[string][int]{\"aa\":2 \"aaa\":3}\n[\nplay\n]\nKeyify\nReturns a map with each unique element of the slice as a key.\nset\n:=\nlo\n.\nKeyify\n([]\nint\n{\n1\n,\n1\n,\n2\n,\n3\n,\n4\n})\n// map[int]struct{}{1:{}, 2:{}, 3:{}, 4:{}}\n[\nplay\n]\nDrop\nDrops n elements from the beginning of a slice.\nl\n:=\nlo\n.\nDrop\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n},\n2\n)\n// []int{2, 3, 4, 5}\n[\nplay\n]\nDropRight\nDrops n elements from the end of a slice.\nl\n:=\nlo\n.\nDropRight\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n},\n2\n)\n// []int{0, 1, 2, 3}\n[\nplay\n]\nDropWhile\nDrop elements from the beginning of a slice while the predicate returns true.\nl\n:=\nlo\n.\nDropWhile\n([]\nstring\n{\n\"a\"\n,\n\"aa\"\n,\n\"aaa\"\n,\n\"aa\"\n,\n\"aa\"\n},\nfunc\n(\nval\nstring\n)\nbool\n{\nreturn\nlen\n(\nval\n)\n<=\n2\n})\n// []string{\"aaa\", \"aa\", \"aa\"}\n[\nplay\n]\nDropRightWhile\nDrop elements from the end of a slice while the predicate returns true.\nl\n:=\nlo\n.\nDropRightWhile\n([]\nstring\n{\n\"a\"\n,\n\"aa\"\n,\n\"aaa\"\n,\n\"aa\"\n,\n\"aa\"\n},\nfunc\n(\nval\nstring\n)\nbool\n{\nreturn\nlen\n(\nval\n)\n<=\n2\n})\n// []string{\"a\", \"aa\", \"aaa\"}\n[\nplay\n]\nDropByIndex\nDrops elements from a slice by the index. A negative index will drop elements from the end of the slice.\nl\n:=\nlo\n.\nDropByIndex\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n},\n2\n,\n4\n,\n-\n1\n)\n// []int{0, 1, 3}\n[\nplay\n]\nReject\nThe opposite of Filter, this method returns the elements of collection that predicate does not return true for.\nodd\n:=\nlo\n.\nReject\n([]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n},\nfunc\n(\nx\nint\n,\n_\nint\n)\nbool\n{\nreturn\nx\n%\n2\n==\n0\n})\n// []int{1, 3}\n[\nplay\n]\nRejectMap\nThe opposite of FilterMap, this method returns a slice obtained after both filtering and mapping using the given callback function.\nThe callback function should return two values:\nthe result of the mapping operation and\nwhether the result element should be included or not.\nitems\n:=\nlo\n.\nRejectMap\n([]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n},\nfunc\n(\nx\nint\n,\n_\nint\n) (\nint\n,\nbool\n) {\nreturn\nx\n*\n10\n,\nx\n%\n2\n==\n0\n})\n// []int{10, 30}\nFilterReject\nMixes Filter and Reject, this method returns two slices, one for the elements of collection that predicate returns true for and one for the elements that predicate does not return true for.\nkept\n,\nrejected\n:=\nlo\n.\nFilterReject\n([]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n},\nfunc\n(\nx\nint\n,\n_\nint\n)\nbool\n{\nreturn\nx\n%\n2\n==\n0\n})\n// []int{2, 4}\n// []int{1, 3}\nCount\nCounts the number of elements in the collection that equal value.\ncount\n:=\nlo\n.\nCount\n([]\nint\n{\n1\n,\n5\n,\n1\n},\n1\n)\n// 2\n[\nplay\n]\nCountBy\nCounts the number of elements in the collection for which predicate is true.\ncount\n:=\nlo\n.\nCountBy\n([]\nint\n{\n1\n,\n5\n,\n1\n},\nfunc\n(\ni\nint\n)\nbool\n{\nreturn\ni\n<\n4\n})\n// 2\n[\nplay\n]\nCountValues\nCounts the number of each element in the collection.\nlo\n.\nCountValues\n([]\nint\n{})\n// map[int]int{}\nlo\n.\nCountValues\n([]\nint\n{\n1\n,\n2\n})\n// map[int]int{1: 1, 2: 1}\nlo\n.\nCountValues\n([]\nint\n{\n1\n,\n2\n,\n2\n})\n// map[int]int{1: 1, 2: 2}\nlo\n.\nCountValues\n([]\nstring\n{\n\"foo\"\n,\n\"bar\"\n,\n\"\"\n})\n// map[string]int{\"\": 1, \"foo\": 1, \"bar\": 1}\nlo\n.\nCountValues\n([]\nstring\n{\n\"foo\"\n,\n\"bar\"\n,\n\"bar\"\n})\n// map[string]int{\"foo\": 1, \"bar\": 2}\n[\nplay\n]\nCountValuesBy\nCounts the number of each element in the collection. It is equivalent to chaining lo.Map and lo.CountValues.\nisEven\n:=\nfunc\n(\nv\nint\n)\nbool\n{\nreturn\nv\n%\n2\n==\n0\n}\nlo\n.\nCountValuesBy\n([]\nint\n{},\nisEven\n)\n// map[bool]int{}\nlo\n.\nCountValuesBy\n([]\nint\n{\n1\n,\n2\n},\nisEven\n)\n// map[bool]int{false: 1, true: 1}\nlo\n.\nCountValuesBy\n([]\nint\n{\n1\n,\n2\n,\n2\n},\nisEven\n)\n// map[bool]int{false: 1, true: 2}\nlength\n:=\nfunc\n(\nv\nstring\n)\nint\n{\nreturn\nlen\n(\nv\n)\n}\nlo\n.\nCountValuesBy\n([]\nstring\n{\n\"foo\"\n,\n\"bar\"\n,\n\"\"\n},\nlength\n)\n// map[int]int{0: 1, 3: 2}\nlo\n.\nCountValuesBy\n([]\nstring\n{\n\"foo\"\n,\n\"bar\"\n,\n\"bar\"\n},\nlength\n)\n// map[int]int{3: 3}\n[\nplay\n]\nSubset\nReturns a copy of a slice from\noffset\nup to\nlength\nelements. Like\nslice[start:start+length]\n, but does not panic on overflow.\nin\n:=\n[]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n}\nsub\n:=\nlo\n.\nSubset\n(\nin\n,\n2\n,\n3\n)\n// []int{2, 3, 4}\nsub\n:=\nlo\n.\nSubset\n(\nin\n,\n-\n4\n,\n3\n)\n// []int{1, 2, 3}\nsub\n:=\nlo\n.\nSubset\n(\nin\n,\n-\n2\n,\nmath\n.\nMaxUint\n)\n// []int{3, 4}\n[\nplay\n]\nSlice\nReturns a copy of a slice from\nstart\nup to, but not including\nend\n. Like\nslice[start:end]\n, but does not panic on overflow.\nin\n:=\n[]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n}\nslice\n:=\nlo\n.\nSlice\n(\nin\n,\n0\n,\n5\n)\n// []int{0, 1, 2, 3, 4}\nslice\n:=\nlo\n.\nSlice\n(\nin\n,\n2\n,\n3\n)\n// []int{2}\nslice\n:=\nlo\n.\nSlice\n(\nin\n,\n2\n,\n6\n)\n// []int{2, 3, 4}\nslice\n:=\nlo\n.\nSlice\n(\nin\n,\n4\n,\n3\n)\n// []int{}\n[\nplay\n]\nReplace\nReturns a copy of the slice with the first n non-overlapping instances of old replaced by new.\nin\n:=\n[]\nint\n{\n0\n,\n1\n,\n0\n,\n1\n,\n2\n,\n3\n,\n0\n}\nslice\n:=\nlo\n.\nReplace\n(\nin\n,\n0\n,\n42\n,\n1\n)\n// []int{42, 1, 0, 1, 2, 3, 0}\nslice\n:=\nlo\n.\nReplace\n(\nin\n,\n-\n1\n,\n42\n,\n1\n)\n// []int{0, 1, 0, 1, 2, 3, 0}\nslice\n:=\nlo\n.\nReplace\n(\nin\n,\n0\n,\n42\n,\n2\n)\n// []int{42, 1, 42, 1, 2, 3, 0}\nslice\n:=\nlo\n.\nReplace\n(\nin\n,\n0\n,\n42\n,\n-\n1\n)\n// []int{42, 1, 42, 1, 2, 3, 42}\n[\nplay\n]\nReplaceAll\nReturns a copy of the slice with all non-overlapping instances of old replaced by new.\nin\n:=\n[]\nint\n{\n0\n,\n1\n,\n0\n,\n1\n,\n2\n,\n3\n,\n0\n}\nslice\n:=\nlo\n.\nReplaceAll\n(\nin\n,\n0\n,\n42\n)\n// []int{42, 1, 42, 1, 2, 3, 42}\nslice\n:=\nlo\n.\nReplaceAll\n(\nin\n,\n-\n1\n,\n42\n)\n// []int{0, 1, 0, 1, 2, 3, 0}\n[\nplay\n]\nCompact\nReturns a slice of all non-zero elements.\nin\n:=\n[]\nstring\n{\n\"\"\n,\n\"foo\"\n,\n\"\"\n,\n\"bar\"\n,\n\"\"\n}\nslice\n:=\nlo\n.\nCompact\n(\nin\n)\n// []string{\"foo\", \"bar\"}\n[\nplay\n]\nIsSorted\nChecks if a slice is sorted.\nslice\n:=\nlo\n.\nIsSorted\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n,\n6\n,\n7\n,\n8\n,\n9\n})\n// true\n[\nplay\n]\nIsSortedByKey\nChecks if a slice is sorted by iteratee.\nslice\n:=\nlo\n.\nIsSortedByKey\n([]\nstring\n{\n\"a\"\n,\n\"bb\"\n,\n\"ccc\"\n},\nfunc\n(\ns\nstring\n)\nint\n{\nreturn\nlen\n(\ns\n)\n})\n// true\n[\nplay\n]\nSplice\nSplice inserts multiple elements at index i. A negative index counts back from the end of the slice. The helper is protected against overflow errors.\nresult\n:=\nlo\n.\nSplice\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n},\n1\n,\n\"1\"\n,\n\"2\"\n)\n// []string{\"a\", \"1\", \"2\", \"b\"}\n// negative\nresult\n=\nlo\n.\nSplice\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n},\n-\n1\n,\n\"1\"\n,\n\"2\"\n)\n// []string{\"a\", \"1\", \"2\", \"b\"}\n// overflow\nresult\n=\nlo\n.\nSplice\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n},\n42\n,\n\"1\"\n,\n\"2\"\n)\n// []string{\"a\", \"b\", \"1\", \"2\"}\n[\nplay\n]\nCut\nSlices collection around the first instance of separator, returning the part of collection before and after separator. The found result reports whether separator appears in collection. If separator does not appear in s, cut returns collection, empty slice of []T, false.\nactualLeft\n,\nactualRight\n,\nresult\n=\nlo\n.\nCut\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n,\n\"d\"\n,\n\"e\"\n,\n\"f\"\n,\n\"g\"\n}, []\nstring\n{\n\"b\"\n,\n\"c\"\n,\n\"d\"\n})\n// actualLeft: []string{\"a\"}\n// actualRight: []string{\"e\", \"f\", \"g\"}\n// result: true\nresult\n=\nlo\n.\nCut\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n,\n\"d\"\n,\n\"e\"\n,\n\"f\"\n,\n\"g\"\n}, []\nstring\n{\n\"z\"\n})\n// actualLeft: []string{\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"}\n// actualRight: []string{}\n// result: false\nresult\n=\nlo\n.\nCut\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n,\n\"d\"\n,\n\"e\"\n,\n\"f\"\n,\n\"g\"\n}, []\nstring\n{\n\"a\"\n,\n\"b\"\n})\n// actualLeft: []string{}\n// actualRight: []string{\"c\", \"d\", \"e\", \"f\", \"g\"}\n// result: true\n[\nplay\n]\nCutPrefix\nReturns collection without the provided leading prefix []T and reports whether it found the prefix. If s doesn't start with prefix, CutPrefix returns collection, false. If prefix is the empty []T, CutPrefix returns collection, true.\nactualRight\n,\nresult\n=\nlo\n.\nCutPrefix\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n,\n\"d\"\n,\n\"e\"\n,\n\"f\"\n,\n\"g\"\n}, []\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n})\n// actualRight: []string{\"d\", \"e\", \"f\", \"g\"}\n// result: true\nresult\n=\nlo\n.\nCutPrefix\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n,\n\"d\"\n,\n\"e\"\n,\n\"f\"\n,\n\"g\"\n}, []\nstring\n{\n\"b\"\n})\n// actualRight: []string{\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"}\n// result: false\nresult\n=\nlo\n.\nCutPrefix\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n,\n\"d\"\n,\n\"e\"\n,\n\"f\"\n,\n\"g\"\n}, []\nstring\n{})\n// actualRight: []string{\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"}\n// result: true\n[\nplay\n]\nCutSuffix\nReturns collection without the provided ending suffix []T and reports whether it found the suffix. If it doesn't end with suffix, CutSuffix returns collection, false. If suffix is the empty []T, CutSuffix returns collection, true.\nactualLeft\n,\nresult\n=\nlo\n.\nCutSuffix\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n,\n\"d\"\n,\n\"e\"\n,\n\"f\"\n,\n\"g\"\n}, []\nstring\n{\n\"f\"\n,\n\"g\"\n})\n// actualLeft: []string{\"a\", \"b\", \"c\", \"d\", \"e\"}\n// result: true\nactualLeft\n,\nresult\n=\nlo\n.\nCutSuffix\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n,\n\"d\"\n,\n\"e\"\n,\n\"f\"\n,\n\"g\"\n}, []\nstring\n{\n\"b\"\n})\n// actualLeft: []string{\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"}\n// result: false\nactualLeft\n,\nresult\n=\nlo\n.\nCutSuffix\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n,\n\"d\"\n,\n\"e\"\n,\n\"f\"\n,\n\"g\"\n}, []\nstring\n{})\n// actualLeft: []string{\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"}\n// result: true\n[\nplay\n]\nTrim\nRemoves all the leading and trailing cutset from the collection.\nresult\n:=\nlo\n.\nTrim\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n0\n,\n3\n,\n0\n}, []\nint\n{\n1\n,\n0\n})\n// []int{2, 0, 3}\nresult\n:=\nlo\n.\nTrim\n([]\nstring\n{\n\"hello\"\n,\n\"world\"\n,\n\" \"\n}, []\nstring\n{\n\" \"\n,\n\"\"\n})\n// []string{\"hello\", \"world\"}\n[\nplay\n]\nTrimLeft\nRemoves all the leading cutset from the collection.\nresult\n:=\nlo\n.\nTrimLeft\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n0\n,\n3\n,\n0\n}, []\nint\n{\n1\n,\n0\n})\n// []int{2, 0, 3, 0}\nresult\n:=\nlo\n.\nTrimLeft\n([]\nstring\n{\n\"hello\"\n,\n\"world\"\n,\n\" \"\n}, []\nstring\n{\n\" \"\n,\n\"\"\n})\n// []string{\"hello\", \"world\", \" \"}\n[\nplay\n]\nTrimPrefix\nRemoves all the leading prefix from the collection.\nresult\n:=\nlo\n.\nTrimPrefix\n([]\nint\n{\n1\n,\n2\n,\n1\n,\n2\n,\n3\n,\n1\n,\n2\n,\n4\n}, []\nint\n{\n1\n,\n2\n})\n// []int{3, 1, 2, 4}\nresult\n:=\nlo\n.\nTrimPrefix\n([]\nstring\n{\n\"hello\"\n,\n\"world\"\n,\n\"hello\"\n,\n\"test\"\n}, []\nstring\n{\n\"hello\"\n})\n// []string{\"world\", \"hello\", \"test\"}\n[\nplay\n]\nTrimRight\nRemoves all the trailing cutset from the collection.\nresult\n:=\nlo\n.\nTrimRight\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n0\n,\n3\n,\n0\n}, []\nint\n{\n0\n,\n3\n})\n// []int{0, 1, 2}\nresult\n:=\nlo\n.\nTrimRight\n([]\nstring\n{\n\"hello\"\n,\n\"world\"\n,\n\"  \"\n}, []\nstring\n{\n\" \"\n,\n\"\"\n})\n// []string{\"hello\", \"world\", \"\"}\n[\nplay\n]\nTrimSuffix\nRemoves all the trailing suffix from the collection.\nresult\n:=\nlo\n.\nTrimSuffix\n([]\nint\n{\n1\n,\n2\n,\n3\n,\n1\n,\n2\n,\n4\n,\n2\n,\n4\n,\n2\n,\n4\n}, []\nint\n{\n2\n,\n4\n})\n// []int{1, 2, 3, 1}\nresult\n:=\nlo\n.\nTrimSuffix\n([]\nstring\n{\n\"hello\"\n,\n\"world\"\n,\n\"hello\"\n,\n\"test\"\n}, []\nstring\n{\n\"test\"\n})\n// []string{\"hello\", \"world\", \"hello\"}\n[\nplay\n]\nKeys\nCreates a slice of the map keys.\nUse the UniqKeys variant to deduplicate common keys.\nkeys\n:=\nlo\n.\nKeys\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n})\n// []string{\"foo\", \"bar\"}\nkeys\n:=\nlo\n.\nKeys\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n},\nmap\n[\nstring\n]\nint\n{\n\"baz\"\n:\n3\n})\n// []string{\"foo\", \"bar\", \"baz\"}\nkeys\n:=\nlo\n.\nKeys\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n},\nmap\n[\nstring\n]\nint\n{\n\"bar\"\n:\n3\n})\n// []string{\"foo\", \"bar\", \"bar\"}\n[\nplay\n]\nUniqKeys\nCreates a slice of unique map keys.\nkeys\n:=\nlo\n.\nUniqKeys\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n},\nmap\n[\nstring\n]\nint\n{\n\"baz\"\n:\n3\n})\n// []string{\"foo\", \"bar\", \"baz\"}\nkeys\n:=\nlo\n.\nUniqKeys\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n},\nmap\n[\nstring\n]\nint\n{\n\"bar\"\n:\n3\n})\n// []string{\"foo\", \"bar\"}\n[\nplay\n]\nHasKey\nReturns whether the given key exists.\nexists\n:=\nlo\n.\nHasKey\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n},\n\"foo\"\n)\n// true\nexists\n:=\nlo\n.\nHasKey\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n},\n\"baz\"\n)\n// false\n[\nplay\n]\nValues\nCreates a slice of the map values.\nUse the UniqValues variant to deduplicate common values.\nvalues\n:=\nlo\n.\nValues\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n})\n// []int{1, 2}\nvalues\n:=\nlo\n.\nValues\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n},\nmap\n[\nstring\n]\nint\n{\n\"baz\"\n:\n3\n})\n// []int{1, 2, 3}\nvalues\n:=\nlo\n.\nValues\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n},\nmap\n[\nstring\n]\nint\n{\n\"bar\"\n:\n2\n})\n// []int{1, 2, 2}\n[\nplay\n]\nUniqValues\nCreates a slice of unique map values.\nvalues\n:=\nlo\n.\nUniqValues\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n})\n// []int{1, 2}\nvalues\n:=\nlo\n.\nUniqValues\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n},\nmap\n[\nstring\n]\nint\n{\n\"baz\"\n:\n3\n})\n// []int{1, 2, 3}\nvalues\n:=\nlo\n.\nUniqValues\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n},\nmap\n[\nstring\n]\nint\n{\n\"bar\"\n:\n2\n})\n// []int{1, 2}\n[\nplay\n]\nValueOr\nReturns the value of the given key or the fallback value if the key is not present.\nvalue\n:=\nlo\n.\nValueOr\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n},\n\"foo\"\n,\n42\n)\n// 1\nvalue\n:=\nlo\n.\nValueOr\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n},\n\"baz\"\n,\n42\n)\n// 42\n[\nplay\n]\nPickBy\nReturns same map type filtered by given predicate.\nm\n:=\nlo\n.\nPickBy\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n,\n\"baz\"\n:\n3\n},\nfunc\n(\nkey\nstring\n,\nvalue\nint\n)\nbool\n{\nreturn\nvalue\n%\n2\n==\n1\n})\n// map[string]int{\"foo\": 1, \"baz\": 3}\n[\nplay\n]\nPickByKeys\nReturns same map type filtered by given keys.\nm\n:=\nlo\n.\nPickByKeys\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n,\n\"baz\"\n:\n3\n}, []\nstring\n{\n\"foo\"\n,\n\"baz\"\n})\n// map[string]int{\"foo\": 1, \"baz\": 3}\n[\nplay\n]\nPickByValues\nReturns same map type filtered by given values.\nm\n:=\nlo\n.\nPickByValues\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n,\n\"baz\"\n:\n3\n}, []\nint\n{\n1\n,\n3\n})\n// map[string]int{\"foo\": 1, \"baz\": 3}\n[\nplay\n]\nOmitBy\nReturns same map type filtered by given predicate.\nm\n:=\nlo\n.\nOmitBy\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n,\n\"baz\"\n:\n3\n},\nfunc\n(\nkey\nstring\n,\nvalue\nint\n)\nbool\n{\nreturn\nvalue\n%\n2\n==\n1\n})\n// map[string]int{\"bar\": 2}\n[\nplay\n]\nOmitByKeys\nReturns same map type filtered by given keys.\nm\n:=\nlo\n.\nOmitByKeys\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n,\n\"baz\"\n:\n3\n}, []\nstring\n{\n\"foo\"\n,\n\"baz\"\n})\n// map[string]int{\"bar\": 2}\n[\nplay\n]\nOmitByValues\nReturns same map type filtered by given values.\nm\n:=\nlo\n.\nOmitByValues\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n,\n\"baz\"\n:\n3\n}, []\nint\n{\n1\n,\n3\n})\n// map[string]int{\"bar\": 2}\n[\nplay\n]\nEntries (alias: ToPairs)\nTransforms a map into a slice of key/value pairs.\nentries\n:=\nlo\n.\nEntries\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n})\n// []lo.Entry[string, int]{\n//     {\n//         Key: \"foo\",\n//         Value: 1,\n//     },\n//     {\n//         Key: \"bar\",\n//         Value: 2,\n//     },\n// }\n[\nplay\n]\nFromEntries (alias: FromPairs)\nTransforms a slice of key/value pairs into a map.\nm\n:=\nlo\n.\nFromEntries\n([]lo.\nEntry\n[\nstring\n,\nint\n]{\n    {\nKey\n:\n\"foo\"\n,\nValue\n:\n1\n,\n    },\n    {\nKey\n:\n\"bar\"\n,\nValue\n:\n2\n,\n    },\n})\n// map[string]int{\"foo\": 1, \"bar\": 2}\n[\nplay\n]\nInvert\nCreates a map composed of the inverted keys and values. If map contains duplicate values, subsequent values overwrite property assignments of previous values.\nm1\n:=\nlo\n.\nInvert\n(\nmap\n[\nstring\n]\nint\n{\n\"a\"\n:\n1\n,\n\"b\"\n:\n2\n})\n// map[int]string{1: \"a\", 2: \"b\"}\nm2\n:=\nlo\n.\nInvert\n(\nmap\n[\nstring\n]\nint\n{\n\"a\"\n:\n1\n,\n\"b\"\n:\n2\n,\n\"c\"\n:\n1\n})\n// map[int]string{1: \"c\", 2: \"b\"}\n[\nplay\n]\nAssign\nMerges multiple maps from left to right.\nmergedMaps\n:=\nlo\n.\nAssign\n(\nmap\n[\nstring\n]\nint\n{\n\"a\"\n:\n1\n,\n\"b\"\n:\n2\n},\nmap\n[\nstring\n]\nint\n{\n\"b\"\n:\n3\n,\n\"c\"\n:\n4\n},\n)\n// map[string]int{\"a\": 1, \"b\": 3, \"c\": 4}\n[\nplay\n]\nChunkEntries\nSplits a map into a slice of elements in groups of length equal to its size. If the map cannot be split evenly, the final chunk will contain the remaining elements.\nmaps\n:=\nlo\n.\nChunkEntries\n(\nmap\n[\nstring\n]\nint\n{\n\"a\"\n:\n1\n,\n\"b\"\n:\n2\n,\n\"c\"\n:\n3\n,\n\"d\"\n:\n4\n,\n\"e\"\n:\n5\n,\n    },\n3\n,\n)\n// []map[string]int{\n//    {\"a\": 1, \"b\": 2, \"c\": 3},\n//    {\"d\": 4, \"e\": 5},\n// }\n[\nplay\n]\nMapKeys\nManipulates map keys and transforms it to a map of another type.\nm2\n:=\nlo\n.\nMapKeys\n(\nmap\n[\nint\n]\nint\n{\n1\n:\n1\n,\n2\n:\n2\n,\n3\n:\n3\n,\n4\n:\n4\n},\nfunc\n(\n_\nint\n,\nv\nint\n)\nstring\n{\nreturn\nstrconv\n.\nFormatInt\n(\nint64\n(\nv\n),\n10\n)\n})\n// map[string]int{\"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4}\n[\nplay\n]\nMapValues\nManipulates map values and transforms it to a map of another type.\nm1\n:=\nmap\n[\nint\n]\nint64\n{\n1\n:\n1\n,\n2\n:\n2\n,\n3\n:\n3\n}\nm2\n:=\nlo\n.\nMapValues\n(\nm1\n,\nfunc\n(\nx\nint64\n,\n_\nint\n)\nstring\n{\nreturn\nstrconv\n.\nFormatInt\n(\nx\n,\n10\n)\n})\n// map[int]string{1: \"1\", 2: \"2\", 3: \"3\"}\n[\nplay\n]\nMapEntries\nManipulates map entries and transforms it to a map of another type.\nin\n:=\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n}\nout\n:=\nlo\n.\nMapEntries\n(\nin\n,\nfunc\n(\nk\nstring\n,\nv\nint\n) (\nint\n,\nstring\n) {\nreturn\nv\n,\nk\n})\n// map[int]string{1: \"foo\", 2: \"bar\"}\n[\nplay\n]\nMapToSlice\nTransforms a map into a slice based on specified iteratee.\nm\n:=\nmap\n[\nint\n]\nint64\n{\n1\n:\n4\n,\n2\n:\n5\n,\n3\n:\n6\n}\ns\n:=\nlo\n.\nMapToSlice\n(\nm\n,\nfunc\n(\nk\nint\n,\nv\nint64\n)\nstring\n{\nreturn\nfmt\n.\nSprintf\n(\n\"%d_%d\"\n,\nk\n,\nv\n)\n})\n// []string{\"1_4\", \"2_5\", \"3_6\"}\n[\nplay\n]\nFilterMapToSlice\nTransforms a map into a slice based on specified iteratee. The iteratee returns a value and a boolean. If the boolean is true, the value is added to the result slice.\nIf the boolean is false, the value is not added to the result slice. The order of the keys in the input map is not specified and the order of the keys in the output slice is not guaranteed.\nkv\n:=\nmap\n[\nint\n]\nint64\n{\n1\n:\n1\n,\n2\n:\n2\n,\n3\n:\n3\n,\n4\n:\n4\n}\nresult\n:=\nlo\n.\nFilterMapToSlice\n(\nkv\n,\nfunc\n(\nk\nint\n,\nv\nint64\n) (\nstring\n,\nbool\n) {\nreturn\nfmt\n.\nSprintf\n(\n\"%d_%d\"\n,\nk\n,\nv\n),\nk\n%\n2\n==\n0\n})\n// []{\"2_2\", \"4_4\"}\nFilterKeys\nTransforms a map into a slice based on predicate returns true for specific elements. It is a mix of\nlo.Filter()\nand\nlo.Keys()\n.\nkv\n:=\nmap\n[\nint\n]\nstring\n{\n1\n:\n\"foo\"\n,\n2\n:\n\"bar\"\n,\n3\n:\n\"baz\"\n}\nresult\n:=\nFilterKeys\n(\nkv\n,\nfunc\n(\nk\nint\n,\nv\nstring\n)\nbool\n{\nreturn\nv\n==\n\"foo\"\n})\n// [1]\n[\nplay\n]\nFilterValues\nTransforms a map into a slice based on predicate returns true for specific elements. It is a mix of\nlo.Filter()\nand\nlo.Values()\n.\nkv\n:=\nmap\n[\nint\n]\nstring\n{\n1\n:\n\"foo\"\n,\n2\n:\n\"bar\"\n,\n3\n:\n\"baz\"\n}\nresult\n:=\nFilterValues\n(\nkv\n,\nfunc\n(\nk\nint\n,\nv\nstring\n)\nbool\n{\nreturn\nv\n==\n\"foo\"\n})\n// [\"foo\"]\n[\nplay\n]\nRange / RangeFrom / RangeWithSteps\nCreates a slice of numbers (positive and/or negative) progressing from start up to, but not including end.\nresult\n:=\nlo\n.\nRange\n(\n4\n)\n// [0, 1, 2, 3]\nresult\n:=\nlo\n.\nRange\n(\n-\n4\n)\n// [0, -1, -2, -3]\nresult\n:=\nlo\n.\nRangeFrom\n(\n1\n,\n5\n)\n// [1, 2, 3, 4, 5]\nresult\n:=\nlo\n.\nRangeFrom\n[\nfloat64\n](\n1.0\n,\n5\n)\n// [1.0, 2.0, 3.0, 4.0, 5.0]\nresult\n:=\nlo\n.\nRangeWithSteps\n(\n0\n,\n20\n,\n5\n)\n// [0, 5, 10, 15]\nresult\n:=\nlo\n.\nRangeWithSteps\n[\nfloat32\n](\n-\n1.0\n,\n-\n4.0\n,\n-\n1.0\n)\n// [-1.0, -2.0, -3.0]\nresult\n:=\nlo\n.\nRangeWithSteps\n(\n1\n,\n4\n,\n-\n1\n)\n// []\nresult\n:=\nlo\n.\nRange\n(\n0\n)\n// []\n[\nplay\n]\nClamp\nClamps number within the inclusive lower and upper bounds.\nr1\n:=\nlo\n.\nClamp\n(\n0\n,\n-\n10\n,\n10\n)\n// 0\nr2\n:=\nlo\n.\nClamp\n(\n-\n42\n,\n-\n10\n,\n10\n)\n// -10\nr3\n:=\nlo\n.\nClamp\n(\n42\n,\n-\n10\n,\n10\n)\n// 10\n[\nplay\n]\nSum\nSums the values in a collection.\nIf collection is empty 0 is returned.\nlist\n:=\n[]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}\nsum\n:=\nlo\n.\nSum\n(\nlist\n)\n// 15\n[\nplay\n]\nSumBy\nSummarizes the values in a collection using the given return value from the iteration function.\nIf collection is empty 0 is returned.\nstrings\n:=\n[]\nstring\n{\n\"foo\"\n,\n\"bar\"\n}\nsum\n:=\nlo\n.\nSumBy\n(\nstrings\n,\nfunc\n(\nitem\nstring\n)\nint\n{\nreturn\nlen\n(\nitem\n)\n})\n// 6\nProduct\nCalculates the product of the values in a collection.\nIf collection is empty 0 is returned.\nlist\n:=\n[]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}\nproduct\n:=\nlo\n.\nProduct\n(\nlist\n)\n// 120\n[\nplay\n]\nProductBy\nCalculates the product of the values in a collection using the given return value from the iteration function.\nIf collection is empty 0 is returned.\nstrings\n:=\n[]\nstring\n{\n\"foo\"\n,\n\"bar\"\n}\nproduct\n:=\nlo\n.\nProductBy\n(\nstrings\n,\nfunc\n(\nitem\nstring\n)\nint\n{\nreturn\nlen\n(\nitem\n)\n})\n// 9\n[\nplay\n]\nMean\nCalculates the mean of a collection of numbers.\nIf collection is empty 0 is returned.\nmean\n:=\nlo\n.\nMean\n([]\nint\n{\n2\n,\n3\n,\n4\n,\n5\n})\n// 3\nmean\n:=\nlo\n.\nMean\n([]\nfloat64\n{\n2\n,\n3\n,\n4\n,\n5\n})\n// 3.5\nmean\n:=\nlo\n.\nMean\n([]\nfloat64\n{})\n// 0\nMeanBy\nCalculates the mean of a collection of numbers using the given return value from the iteration function.\nIf collection is empty 0 is returned.\nlist\n:=\n[]\nstring\n{\n\"aa\"\n,\n\"bbb\"\n,\n\"cccc\"\n,\n\"ddddd\"\n}\nmapper\n:=\nfunc\n(\nitem\nstring\n)\nfloat64\n{\nreturn\nfloat64\n(\nlen\n(\nitem\n))\n}\nmean\n:=\nlo\n.\nMeanBy\n(\nlist\n,\nmapper\n)\n// 3.5\nmean\n:=\nlo\n.\nMeanBy\n([]\nfloat64\n{},\nmapper\n)\n// 0\n[\nplay\n]\nMode\nCalculates the mode (most frequent value) of a collection of numbers.\nIf multiple values have the same highest frequency, then multiple values are returned.\nIf the collection is empty, the zero value of\nT[]\nis returned.\nmode\n:=\nlo\n.\nMode\n([]\nint\n{\n2\n,\n2\n,\n3\n,\n4\n})\n// [2]\nmode\n:=\nlo\n.\nMode\n([]\nfloat64\n{\n2\n,\n2\n,\n3\n,\n3\n})\n// [2, 3]\nmode\n:=\nlo\n.\nMode\n([]\nfloat64\n{})\n// []\nmode\n:=\nlo\n.\nMode\n([]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n,\n5\n,\n6\n,\n7\n,\n8\n,\n9\n})\n// [1, 2, 3, 4, 5, 6, 7, 8, 9]\nRandomString\nReturns a random string of the specified length and made of the specified charset.\nstr\n:=\nlo\n.\nRandomString\n(\n5\n,\nlo\n.\nLettersCharset\n)\n// example: \"eIGbt\"\n[\nplay\n]\nSubstring\nReturn part of a string.\nsub\n:=\nlo\n.\nSubstring\n(\n\"hello\"\n,\n2\n,\n3\n)\n// \"llo\"\nsub\n:=\nlo\n.\nSubstring\n(\n\"hello\"\n,\n-\n4\n,\n3\n)\n// \"ell\"\nsub\n:=\nlo\n.\nSubstring\n(\n\"hello\"\n,\n-\n2\n,\nmath\n.\nMaxUint\n)\n// \"lo\"\n[\nplay\n]\nChunkString\nReturns a slice of strings split into groups of length size. If the string can't be split evenly, the final chunk will be the remaining characters.\nlo\n.\nChunkString\n(\n\"123456\"\n,\n2\n)\n// []string{\"12\", \"34\", \"56\"}\nlo\n.\nChunkString\n(\n\"1234567\"\n,\n2\n)\n// []string{\"12\", \"34\", \"56\", \"7\"}\nlo\n.\nChunkString\n(\n\"\"\n,\n2\n)\n// []string{\"\"}\nlo\n.\nChunkString\n(\n\"1\"\n,\n2\n)\n// []string{\"1\"}\n[\nplay\n]\nRuneLength\nAn alias to utf8.RuneCountInString which returns the number of runes in string.\nsub\n:=\nlo\n.\nRuneLength\n(\n\"hell√¥\"\n)\n// 5\nsub\n:=\nlen\n(\n\"hell√¥\"\n)\n// 6\n[\nplay\n]\nPascalCase\nConverts string to pascal case.\nstr\n:=\nlo\n.\nPascalCase\n(\n\"hello_world\"\n)\n// HelloWorld\n[\nplay\n]\nCamelCase\nConverts string to camel case.\nstr\n:=\nlo\n.\nCamelCase\n(\n\"hello_world\"\n)\n// helloWorld\n[\nplay\n]\nKebabCase\nConverts string to kebab case.\nstr\n:=\nlo\n.\nKebabCase\n(\n\"helloWorld\"\n)\n// hello-world\n[\nplay\n]\nSnakeCase\nConverts string to snake case.\nstr\n:=\nlo\n.\nSnakeCase\n(\n\"HelloWorld\"\n)\n// hello_world\n[\nplay\n]\nWords\nSplits string into a slice of its words.\nstr\n:=\nlo\n.\nWords\n(\n\"helloWorld\"\n)\n// []string{\"hello\", \"world\"}\n[\nplay\n]\nCapitalize\nConverts the first character of string to upper case and the remaining to lower case.\nstr\n:=\nlo\n.\nCapitalize\n(\n\"heLLO\"\n)\n// Hello\n[\nplay\n]\nEllipsis\nTrims and truncates a string to a specified length in\nbytes\nand appends an ellipsis if truncated. If the string contains non-ASCII characters (which may occupy multiple bytes in UTF-8), truncating by byte length may split a character in the middle, potentially resulting in garbled output.\nstr\n:=\nlo\n.\nEllipsis\n(\n\"  Lorem Ipsum  \"\n,\n5\n)\n// Lo...\nstr\n:=\nlo\n.\nEllipsis\n(\n\"Lorem Ipsum\"\n,\n100\n)\n// Lorem Ipsum\nstr\n:=\nlo\n.\nEllipsis\n(\n\"Lorem Ipsum\"\n,\n3\n)\n// ...\n[\nplay\n]\nT2 -> T9\nCreates a tuple from a list of values.\ntuple1\n:=\nlo\n.\nT2\n(\n\"x\"\n,\n1\n)\n// Tuple2[string, int]{A: \"x\", B: 1}\nfunc\nexample\n() (\nstring\n,\nint\n) {\nreturn\n\"y\"\n,\n2\n}\ntuple2\n:=\nlo\n.\nT2\n(\nexample\n())\n// Tuple2[string, int]{A: \"y\", B: 2}\n[\nplay\n]\nUnpack2 -> Unpack9\nReturns values contained in a tuple.\nr1\n,\nr2\n:=\nlo\n.\nUnpack2\n(lo.\nTuple2\n[\nstring\n,\nint\n]{\n\"a\"\n,\n1\n})\n// \"a\", 1\nUnpack is also available as a method of TupleX.\ntuple2\n:=\nlo\n.\nT2\n(\n\"a\"\n,\n1\n)\na\n,\nb\n:=\ntuple2\n.\nUnpack\n()\n// \"a\", 1\n[\nplay\n]\nZip2 -> Zip9\nZip creates a slice of grouped elements, the first of which contains the first elements of the given slices, the second of which contains the second elements of the given slices, and so on.\nWhen collections are different sizes, the Tuple attributes are filled with zero value.\ntuples\n:=\nlo\n.\nZip2\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n}, []\nint\n{\n1\n,\n2\n})\n// []Tuple2[string, int]{{A: \"a\", B: 1}, {A: \"b\", B: 2}}\n[\nplay\n]\nZipBy2 -> ZipBy9\nZipBy creates a slice of transformed elements, the first of which contains the first elements of the given slices, the second of which contains the second elements of the given slices, and so on.\nWhen collections are different sizes, the Tuple attributes are filled with zero value.\nitems\n:=\nlo\n.\nZipBy2\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n}, []\nint\n{\n1\n,\n2\n},\nfunc\n(\na\nstring\n,\nb\nint\n)\nstring\n{\nreturn\nfmt\n.\nSprintf\n(\n\"%s-%d\"\n,\na\n,\nb\n)\n})\n// []string{\"a-1\", \"b-2\"}\nUnzip2 -> Unzip9\nUnzip accepts a slice of grouped elements and creates a slice regrouping the elements to their pre-zip configuration.\na\n,\nb\n:=\nlo\n.\nUnzip2\n([]\nTuple2\n[\nstring\n,\nint\n]{{\nA\n:\n\"a\"\n,\nB\n:\n1\n}, {\nA\n:\n\"b\"\n,\nB\n:\n2\n}})\n// []string{\"a\", \"b\"}\n// []int{1, 2}\n[\nplay\n]\nUnzipBy2 -> UnzipBy9\nUnzipBy2 iterates over a collection and creates a slice regrouping the elements to their pre-zip configuration.\na\n,\nb\n:=\nlo\n.\nUnzipBy2\n([]\nstring\n{\n\"hello\"\n,\n\"john\"\n,\n\"doe\"\n},\nfunc\n(\nstr\nstring\n) (\nstring\n,\nint\n) {\nreturn\nstr\n,\nlen\n(\nstr\n)\n})\n// []string{\"hello\", \"john\", \"doe\"}\n// []int{5, 4, 3}\nCrossJoin2 -> CrossJoin9\nCombines every item from one list with every item from others. It is the cartesian product of lists received as arguments. Returns an empty list if a list is empty.\nresult\n:=\nlo\n.\nCrossJoin2\n([]\nstring\n{\n\"hello\"\n,\n\"john\"\n,\n\"doe\"\n}, []\nint\n{\n1\n,\n2\n})\n// lo.Tuple2{\"hello\", 1}\n// lo.Tuple2{\"hello\", 2}\n// lo.Tuple2{\"john\", 1}\n// lo.Tuple2{\"john\", 2}\n// lo.Tuple2{\"doe\", 1}\n// lo.Tuple2{\"doe\", 2}\nCrossJoinBy2 -> CrossJoinBy9\nCombines every item from one list with every item from others. It is the cartesian product of lists received as arguments. The project function is used to create the output values. Returns an empty list if a list is empty.\nresult\n:=\nlo\n.\nCrossJoinBy2\n([]\nstring\n{\n\"hello\"\n,\n\"john\"\n,\n\"doe\"\n}, []\nint\n{\n1\n,\n2\n},\nfunc\n(\na\nA\n,\nb\nB\n)\nstring\n{\nreturn\nfmt\n.\nSprintf\n(\n\"%s - %d\"\n,\na\n,\nb\n)\n})\n// \"hello - 1\"\n// \"hello - 2\"\n// \"john - 1\"\n// \"john - 2\"\n// \"doe - 1\"\n// \"doe - 2\"\nDuration\nReturns the time taken to execute a function.\nduration\n:=\nlo\n.\nDuration\n(\nfunc\n() {\n// very long job\n})\n// 3s\n[\nplay\n]\nDuration0 -> Duration10\nReturns the time taken to execute a function.\nduration\n:=\nlo\n.\nDuration0\n(\nfunc\n() {\n// very long job\n})\n// 3s\nerr\n,\nduration\n:=\nlo\n.\nDuration1\n(\nfunc\n()\nerror\n{\n// very long job\nreturn\nerrors\n.\nNew\n(\n\"an error\"\n)\n})\n// an error\n// 3s\nstr\n,\nnbr\n,\nerr\n,\nduration\n:=\nlo\n.\nDuration3\n(\nfunc\n() (\nstring\n,\nint\n,\nerror\n) {\n// very long job\nreturn\n\"hello\"\n,\n42\n,\nnil\n})\n// hello\n// 42\n// nil\n// 3s\nChannelDispatcher\nDistributes messages from input channels into N child channels. Close events are propagated to children.\nUnderlying channels can have a fixed buffer capacity or be unbuffered when cap is 0.\nch\n:=\nmake\n(\nchan\nint\n,\n42\n)\nfor\ni\n:=\n0\n;\ni\n<=\n10\n;\ni\n++\n{\nch\n<-\ni\n}\nchildren\n:=\nlo\n.\nChannelDispatcher\n(\nch\n,\n5\n,\n10\n,\nDispatchingStrategyRoundRobin\n[\nint\n])\n// []<-chan int{...}\nconsumer\n:=\nfunc\n(\nc\n<-\nchan\nint\n) {\nfor\n{\nmsg\n,\nok\n:=\n<-\nc\nif\n!\nok\n{\nprintln\n(\n\"closed\"\n)\nbreak\n}\nprintln\n(\nmsg\n)\n    }\n}\nfor\ni\n:=\nrange\nchildren\n{\ngo\nconsumer\n(\nchildren\n[\ni\n])\n}\n[\nplay\n]\nMany distributions strategies are available:\nlo.DispatchingStrategyRoundRobin\n: Distributes messages in a rotating sequential manner.\nlo.DispatchingStrategyRandom\n: Distributes messages in a random manner.\nlo.DispatchingStrategyWeightedRandom\n: Distributes messages in a weighted manner.\nlo.DispatchingStrategyFirst\n: Distributes messages in the first non-full channel.\nlo.DispatchingStrategyLeast\n: Distributes messages in the emptiest channel.\nlo.DispatchingStrategyMost\n: Distributes to the fullest channel.\nSome strategies bring fallback, in order to favor non-blocking behaviors. See implementations.\nFor custom strategies, just implement the\nlo.DispatchingStrategy\nprototype:\ntype\nDispatchingStrategy\n[\nT\nany\n]\nfunc\n(\nmessage\nT\n,\nmessageIndex\nuint64\n,\nchannels\n[]\n<-\nchan\nT\n)\nint\nEg:\ntype\nMessage\nstruct\n{\nTenantID\nuuid.\nUUID\n}\nfunc\nhash\n(\nid\nuuid.\nUUID\n)\nint\n{\nh\n:=\nfnv\n.\nNew32a\n()\nh\n.\nWrite\n([]\nbyte\n(\nid\n.\nString\n()))\nreturn\nint\n(\nh\n.\nSum32\n())\n}\n// Routes messages per TenantID.\ncustomStrategy\n:=\nfunc\n(\nmessage\nstring\n,\nmessageIndex\nuint64\n,\nchannels\n[]\n<-\nchan\nstring\n)\nint\n{\ndestination\n:=\nhash\n(\nmessage\n)\n%\nlen\n(\nchannels\n)\n// check if channel is full\nif\nlen\n(\nchannels\n[\ndestination\n])\n<\ncap\n(\nchannels\n[\ndestination\n]) {\nreturn\ndestination\n}\n// fallback when child channel is full\nreturn\nutils\n.\nDispatchingStrategyRoundRobin\n(\nmessage\n,\nuint64\n(\ndestination\n),\nchannels\n)\n}\nchildren\n:=\nlo\n.\nChannelDispatcher\n(\nch\n,\n5\n,\n10\n,\ncustomStrategy\n)\n...\nSliceToChannel\nReturns a read-only channel of collection elements. Channel is closed after last element. Channel capacity can be customized.\nlist\n:=\n[]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}\nfor\nv\n:=\nrange\nlo\n.\nSliceToChannel\n(\n2\n,\nlist\n) {\nprintln\n(\nv\n)\n}\n// prints 1, then 2, then 3, then 4, then 5\n[\nplay\n]\nChannelToSlice\nReturns a slice built from channel items. Blocks until channel closes.\nlist\n:=\n[]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}\nch\n:=\nlo\n.\nSliceToChannel\n(\n2\n,\nlist\n)\nitems\n:=\nChannelToSlice\n(\nch\n)\n// []int{1, 2, 3, 4, 5}\nGenerator\nImplements the generator design pattern. Channel is closed after last element. Channel capacity can be customized.\ngenerator\n:=\nfunc\n(\nyield\nfunc\n(\nint\n)) {\nyield\n(\n1\n)\nyield\n(\n2\n)\nyield\n(\n3\n)\n}\nfor\nv\n:=\nrange\nlo\n.\nGenerator\n(\n2\n,\ngenerator\n) {\nprintln\n(\nv\n)\n}\n// prints 1, then 2, then 3\nBuffer\nCreates a slice of n elements from a channel. Returns the slice, the slice length, the read time and the channel status (opened/closed).\nch\n:=\nlo\n.\nSliceToChannel\n(\n2\n, []\nint\n{\n1\n,\n2\n,\n3\n,\n4\n,\n5\n})\nitems1\n,\nlength1\n,\nduration1\n,\nok1\n:=\nlo\n.\nBuffer\n(\nch\n,\n3\n)\n// []int{1, 2, 3}, 3, 0s, true\nitems2\n,\nlength2\n,\nduration2\n,\nok2\n:=\nlo\n.\nBuffer\n(\nch\n,\n3\n)\n// []int{4, 5}, 2, 0s, false\nExample: RabbitMQ consumer üëá\nch\n:=\nreadFromQueue\n()\nfor\n{\n// read 1k items\nitems\n,\nlength\n,\n_\n,\nok\n:=\nlo\n.\nBuffer\n(\nch\n,\n1000\n)\n// do batching stuff\nif\n!\nok\n{\nbreak\n}\n}\nBufferWithContext\nCreates a slice of n elements from a channel, with timeout. Returns the slice, the slice length, the read time and the channel status (opened/closed).\nctx\n,\ncancel\n:=\ncontext\n.\nWithCancel\n(\ncontext\n.\nTODO\n())\ngo\nfunc\n() {\nch\n<-\n0\ntime\n.\nSleep\n(\n10\n*\ntime\n.\nMillisecond\n)\nch\n<-\n1\ntime\n.\nSleep\n(\n10\n*\ntime\n.\nMillisecond\n)\nch\n<-\n2\ntime\n.\nSleep\n(\n10\n*\ntime\n.\nMillisecond\n)\nch\n<-\n3\ntime\n.\nSleep\n(\n10\n*\ntime\n.\nMillisecond\n)\nch\n<-\n4\ntime\n.\nSleep\n(\n10\n*\ntime\n.\nMillisecond\n)\ncancel\n()\n}()\nitems1\n,\nlength1\n,\nduration1\n,\nok1\n:=\nlo\n.\nBufferWithContext\n(\nctx\n,\nch\n,\n3\n)\n// []int{0, 1, 2}, 3, 20ms, true\nitems2\n,\nlength2\n,\nduration2\n,\nok2\n:=\nlo\n.\nBufferWithContext\n(\nctx\n,\nch\n,\n3\n)\n// []int{3, 4}, 2, 30ms, false\nBufferWithTimeout\nCreates a slice of n elements from a channel, with timeout. Returns the slice, the slice length, the read time and the channel status (opened/closed).\ngenerator\n:=\nfunc\n(\nyield\nfunc\n(\nint\n)) {\nfor\ni\n:=\n0\n;\ni\n<\n5\n;\ni\n++\n{\nyield\n(\ni\n)\ntime\n.\nSleep\n(\n35\n*\ntime\n.\nMillisecond\n)\n    }\n}\nch\n:=\nlo\n.\nGenerator\n(\n0\n,\ngenerator\n)\nitems1\n,\nlength1\n,\nduration1\n,\nok1\n:=\nlo\n.\nBufferWithTimeout\n(\nch\n,\n3\n,\n100\n*\ntime\n.\nMillisecond\n)\n// []int{1, 2}, 2, 100ms, true\nitems2\n,\nlength2\n,\nduration2\n,\nok2\n:=\nlo\n.\nBufferWithTimeout\n(\nch\n,\n3\n,\n100\n*\ntime\n.\nMillisecond\n)\n// []int{3, 4, 5}, 3, 75ms, true\nitems3\n,\nlength3\n,\nduration2\n,\nok3\n:=\nlo\n.\nBufferWithTimeout\n(\nch\n,\n3\n,\n100\n*\ntime\n.\nMillisecond\n)\n// []int{}, 0, 10ms, false\nExample: RabbitMQ consumer üëá\nch\n:=\nreadFromQueue\n()\nfor\n{\n// read 1k items\n// wait up to 1 second\nitems\n,\nlength\n,\n_\n,\nok\n:=\nlo\n.\nBufferWithTimeout\n(\nch\n,\n1000\n,\n1\n*\ntime\n.\nSecond\n)\n// do batching stuff\nif\n!\nok\n{\nbreak\n}\n}\nExample: Multithreaded RabbitMQ consumer üëá\nch\n:=\nreadFromQueue\n()\n// 5 workers\n// prefetch 1k messages per worker\nchildren\n:=\nlo\n.\nChannelDispatcher\n(\nch\n,\n5\n,\n1000\n,\nlo\n.\nDispatchingStrategyFirst\n[\nint\n])\nconsumer\n:=\nfunc\n(\nc\n<-\nchan\nint\n) {\nfor\n{\n// read 1k items\n// wait up to 1 second\nitems\n,\nlength\n,\n_\n,\nok\n:=\nlo\n.\nBufferWithTimeout\n(\nch\n,\n1000\n,\n1\n*\ntime\n.\nSecond\n)\n// do batching stuff\nif\n!\nok\n{\nbreak\n}\n    }\n}\nfor\ni\n:=\nrange\nchildren\n{\ngo\nconsumer\n(\nchildren\n[\ni\n])\n}\nFanIn\nMerge messages from multiple input channels into a single buffered channel. Output messages have no priority. When all upstream channels reach EOF, downstream channel closes.\nstream1\n:=\nmake\n(\nchan\nint\n,\n42\n)\nstream2\n:=\nmake\n(\nchan\nint\n,\n42\n)\nstream3\n:=\nmake\n(\nchan\nint\n,\n42\n)\nall\n:=\nlo\n.\nFanIn\n(\n100\n,\nstream1\n,\nstream2\n,\nstream3\n)\n// <-chan int\nFanOut\nBroadcasts all the upstream messages to multiple downstream channels. When upstream channel reaches EOF, downstream channels close. If any downstream channels is full, broadcasting is paused.\nstream\n:=\nmake\n(\nchan\nint\n,\n42\n)\nall\n:=\nlo\n.\nFanOut\n(\n5\n,\n100\n,\nstream\n)\n// [5]<-chan int\nContains\nReturns true if an element is present in a collection.\npresent\n:=\nlo\n.\nContains\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n},\n5\n)\n// true\n[\nplay\n]\nContainsBy\nReturns true if the predicate function returns\ntrue\n.\npresent\n:=\nlo\n.\nContainsBy\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n},\nfunc\n(\nx\nint\n)\nbool\n{\nreturn\nx\n==\n3\n})\n// true\nEvery\nReturns true if all elements of a subset are contained in a collection or if the subset is empty.\nok\n:=\nlo\n.\nEvery\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}, []\nint\n{\n0\n,\n2\n})\n// true\nok\n:=\nlo\n.\nEvery\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}, []\nint\n{\n0\n,\n6\n})\n// false\nEveryBy\nReturns true if the predicate returns true for all elements in the collection or if the collection is empty.\nb\n:=\nEveryBy\n([]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n},\nfunc\n(\nx\nint\n)\nbool\n{\nreturn\nx\n<\n5\n})\n// true\n[\nplay\n]\nSome\nReturns true if at least 1 element of a subset is contained in a collection.\nIf the subset is empty Some returns false.\nok\n:=\nlo\n.\nSome\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}, []\nint\n{\n0\n,\n6\n})\n// true\n[\nplay\n]\nok := lo.Some([]int{0, 1, 2, 3, 4, 5}, []int{-1, 6})\n// false\n### SomeBy\n\nReturns true if the predicate returns true for any of the elements in the collection.\nIf the collection is empty SomeBy returns false.\n\n```go\nb := SomeBy([]int{1, 2, 3, 4}, func(x int) bool {\n    return x < 3\n})\n// true\nNone\nReturns true if no element of a subset is contained in a collection or if the subset is empty.\nb\n:=\nNone\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}, []\nint\n{\n0\n,\n2\n})\n// false\nb\n:=\nNone\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}, []\nint\n{\n-\n1\n,\n6\n})\n// true\n[\nplay\n]\nNoneBy\nReturns true if the predicate returns true for none of the elements in the collection or if the collection is empty.\nb\n:=\nNoneBy\n([]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n},\nfunc\n(\nx\nint\n)\nbool\n{\nreturn\nx\n<\n0\n})\n// true\n[\nplay\n]\nIntersect\nReturns the intersection between two collections.\nresult1\n:=\nlo\n.\nIntersect\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}, []\nint\n{\n0\n,\n2\n})\n// []int{0, 2}\nresult2\n:=\nlo\n.\nIntersect\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}, []\nint\n{\n0\n,\n6\n})\n// []int{0}\nresult3\n:=\nlo\n.\nIntersect\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}, []\nint\n{\n-\n1\n,\n6\n})\n// []int{}\nDifference\nReturns the difference between two collections.\nThe first value is the collection of elements absent from list2.\nThe second value is the collection of elements absent from list1.\nleft\n,\nright\n:=\nlo\n.\nDifference\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}, []\nint\n{\n0\n,\n2\n,\n6\n})\n// []int{1, 3, 4, 5}, []int{6}\nleft\n,\nright\n:=\nlo\n.\nDifference\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}, []\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n})\n// []int{}, []int{}\n[\nplay\n]\nUnion\nReturns all distinct elements from given collections. Result will not change the order of elements relatively.\nunion\n:=\nlo\n.\nUnion\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n}, []\nint\n{\n0\n,\n2\n}, []\nint\n{\n0\n,\n10\n})\n// []int{0, 1, 2, 3, 4, 5, 10}\nWithout\nReturns a slice excluding all given values.\nsubset\n:=\nlo\n.\nWithout\n([]\nint\n{\n0\n,\n2\n,\n10\n},\n2\n)\n// []int{0, 10}\nsubset\n:=\nlo\n.\nWithout\n([]\nint\n{\n0\n,\n2\n,\n10\n},\n0\n,\n1\n,\n2\n,\n3\n,\n4\n,\n5\n)\n// []int{10}\nWithoutBy\nFilters a slice by excluding elements whose extracted keys match any in the exclude list.\nReturns a new slice containing only the elements whose keys are not in the exclude list.\ntype\nstruct\nUser\n{\nID\nint\nName\nstring\n}\n// original users\nusers\n:=\n[]\nUser\n{\n    {\nID\n:\n1\n,\nName\n:\n\"Alice\"\n},\n    {\nID\n:\n2\n,\nName\n:\n\"Bob\"\n},\n    {\nID\n:\n3\n,\nName\n:\n\"Charlie\"\n},\n}\n// extract function to get the user ID\ngetID\n:=\nfunc\n(\nuser\nUser\n)\nint\n{\nreturn\nuser\n.\nID\n}\n// exclude users with IDs 2 and 3\nexcludedIDs\n:=\n[]\nint\n{\n2\n,\n3\n}\n// filtering users\nfilteredUsers\n:=\nlo\n.\nWithoutBy\n(\nusers\n,\ngetID\n,\nexcludedIDs\n...\n)\n// []User[{ID: 1, Name: \"Alice\"}]\nWithoutEmpty\nReturns a slice excluding zero values.\nsubset\n:=\nlo\n.\nWithoutEmpty\n([]\nint\n{\n0\n,\n2\n,\n10\n})\n// []int{2, 10}\nWithoutNth\nReturns a slice excluding the nth value.\nsubset\n:=\nlo\n.\nWithoutNth\n([]\nint\n{\n-\n2\n,\n-\n1\n,\n0\n,\n1\n,\n2\n},\n3\n,\n-\n42\n,\n1\n)\n// []int{-2, 0, 2}\nElementsMatch\nReturns true if lists contain the same set of elements (including empty set).\nIf there are duplicate elements, the number of occurrences in each list should match.\nThe order of elements is not checked.\nb\n:=\nlo\n.\nElementsMatch\n([]\nint\n{\n1\n,\n1\n,\n2\n}, []\nint\n{\n2\n,\n1\n,\n1\n})\n// true\nElementsMatchBy\nReturns true if lists contain the same set of elements' keys (including empty set).\nIf there are duplicate keys, the number of occurrences in each list should match.\nThe order of elements is not checked.\nb\n:=\nlo\n.\nElementsMatchBy\n(\n    []\nsomeType\n{\na\n,\nb\n},\n    []\nsomeType\n{\nb\n,\na\n},\nfunc\n(\nitem\nsomeType\n)\nstring\n{\nreturn\nitem\n.\nID\n() },\n)\n// true\nIndexOf\nReturns the index at which the first occurrence of a value is found in a slice or -1 if the value cannot be found.\nfound\n:=\nlo\n.\nIndexOf\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n1\n,\n2\n,\n3\n},\n2\n)\n// 2\nnotFound\n:=\nlo\n.\nIndexOf\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n1\n,\n2\n,\n3\n},\n6\n)\n// -1\n[\nplay\n]\nLastIndexOf\nReturns the index at which the last occurrence of a value is found in a slice or -1 if the value cannot be found.\nfound\n:=\nlo\n.\nLastIndexOf\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n1\n,\n2\n,\n3\n},\n2\n)\n// 4\nnotFound\n:=\nlo\n.\nLastIndexOf\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n1\n,\n2\n,\n3\n},\n6\n)\n// -1\nHasPrefix\nReturns true if the collection has the prefix.\nok\n:=\nlo\n.\nHasPrefix\n([]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n}, []\nint\n{\n42\n})\n// false\nok\n:=\nlo\n.\nHasPrefix\n([]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n}, []\nint\n{\n1\n,\n2\n})\n// true\n[\nplay\n]\nHasSuffix\nReturns true if the collection has the suffix.\nok\n:=\nlo\n.\nHasSuffix\n([]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n}, []\nint\n{\n42\n})\n// false\nok\n:=\nlo\n.\nHasSuffix\n([]\nint\n{\n1\n,\n2\n,\n3\n,\n4\n}, []\nint\n{\n3\n,\n4\n})\n// true\n[\nplay\n]\nFind\nSearches for an element in a slice based on a predicate. Returns element and true if element was found.\nstr\n,\nok\n:=\nlo\n.\nFind\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n,\n\"d\"\n},\nfunc\n(\ni\nstring\n)\nbool\n{\nreturn\ni\n==\n\"b\"\n})\n// \"b\", true\nstr\n,\nok\n:=\nlo\n.\nFind\n([]\nstring\n{\n\"foobar\"\n},\nfunc\n(\ni\nstring\n)\nbool\n{\nreturn\ni\n==\n\"b\"\n})\n// \"\", false\n[\nplay\n]\nFindIndexOf\nFindIndexOf searches for an element in a slice based on a predicate and returns the index and true. Returns -1 and false if the element is not found.\nstr\n,\nindex\n,\nok\n:=\nlo\n.\nFindIndexOf\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"a\"\n,\n\"b\"\n},\nfunc\n(\ni\nstring\n)\nbool\n{\nreturn\ni\n==\n\"b\"\n})\n// \"b\", 1, true\nstr\n,\nindex\n,\nok\n:=\nlo\n.\nFindIndexOf\n([]\nstring\n{\n\"foobar\"\n},\nfunc\n(\ni\nstring\n)\nbool\n{\nreturn\ni\n==\n\"b\"\n})\n// \"\", -1, false\n[\nplay\n]\nFindLastIndexOf\nFindLastIndexOf searches for the last element in a slice based on a predicate and returns the index and true. Returns -1 and false if the element is not found.\nstr\n,\nindex\n,\nok\n:=\nlo\n.\nFindLastIndexOf\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"a\"\n,\n\"b\"\n},\nfunc\n(\ni\nstring\n)\nbool\n{\nreturn\ni\n==\n\"b\"\n})\n// \"b\", 4, true\nstr\n,\nindex\n,\nok\n:=\nlo\n.\nFindLastIndexOf\n([]\nstring\n{\n\"foobar\"\n},\nfunc\n(\ni\nstring\n)\nbool\n{\nreturn\ni\n==\n\"b\"\n})\n// \"\", -1, false\n[\nplay\n]\nFindOrElse\nSearches for an element in a slice based on a predicate. Returns the element if found or a given fallback value otherwise.\nstr\n:=\nlo\n.\nFindOrElse\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n,\n\"d\"\n},\n\"x\"\n,\nfunc\n(\ni\nstring\n)\nbool\n{\nreturn\ni\n==\n\"b\"\n})\n// \"b\"\nstr\n:=\nlo\n.\nFindOrElse\n([]\nstring\n{\n\"foobar\"\n},\n\"x\"\n,\nfunc\n(\ni\nstring\n)\nbool\n{\nreturn\ni\n==\n\"b\"\n})\n// \"x\"\nFindKey\nReturns the key of the first value matching.\nresult1\n,\nok1\n:=\nlo\n.\nFindKey\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n,\n\"baz\"\n:\n3\n},\n2\n)\n// \"bar\", true\nresult2\n,\nok2\n:=\nlo\n.\nFindKey\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n,\n\"baz\"\n:\n3\n},\n42\n)\n// \"\", false\ntype\ntest\nstruct\n{\nfoobar\nstring\n}\nresult3\n,\nok3\n:=\nlo\n.\nFindKey\n(\nmap\n[\nstring\n]\ntest\n{\n\"foo\"\n:\ntest\n{\n\"foo\"\n},\n\"bar\"\n:\ntest\n{\n\"bar\"\n},\n\"baz\"\n:\ntest\n{\n\"baz\"\n}},\ntest\n{\n\"foo\"\n})\n// \"foo\", true\nFindKeyBy\nReturns the key of the first element predicate returns true for.\nresult1\n,\nok1\n:=\nlo\n.\nFindKeyBy\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n,\n\"baz\"\n:\n3\n},\nfunc\n(\nk\nstring\n,\nv\nint\n)\nbool\n{\nreturn\nk\n==\n\"foo\"\n})\n// \"foo\", true\nresult2\n,\nok2\n:=\nlo\n.\nFindKeyBy\n(\nmap\n[\nstring\n]\nint\n{\n\"foo\"\n:\n1\n,\n\"bar\"\n:\n2\n,\n\"baz\"\n:\n3\n},\nfunc\n(\nk\nstring\n,\nv\nint\n)\nbool\n{\nreturn\nfalse\n})\n// \"\", false\nFindUniques\nReturns a slice with all the elements that appear in the collection only once. The order of result values is determined by the order they occur in the slice.\nuniqueValues\n:=\nlo\n.\nFindUniques\n([]\nint\n{\n1\n,\n2\n,\n2\n,\n1\n,\n2\n,\n3\n})\n// []int{3}\nFindUniquesBy\nReturns a slice with all the elements that appear in the collection only once. The order of result values is determined by the order they occur in the slice. It accepts\niteratee\nwhich is invoked for each element in the slice to generate the criterion by which uniqueness is computed.\nuniqueValues\n:=\nlo\n.\nFindUniquesBy\n([]\nint\n{\n3\n,\n4\n,\n5\n,\n6\n,\n7\n},\nfunc\n(\ni\nint\n)\nint\n{\nreturn\ni\n%\n3\n})\n// []int{5}\nFindDuplicates\nReturns a slice with the first occurrence of each duplicated element in the collection. The order of result values is determined by the order they occur in the slice.\nduplicatedValues\n:=\nlo\n.\nFindDuplicates\n([]\nint\n{\n1\n,\n2\n,\n2\n,\n1\n,\n2\n,\n3\n})\n// []int{1, 2}\nFindDuplicatesBy\nReturns a slice with the first occurrence of each duplicated element in the collection. The order of result values is determined by the order they occur in the slice. It accepts\niteratee\nwhich is invoked for each element in the slice to generate the criterion by which uniqueness is computed.\nduplicatedValues\n:=\nlo\n.\nFindDuplicatesBy\n([]\nint\n{\n3\n,\n4\n,\n5\n,\n6\n,\n7\n},\nfunc\n(\ni\nint\n)\nint\n{\nreturn\ni\n%\n3\n})\n// []int{3, 4}\nMin\nSearch the minimum value of a collection.\nReturns zero value when the collection is empty.\nmin\n:=\nlo\n.\nMin\n([]\nint\n{\n1\n,\n2\n,\n3\n})\n// 1\nmin\n:=\nlo\n.\nMin\n([]\nint\n{})\n// 0\nmin\n:=\nlo\n.\nMin\n([]time.\nDuration\n{\ntime\n.\nSecond\n,\ntime\n.\nHour\n})\n// 1s\n[\nplay\n]\nMinIndex\nSearch the minimum value of a collection and the index of the minimum value.\nReturns (zero value, -1) when the collection is empty.\nmin\n,\nindex\n:=\nlo\n.\nMinIndex\n([]\nint\n{\n1\n,\n2\n,\n3\n})\n// 1, 0\nmin\n,\nindex\n:=\nlo\n.\nMinIndex\n([]\nint\n{})\n// 0, -1\nmin\n,\nindex\n:=\nlo\n.\nMinIndex\n([]time.\nDuration\n{\ntime\n.\nSecond\n,\ntime\n.\nHour\n})\n// 1s, 0\nMinBy\nSearch the minimum value of a collection using the given comparison function.\nIf several values of the collection are equal to the smallest value, returns the first such value.\nReturns zero value when the collection is empty.\nmin\n:=\nlo\n.\nMinBy\n([]\nstring\n{\n\"s1\"\n,\n\"string2\"\n,\n\"s3\"\n},\nfunc\n(\nitem\nstring\n,\nmin\nstring\n)\nbool\n{\nreturn\nlen\n(\nitem\n)\n<\nlen\n(\nmin\n)\n})\n// \"s1\"\nmin\n:=\nlo\n.\nMinBy\n([]\nstring\n{},\nfunc\n(\nitem\nstring\n,\nmin\nstring\n)\nbool\n{\nreturn\nlen\n(\nitem\n)\n<\nlen\n(\nmin\n)\n})\n// \"\"\nMinIndexBy\nSearch the minimum value of a collection using the given comparison function and the index of the minimum value.\nIf several values of the collection are equal to the smallest value, returns the first such value.\nReturns (zero value, -1) when the collection is empty.\nmin\n,\nindex\n:=\nlo\n.\nMinIndexBy\n([]\nstring\n{\n\"s1\"\n,\n\"string2\"\n,\n\"s3\"\n},\nfunc\n(\nitem\nstring\n,\nmin\nstring\n)\nbool\n{\nreturn\nlen\n(\nitem\n)\n<\nlen\n(\nmin\n)\n})\n// \"s1\", 0\nmin\n,\nindex\n:=\nlo\n.\nMinIndexBy\n([]\nstring\n{},\nfunc\n(\nitem\nstring\n,\nmin\nstring\n)\nbool\n{\nreturn\nlen\n(\nitem\n)\n<\nlen\n(\nmin\n)\n})\n// \"\", -1\nEarliest\nSearch the minimum time.Time of a collection.\nReturns zero value when the collection is empty.\nearliest\n:=\nlo\n.\nEarliest\n(\ntime\n.\nNow\n(), time.\nTime\n{})\n// 0001-01-01 00:00:00 +0000 UTC\nEarliestBy\nSearch the minimum time.Time of a collection using the given iteratee function.\nReturns zero value when the collection is empty.\ntype\nfoo\nstruct\n{\nbar\ntime.\nTime\n}\nearliest\n:=\nlo\n.\nEarliestBy\n([]\nfoo\n{{\ntime\n.\nNow\n()}, {}},\nfunc\n(\ni\nfoo\n) time.\nTime\n{\nreturn\ni\n.\nbar\n})\n// {bar:{2023-04-01 01:02:03 +0000 UTC}}\nMax\nSearch the maximum value of a collection.\nReturns zero value when the collection is empty.\nmax\n:=\nlo\n.\nMax\n([]\nint\n{\n1\n,\n2\n,\n3\n})\n// 3\nmax\n:=\nlo\n.\nMax\n([]\nint\n{})\n// 0\nmax\n:=\nlo\n.\nMax\n([]time.\nDuration\n{\ntime\n.\nSecond\n,\ntime\n.\nHour\n})\n// 1h\nMaxIndex\nSearch the maximum value of a collection and the index of the maximum value.\nReturns (zero value, -1) when the collection is empty.\nmax\n,\nindex\n:=\nlo\n.\nMaxIndex\n([]\nint\n{\n1\n,\n2\n,\n3\n})\n// 3, 2\nmax\n,\nindex\n:=\nlo\n.\nMaxIndex\n([]\nint\n{})\n// 0, -1\nmax\n,\nindex\n:=\nlo\n.\nMaxIndex\n([]time.\nDuration\n{\ntime\n.\nSecond\n,\ntime\n.\nHour\n})\n// 1h, 1\nMaxBy\nSearch the maximum value of a collection using the given comparison function.\nIf several values of the collection are equal to the greatest value, returns the first such value.\nReturns zero value when the collection is empty.\nmax\n:=\nlo\n.\nMaxBy\n([]\nstring\n{\n\"string1\"\n,\n\"s2\"\n,\n\"string3\"\n},\nfunc\n(\nitem\nstring\n,\nmax\nstring\n)\nbool\n{\nreturn\nlen\n(\nitem\n)\n>\nlen\n(\nmax\n)\n})\n// \"string1\"\nmax\n:=\nlo\n.\nMaxBy\n([]\nstring\n{},\nfunc\n(\nitem\nstring\n,\nmax\nstring\n)\nbool\n{\nreturn\nlen\n(\nitem\n)\n>\nlen\n(\nmax\n)\n})\n// \"\"\nMaxIndexBy\nSearch the maximum value of a collection using the given comparison function and the index of the maximum value.\nIf several values of the collection are equal to the greatest value, returns the first such value.\nReturns (zero value, -1) when the collection is empty.\nmax\n,\nindex\n:=\nlo\n.\nMaxIndexBy\n([]\nstring\n{\n\"string1\"\n,\n\"s2\"\n,\n\"string3\"\n},\nfunc\n(\nitem\nstring\n,\nmax\nstring\n)\nbool\n{\nreturn\nlen\n(\nitem\n)\n>\nlen\n(\nmax\n)\n})\n// \"string1\", 0\nmax\n,\nindex\n:=\nlo\n.\nMaxIndexBy\n([]\nstring\n{},\nfunc\n(\nitem\nstring\n,\nmax\nstring\n)\nbool\n{\nreturn\nlen\n(\nitem\n)\n>\nlen\n(\nmax\n)\n})\n// \"\", -1\nLatest\nSearch the maximum time.Time of a collection.\nReturns zero value when the collection is empty.\nlatest\n:=\nlo\n.\nLatest\n(\ntime\n.\nNow\n(), time.\nTime\n{})\n// 2023-04-01 01:02:03 +0000 UTC\nLatestBy\nSearch the maximum time.Time of a collection using the given iteratee function.\nReturns zero value when the collection is empty.\ntype\nfoo\nstruct\n{\nbar\ntime.\nTime\n}\nlatest\n:=\nlo\n.\nLatestBy\n([]\nfoo\n{{\ntime\n.\nNow\n()}, {}},\nfunc\n(\ni\nfoo\n) time.\nTime\n{\nreturn\ni\n.\nbar\n})\n// {bar:{2023-04-01 01:02:03 +0000 UTC}}\nFirst\nReturns the first element of a collection and check for availability of the first element.\nfirst\n,\nok\n:=\nlo\n.\nFirst\n([]\nint\n{\n1\n,\n2\n,\n3\n})\n// 1, true\nfirst\n,\nok\n:=\nlo\n.\nFirst\n([]\nint\n{})\n// 0, false\nFirstOrEmpty\nReturns the first element of a collection or zero value if empty.\nfirst\n:=\nlo\n.\nFirstOrEmpty\n([]\nint\n{\n1\n,\n2\n,\n3\n})\n// 1\nfirst\n:=\nlo\n.\nFirstOrEmpty\n([]\nint\n{})\n// 0\nFirstOr\nReturns the first element of a collection or the fallback value if empty.\nfirst\n:=\nlo\n.\nFirstOr\n([]\nint\n{\n1\n,\n2\n,\n3\n},\n245\n)\n// 1\nfirst\n:=\nlo\n.\nFirstOr\n([]\nint\n{},\n31\n)\n// 31\nLast\nReturns the last element of a collection or error if empty.\nlast\n,\nok\n:=\nlo\n.\nLast\n([]\nint\n{\n1\n,\n2\n,\n3\n})\n// 3\n// true\nlast\n,\nok\n:=\nlo\n.\nLast\n([]\nint\n{})\n// 0\n// false\nLastOrEmpty\nReturns the last element of a collection or zero value if empty.\nlast\n:=\nlo\n.\nLastOrEmpty\n([]\nint\n{\n1\n,\n2\n,\n3\n})\n// 3\nlast\n:=\nlo\n.\nLastOrEmpty\n([]\nint\n{})\n// 0\nLastOr\nReturns the last element of a collection or the fallback value if empty.\nlast\n:=\nlo\n.\nLastOr\n([]\nint\n{\n1\n,\n2\n,\n3\n},\n245\n)\n// 3\nlast\n:=\nlo\n.\nLastOr\n([]\nint\n{},\n31\n)\n// 31\nNth\nReturns the element at index\nnth\nof collection. If\nnth\nis negative, the nth element from the end is returned. An error is returned when nth is out of slice bounds.\nnth\n,\nerr\n:=\nlo\n.\nNth\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n},\n2\n)\n// 2\nnth\n,\nerr\n:=\nlo\n.\nNth\n([]\nint\n{\n0\n,\n1\n,\n2\n,\n3\n},\n-\n2\n)\n// 2\nNthOr\nReturns the element at index\nnth\nof the collection. If\nnth\nis negative, it returns the\nnth\nelement from the end. If\nnth\nis out of slice bounds, it returns the provided fallback value\nnth\n:=\nlo\n.\nNthOr\n([]\nint\n{\n10\n,\n20\n,\n30\n,\n40\n,\n50\n},\n2\n,\n-\n1\n)\n// 30\nnth\n:=\nlo\n.\nNthOr\n([]\nint\n{\n10\n,\n20\n,\n30\n,\n40\n,\n50\n},\n-\n1\n,\n-\n1\n)\n// 50\nnth\n:=\nlo\n.\nNthOr\n([]\nint\n{\n10\n,\n20\n,\n30\n,\n40\n,\n50\n},\n5\n,\n-\n1\n)\n// -1 (fallback value)\nNthOrEmpty\nReturns the element at index\nnth\nof the collection. If\nnth\nis negative, it returns the\nnth\nelement from the end. If\nnth\nis out of slice bounds, it returns the zero value for the element type (e.g., 0 for integers, \"\" for strings, etc).\nnth\n:=\nlo\n.\nNthOrEmpty\n([]\nint\n{\n10\n,\n20\n,\n30\n,\n40\n,\n50\n},\n2\n)\n// 30\nnth\n:=\nlo\n.\nNthOrEmpty\n([]\nint\n{\n10\n,\n20\n,\n30\n,\n40\n,\n50\n},\n-\n1\n)\n// 50\nnth\n:=\nlo\n.\nNthOrEmpty\n([]\nint\n{\n10\n,\n20\n,\n30\n,\n40\n,\n50\n},\n5\n)\n// 0 (zero value for int)\nnth\n:=\nlo\n.\nNthOrEmpty\n([]\nstring\n{\n\"apple\"\n,\n\"banana\"\n,\n\"cherry\"\n},\n2\n)\n// \"cherry\"\nnth\n:=\nlo\n.\nNthOrEmpty\n([]\nstring\n{\n\"apple\"\n,\n\"banana\"\n,\n\"cherry\"\n},\n5\n)\n// \"\" (zero value for string)\nSample\nReturns a random item from collection.\nlo\n.\nSample\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n})\n// a random string from []string{\"a\", \"b\", \"c\"}\nlo\n.\nSample\n([]\nstring\n{})\n// \"\"\n[\nplay\n]\nSampleBy\nReturns a random item from collection, using a given random integer generator.\nimport\n\"math/rand\"\nr\n:=\nrand\n.\nNew\n(\nrand\n.\nNewSource\n(\n42\n))\nlo\n.\nSampleBy\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n},\nr\n.\nIntn\n)\n// a random string from []string{\"a\", \"b\", \"c\"}, using a seeded random generator\nlo\n.\nSampleBy\n([]\nstring\n{},\nr\n.\nIntn\n)\n// \"\"\nSamples\nReturns N random unique items from collection.\nlo\n.\nSamples\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n},\n3\n)\n// []string{\"a\", \"b\", \"c\"} in random order\nSamplesBy\nReturns N random unique items from collection, using a given random integer generator.\nr\n:=\nrand\n.\nNew\n(\nrand\n.\nNewSource\n(\n42\n))\nlo\n.\nSamplesBy\n([]\nstring\n{\n\"a\"\n,\n\"b\"\n,\n\"c\"\n},\n3\n,\nr\n.\nIntn\n)\n// []string{\"a\", \"b\", \"c\"} in random order, using a seeded random generator\nTernary\nA single line if/else statement.\nresult\n:=\nlo\n.\nTernary\n(\ntrue\n,\n\"a\"\n,\n\"b\"\n)\n// \"a\"\nresult\n:=\nlo\n.\nTernary\n(\nfalse\n,\n\"a\"\n,\n\"b\"\n)\n// \"b\"\nTake care to avoid dereferencing potentially nil pointers in your A/B expressions, because they are both evaluated. See TernaryF to avoid this problem.\n[\nplay\n]\nTernaryF\nA single line if/else statement whose options are functions.\nresult\n:=\nlo\n.\nTernaryF\n(\ntrue\n,\nfunc\n()\nstring\n{\nreturn\n\"a\"\n},\nfunc\n()\nstring\n{\nreturn\n\"b\"\n})\n// \"a\"\nresult\n:=\nlo\n.\nTernaryF\n(\nfalse\n,\nfunc\n()\nstring\n{\nreturn\n\"a\"\n},\nfunc\n()\nstring\n{\nreturn\n\"b\"\n})\n// \"b\"\nUseful to avoid nil-pointer dereferencing in initializations, or avoid running unnecessary code\nvar\ns\n*\nstring\nsomeStr\n:=\nTernaryF\n(\ns\n==\nnil\n,\nfunc\n()\nstring\n{\nreturn\nuuid\n.\nNew\n().\nString\n() },\nfunc\n()\nstring\n{\nreturn\n*\ns\n})\n// ef782193-c30c-4e2e-a7ae-f8ab5e125e02\n[\nplay\n]\nIf / ElseIf / Else\nresult\n:=\nlo\n.\nIf\n(\ntrue\n,\n1\n).\nElseIf\n(\nfalse\n,\n2\n).\nElse\n(\n3\n)\n// 1\nresult\n:=\nlo\n.\nIf\n(\nfalse\n,\n1\n).\nElseIf\n(\ntrue\n,\n2\n).\nElse\n(\n3\n)\n// 2\nresult\n:=\nlo\n.\nIf\n(\nfalse\n,\n1\n).\nElseIf\n(\nfalse\n,\n2\n).\nElse\n(\n3\n)\n// 3\nUsing callbacks:\nresult\n:=\nlo\n.\nIfF\n(\ntrue\n,\nfunc\n()\nint\n{\nreturn\n1\n}).\nElseIfF\n(\nfalse\n,\nfunc\n()\nint\n{\nreturn\n2\n}).\nElseF\n(\nfunc\n()\nint\n{\nreturn\n3\n})\n// 1\nMixed:\nresult\n:=\nlo\n.\nIfF\n(\ntrue\n,\nfunc\n()\nint\n{\nreturn\n1\n}).\nElse\n(\n42\n)\n// 1\n[\nplay\n]\nSwitch / Case / Default\nresult\n:=\nlo\n.\nSwitch\n(\n1\n).\nCase\n(\n1\n,\n\"1\"\n).\nCase\n(\n2\n,\n\"2\"\n).\nDefault\n(\n\"3\"\n)\n// \"1\"\nresult\n:=\nlo\n.\nSwitch\n(\n2\n).\nCase\n(\n1\n,\n\"1\"\n).\nCase\n(\n2\n,\n\"2\"\n).\nDefault\n(\n\"3\"\n)\n// \"2\"\nresult\n:=\nlo\n.\nSwitch\n(\n42\n).\nCase\n(\n1\n,\n\"1\"\n).\nCase\n(\n2\n,\n\"2\"\n).\nDefault\n(\n\"3\"\n)\n// \"3\"\nUsing callbacks:\nresult\n:=\nlo\n.\nSwitch\n(\n1\n).\nCaseF\n(\n1\n,\nfunc\n()\nstring\n{\nreturn\n\"1\"\n}).\nCaseF\n(\n2\n,\nfunc\n()\nstring\n{\nreturn\n\"2\"\n}).\nDefaultF\n(\nfunc\n()\nstring\n{\nreturn\n\"3\"\n})\n// \"1\"\nMixed:\nresult\n:=\nlo\n.\nSwitch\n(\n1\n).\nCaseF\n(\n1\n,\nfunc\n()\nstring\n{\nreturn\n\"1\"\n}).\nDefault\n(\n\"42\"\n)\n// \"1\"\n[\nplay\n]\nIsNil\nChecks if a value is nil or if it's a reference type with a nil underlying value.\nvar\nx\nint\nlo\n.\nIsNil\n(\nx\n)\n// false\nvar\nk\nstruct\n{}\nlo\n.\nIsNil\n(\nk\n)\n// false\nvar\ni\n*\nint\nlo\n.\nIsNil\n(\ni\n)\n// true\nvar\nifaceWithNilValue\nany\n=\n(\n*\nstring\n)(\nnil\n)\nlo\n.\nIsNil\n(\nifaceWithNilValue\n)\n// true\nifaceWithNilValue\n==\nnil\n// false\nIsNotNil\nChecks if a value is not nil or if it's not a reference type with a nil underlying value.\nvar\nx\nint\nlo\n.\nIsNotNil\n(\nx\n)\n// true\nvar\nk\nstruct\n{}\nlo\n.\nIsNotNil\n(\nk\n)\n// true\nvar\ni\n*\nint\nlo\n.\nIsNotNil\n(\ni\n)\n// false\nvar\nifaceWithNilValue\nany\n=\n(\n*\nstring\n)(\nnil\n)\nlo\n.\nIsNotNil\n(\nifaceWithNilValue\n)\n// false\nifaceWithNilValue\n==\nnil\n// true\nToPtr\nReturns a pointer copy of the value.\nptr\n:=\nlo\n.\nToPtr\n(\n\"hello world\"\n)\n// *string{\"hello world\"}\n[\nplay\n]\nNil\nReturns a nil pointer of type.\nptr\n:=\nlo\n.\nNil\n[\nfloat64\n]()\n// nil\nEmptyableToPtr\nReturns a pointer copy of value if it's nonzero.\nOtherwise, returns nil pointer.\nptr\n:=\nlo\n.\nEmptyableToPtr\n(\nnil\n)\n// nil\nptr\n:=\nlo\n.\nEmptyableToPtr\n(\n\"\"\n)\n// nil\nptr\n:=\nlo\n.\nEmptyableToPtr\n([]\nint\n{})\n// *[]int{}\nptr\n:=\nlo\n.\nEmptyableToPtr\n(\n\"hello world\"\n)\n// *string{\"hello world\"}\nFromPtr\nReturns the pointer value or empty.\nstr\n:=\n\"hello world\"\nvalue\n:=\nlo\n.\nFromPtr\n(\n&\nstr\n)\n// \"hello world\"\nvalue\n:=\nlo\n.\nFromPtr\n(\nnil\n)\n// \"\"\nFromPtrOr\nReturns the pointer value or the fallback value.\nstr\n:=\n\"hello world\"\nvalue\n:=\nlo\n.\nFromPtrOr\n(\n&\nstr\n,\n\"empty\"\n)\n// \"hello world\"\nvalue\n:=\nlo\n.\nFromPtrOr\n(\nnil\n,\n\"empty\"\n)\n// \"empty\"\nToSlicePtr\nReturns a slice of pointers to each value.\nptr\n:=\nlo\n.\nToSlicePtr\n([]\nstring\n{\n\"hello\"\n,\n\"world\"\n})\n// []*string{\"hello\", \"world\"}\nFromSlicePtr\nReturns a slice with the pointer values.\nReturns a zero value in case of a nil pointer element.\nstr1\n:=\n\"hello\"\nstr2\n:=\n\"world\"\nptr\n:=\nlo.\nFromSlicePtr\n[\nstring\n]([]\n*\nstring\n{\n&\nstr1\n,\n&\nstr2\n,\nnil\n})\n// []string{\"hello\", \"world\", \"\"}\nptr\n:=\nlo\n.\nCompact\n(\n    lo.\nFromSlicePtr\n[\nstring\n]([]\n*\nstring\n{\n&\nstr1\n,\n&\nstr2\n,\nnil\n}),\n)\n// []string{\"hello\", \"world\"}\nFromSlicePtrOr\nReturns a slice with the pointer values or the fallback value.\nstr1\n:=\n\"hello\"\nstr2\n:=\n\"world\"\nptr\n:=\nlo\n.\nFromSlicePtrOr\n([]\n*\nstring\n{\n&\nstr1\n,\nnil\n,\n&\nstr2\n},\n\"fallback value\"\n)\n// []string{\"hello\", \"fallback value\", \"world\"}\n[\nplay\n]\nToAnySlice\nReturns a slice with all elements mapped to\nany\ntype.\nelements\n:=\nlo\n.\nToAnySlice\n([]\nint\n{\n1\n,\n5\n,\n1\n})\n// []any{1, 5, 1}\nFromAnySlice\nReturns a slice with all elements mapped to a type. Returns false in case of type conversion failure.\nelements\n,\nok\n:=\nlo\n.\nFromAnySlice\n([]\nany\n{\n\"foobar\"\n,\n42\n})\n// []string{}, false\nelements\n,\nok\n:=\nlo\n.\nFromAnySlice\n([]\nany\n{\n\"foobar\"\n,\n\"42\"\n})\n// []string{\"foobar\", \"42\"}, true\nEmpty\nReturns the\nzero value\n.\nlo\n.\nEmpty\n[\nint\n]()\n// 0\nlo\n.\nEmpty\n[\nstring\n]()\n// \"\"\nlo\n.\nEmpty\n[\nbool\n]()\n// false\nIsEmpty\nReturns true if argument is a zero value.\nlo\n.\nIsEmpty\n(\n0\n)\n// true\nlo\n.\nIsEmpty\n(\n42\n)\n// false\nlo\n.\nIsEmpty\n(\n\"\"\n)\n// true\nlo\n.\nIsEmpty\n(\n\"foobar\"\n)\n// false\ntype\ntest\nstruct\n{\nfoobar\nstring\n}\nlo\n.\nIsEmpty\n(\ntest\n{\nfoobar\n:\n\"\"\n})\n// true\nlo\n.\nIsEmpty\n(\ntest\n{\nfoobar\n:\n\"foobar\"\n})\n// false\nIsNotEmpty\nReturns true if argument is a zero value.\nlo\n.\nIsNotEmpty\n(\n0\n)\n// false\nlo\n.\nIsNotEmpty\n(\n42\n)\n// true\nlo\n.\nIsNotEmpty\n(\n\"\"\n)\n// false\nlo\n.\nIsNotEmpty\n(\n\"foobar\"\n)\n// true\ntype\ntest\nstruct\n{\nfoobar\nstring\n}\nlo\n.\nIsNotEmpty\n(\ntest\n{\nfoobar\n:\n\"\"\n})\n// false\nlo\n.\nIsNotEmpty\n(\ntest\n{\nfoobar\n:\n\"foobar\"\n})\n// true\nCoalesce\nReturns the first non-empty arguments. Arguments must be comparable.\nresult\n,\nok\n:=\nlo\n.\nCoalesce\n(\n0\n,\n1\n,\n2\n,\n3\n)\n// 1 true\nresult\n,\nok\n:=\nlo\n.\nCoalesce\n(\n\"\"\n)\n// \"\" false\nvar\nnilStr\n*\nstring\nstr\n:=\n\"foobar\"\nresult\n,\nok\n:=\nlo\n.\nCoalesce\n(\nnil\n,\nnilStr\n,\n&\nstr\n)\n// &\"foobar\" true\nCoalesceOrEmpty\nReturns the first non-empty arguments. Arguments must be comparable.\nresult\n:=\nlo\n.\nCoalesceOrEmpty\n(\n0\n,\n1\n,\n2\n,\n3\n)\n// 1\nresult\n:=\nlo\n.\nCoalesceOrEmpty\n(\n\"\"\n)\n// \"\"\nvar\nnilStr\n*\nstring\nstr\n:=\n\"foobar\"\nresult\n:=\nlo\n.\nCoalesceOrEmpty\n(\nnil\n,\nnilStr\n,\n&\nstr\n)\n// &\"foobar\"\nCoalesceSlice\nReturns the first non-zero slice.\nresult\n,\nok\n:=\nlo\n.\nCoalesceSlice\n([]\nint\n{\n1\n,\n2\n,\n3\n}, []\nint\n{\n4\n,\n5\n,\n6\n})\n// [1, 2, 3]\n// true\nresult\n,\nok\n:=\nlo\n.\nCoalesceSlice\n(\nnil\n, []\nint\n{})\n// []\n// true\nresult\n,\nok\n:=\nlo\n.\nCoalesceSlice\n([]\nint\n(\nnil\n))\n// []\n// false\nCoalesceSliceOrEmpty\nReturns the first non-zero slice.\nresult\n:=\nlo\n.\nCoalesceSliceOrEmpty\n([]\nint\n{\n1\n,\n2\n,\n3\n}, []\nint\n{\n4\n,\n5\n,\n6\n})\n// [1, 2, 3]\nresult\n:=\nlo\n.\nCoalesceSliceOrEmpty\n(\nnil\n, []\nint\n{})\n// []\nCoalesceMap\nReturns the first non-zero map.\nresult\n,\nok\n:=\nlo\n.\nCoalesceMap\n(\nmap\n[\nstring\n]\nint\n{\n\"1\"\n:\n1\n,\n\"2\"\n:\n2\n,\n\"3\"\n:\n3\n},\nmap\n[\nstring\n]\nint\n{\n\"4\"\n:\n4\n,\n\"5\"\n:\n5\n,\n\"6\"\n:\n6\n})\n// {\"1\": 1, \"2\": 2, \"3\": 3}\n// true\nresult\n,\nok\n:=\nlo\n.\nCoalesceMap\n(\nnil\n,\nmap\n[\nstring\n]\nint\n{})\n// {}\n// true\nresult\n,\nok\n:=\nlo\n.\nCoalesceMap\n(\nmap\n[\nstring\n]\nint\n(\nnil\n))\n// {}\n// false\nCoalesceMapOrEmpty\nReturns the first non-zero map.\nresult\n:=\nlo\n.\nCoalesceMapOrEmpty\n(\nmap\n[\nstring\n]\nint\n{\n\"1\"\n:\n1\n,\n\"2\"\n:\n2\n,\n\"3\"\n:\n3\n},\nmap\n[\nstring\n]\nint\n{\n\"4\"\n:\n4\n,\n\"5\"\n:\n5\n,\n\"6\"\n:\n6\n})\n// {\"1\": 1, \"2\": 2, \"3\": 3}\nresult\n:=\nlo\n.\nCoalesceMapOrEmpty\n(\nnil\n,\nmap\n[\nstring\n]\nint\n{})\n// {}\nPartial\nReturns new function that, when called, has its first argument set to the provided value.\nadd\n:=\nfunc\n(\nx\n,\ny\nint\n)\nint\n{\nreturn\nx\n+\ny\n}\nf\n:=\nlo\n.\nPartial\n(\nadd\n,\n5\n)\nf\n(\n10\n)\n// 15\nf\n(\n42\n)\n// 47\n[\nplay\n]\nPartial2 -> Partial5\nReturns new function that, when called, has its first argument set to the provided value.\nadd\n:=\nfunc\n(\nx\n,\ny\n,\nz\nint\n)\nint\n{\nreturn\nx\n+\ny\n+\nz\n}\nf\n:=\nlo\n.\nPartial2\n(\nadd\n,\n42\n)\nf\n(\n10\n,\n5\n)\n// 57\nf\n(\n42\n,\n-\n4\n)\n// 80\n[\nplay\n]\nAttempt\nInvokes a function N times until it returns valid output. Returns either the caught error or nil.\nWhen the first argument is less than\n1\n, the function runs until a successful response is returned.\niter\n,\nerr\n:=\nlo\n.\nAttempt\n(\n42\n,\nfunc\n(\ni\nint\n)\nerror\n{\nif\ni\n==\n5\n{\nreturn\nnil\n}\nreturn\nerrors\n.\nNew\n(\n\"failed\"\n)\n})\n// 6\n// nil\niter\n,\nerr\n:=\nlo\n.\nAttempt\n(\n2\n,\nfunc\n(\ni\nint\n)\nerror\n{\nif\ni\n==\n5\n{\nreturn\nnil\n}\nreturn\nerrors\n.\nNew\n(\n\"failed\"\n)\n})\n// 2\n// error \"failed\"\niter\n,\nerr\n:=\nlo\n.\nAttempt\n(\n0\n,\nfunc\n(\ni\nint\n)\nerror\n{\nif\ni\n<\n42\n{\nreturn\nerrors\n.\nNew\n(\n\"failed\"\n)\n    }\nreturn\nnil\n})\n// 43\n// nil\nFor more advanced retry strategies (delay, exponential backoff...), please take a look at\ncenkalti/backoff\n.\n[\nplay\n]\nAttemptWithDelay\nInvokes a function N times until it returns valid output, with a pause between each call. Returns either the caught error or nil.\nWhen the first argument is less than\n1\n, the function runs until a successful response is returned.\niter\n,\nduration\n,\nerr\n:=\nlo\n.\nAttemptWithDelay\n(\n5\n,\n2\n*\ntime\n.\nSecond\n,\nfunc\n(\ni\nint\n,\nduration\ntime.\nDuration\n)\nerror\n{\nif\ni\n==\n2\n{\nreturn\nnil\n}\nreturn\nerrors\n.\nNew\n(\n\"failed\"\n)\n})\n// 3\n// ~ 4 seconds\n// nil\nFor more advanced retry strategies (delay, exponential backoff...), please take a look at\ncenkalti/backoff\n.\n[\nplay\n]\nAttemptWhile\nInvokes a function N times until it returns valid output. Returns either the caught error or nil, along with a bool value to determine whether the function should be invoked again. It will terminate the invoke immediately if the second return value is false.\nWhen the first argument is less than\n1\n, the function runs until a successful response is returned.\ncount1\n,\nerr1\n:=\nlo\n.\nAttemptWhile\n(\n5\n,\nfunc\n(\ni\nint\n) (\nerror\n,\nbool\n) {\nerr\n:=\ndoMockedHTTPRequest\n(\ni\n)\nif\nerr\n!=\nnil\n{\nif\nerrors\n.\nIs\n(\nerr\n,\nErrBadRequest\n) {\n// let's assume ErrBadRequest is a critical error that needs to terminate the invoke\nreturn\nerr\n,\nfalse\n// flag the second return value as false to terminate the invoke\n}\nreturn\nerr\n,\ntrue\n}\nreturn\nnil\n,\nfalse\n})\nFor more advanced retry strategies (delay, exponential backoff...), please take a look at\ncenkalti/backoff\n.\n[\nplay\n]\nAttemptWhileWithDelay\nInvokes a function N times until it returns valid output, with a pause between each call. Returns either the caught error or nil, along with a bool value to determine whether the function should be invoked again. It will terminate the invoke immediately if the second return value is false.\nWhen the first argument is less than\n1\n, the function runs until a successful response is returned.\ncount1\n,\ntime1\n,\nerr1\n:=\nlo\n.\nAttemptWhileWithDelay\n(\n5\n,\ntime\n.\nMillisecond\n,\nfunc\n(\ni\nint\n,\nd\ntime.\nDuration\n) (\nerror\n,\nbool\n) {\nerr\n:=\ndoMockedHTTPRequest\n(\ni\n)\nif\nerr\n!=\nnil\n{\nif\nerrors\n.\nIs\n(\nerr\n,\nErrBadRequest\n) {\n// let's assume ErrBadRequest is a critical error that needs to terminate the invoke\nreturn\nerr\n,\nfalse\n// flag the second return value as false to terminate the invoke\n}\nreturn\nerr\n,\ntrue\n}\nreturn\nnil\n,\nfalse\n})\nFor more advanced retry strategies (delay, exponential backoff...), please take a look at\ncenkalti/backoff\n.\n[\nplay\n]\nDebounce\nNewDebounce\ncreates a debounced instance that delays invoking functions given until after wait milliseconds have elapsed, until\ncancel\nis called.\nf\n:=\nfunc\n() {\nprintln\n(\n\"Called once after 100ms when debounce stopped invoking!\"\n)\n}\ndebounce\n,\ncancel\n:=\nlo\n.\nNewDebounce\n(\n100\n*\ntime\n.\nMillisecond\n,\nf\n)\nfor\nj\n:=\n0\n;\nj\n<\n10\n;\nj\n++\n{\ndebounce\n()\n}\ntime\n.\nSleep\n(\n1\n*\ntime\n.\nSecond\n)\ncancel\n()\n[\nplay\n]\nDebounceBy\nNewDebounceBy\ncreates a debounced instance for each distinct key, that delays invoking functions given until after wait milliseconds have elapsed, until\ncancel\nis called.\nf\n:=\nfunc\n(\nkey\nstring\n,\ncount\nint\n) {\nprintln\n(\nkey\n+\n\": Called once after 100ms when debounce stopped invoking!\"\n)\n}\ndebounce\n,\ncancel\n:=\nlo\n.\nNewDebounceBy\n(\n100\n*\ntime\n.\nMillisecond\n,\nf\n)\nfor\nj\n:=\n0\n;\nj\n<\n10\n;\nj\n++\n{\ndebounce\n(\n\"first key\"\n)\ndebounce\n(\n\"second key\"\n)\n}\ntime\n.\nSleep\n(\n1\n*\ntime\n.\nSecond\n)\ncancel\n(\n\"first key\"\n)\ncancel\n(\n\"second key\"\n)\n[\nplay\n]\nThrottle\nCreates a throttled instance that invokes given functions only once in every interval.\nThis returns 2 functions, First one is throttled function and Second one is a function to reset interval.\nf\n:=\nfunc\n() {\nprintln\n(\n\"Called once in every 100ms\"\n)\n}\nthrottle\n,\nreset\n:=\nlo\n.\nNewThrottle\n(\n100\n*\ntime\n.\nMillisecond\n,\nf\n)\nfor\nj\n:=\n0\n;\nj\n<\n10\n;\nj\n++\n{\nthrottle\n()\ntime\n.\nSleep\n(\n30\n*\ntime\n.\nMillisecond\n)\n}\nreset\n()\nthrottle\n()\nNewThrottleWithCount\nis NewThrottle with count limit, throttled function will be invoked count times in every interval.\nf\n:=\nfunc\n() {\nprintln\n(\n\"Called three times in every 100ms\"\n)\n}\nthrottle\n,\nreset\n:=\nlo\n.\nNewThrottleWithCount\n(\n100\n*\ntime\n.\nMillisecond\n,\nf\n)\nfor\nj\n:=\n0\n;\nj\n<\n10\n;\nj\n++\n{\nthrottle\n()\ntime\n.\nSleep\n(\n30\n*\ntime\n.\nMillisecond\n)\n}\nreset\n()\nthrottle\n()\nNewThrottleBy\nand\nNewThrottleByWithCount\nare NewThrottle with sharding key, throttled function will be invoked count times in every interval.\nf\n:=\nfunc\n(\nkey\nstring\n) {\nprintln\n(\nkey\n,\n\"Called three times in every 100ms\"\n)\n}\nthrottle\n,\nreset\n:=\nlo\n.\nNewThrottleByWithCount\n(\n100\n*\ntime\n.\nMillisecond\n,\nf\n)\nfor\nj\n:=\n0\n;\nj\n<\n10\n;\nj\n++\n{\nthrottle\n(\n\"foo\"\n)\ntime\n.\nSleep\n(\n30\n*\ntime\n.\nMillisecond\n)\n}\nreset\n()\nthrottle\n()\nSynchronize\nWraps the underlying callback in a mutex. It receives an optional mutex.\ns\n:=\nlo\n.\nSynchronize\n()\nfor\ni\n:=\n0\n;\ni\n<\n10\n;\ni\n++\n{\ngo\ns\n.\nDo\n(\nfunc\n() {\nprintln\n(\n\"will be called sequentially\"\n)\n    })\n}\nIt is equivalent to:\nmu\n:=\nsync.\nMutex\n{}\nfunc\nfoobar\n() {\nmu\n.\nLock\n()\ndefer\nmu\n.\nUnlock\n()\n// ...\n}\nAsync\nExecutes a function in a goroutine and returns the result in a channel.\nch\n:=\nlo\n.\nAsync\n(\nfunc\n()\nerror\n{\ntime\n.\nSleep\n(\n10\n*\ntime\n.\nSecond\n);\nreturn\nnil\n})\n// chan error (nil)\nAsync{0->6}\nExecutes a function in a goroutine and returns the result in a channel.\nFor functions with multiple return values, the results will be returned as a tuple inside the channel.\nFor functions without return, struct{} will be returned in the channel.\nch\n:=\nlo\n.\nAsync0\n(\nfunc\n() {\ntime\n.\nSleep\n(\n10\n*\ntime\n.\nSecond\n) })\n// chan struct{}\nch\n:=\nlo\n.\nAsync1\n(\nfunc\n()\nint\n{\ntime\n.\nSleep\n(\n10\n*\ntime\n.\nSecond\n);\nreturn\n42\n})\n// chan int (42)\nch\n:=\nlo\n.\nAsync2\n(\nfunc\n() (\nint\n,\nstring\n) {\ntime\n.\nSleep\n(\n10\n*\ntime\n.\nSecond\n);\nreturn\n42\n,\n\"Hello\"\n})\n// chan lo.Tuple2[int, string] ({42, \"Hello\"})\nTransaction\nImplements a Saga pattern.\ntransaction\n:=\nNewTransaction\n().\nThen\n(\nfunc\n(\nstate\nint\n) (\nint\n,\nerror\n) {\nfmt\n.\nPrintln\n(\n\"step 1\"\n)\nreturn\nstate\n+\n10\n,\nnil\n},\nfunc\n(\nstate\nint\n)\nint\n{\nfmt\n.\nPrintln\n(\n\"rollback 1\"\n)\nreturn\nstate\n-\n10\n},\n    ).\nThen\n(\nfunc\n(\nstate\nint\n) (\nint\n,\nerror\n) {\nfmt\n.\nPrintln\n(\n\"step 2\"\n)\nreturn\nstate\n+\n15\n,\nnil\n},\nfunc\n(\nstate\nint\n)\nint\n{\nfmt\n.\nPrintln\n(\n\"rollback 2\"\n)\nreturn\nstate\n-\n15\n},\n    ).\nThen\n(\nfunc\n(\nstate\nint\n) (\nint\n,\nerror\n) {\nfmt\n.\nPrintln\n(\n\"step 3\"\n)\nif\ntrue\n{\nreturn\nstate\n,\nerrors\n.\nNew\n(\n\"error\"\n)\n            }\nreturn\nstate\n+\n42\n,\nnil\n},\nfunc\n(\nstate\nint\n)\nint\n{\nfmt\n.\nPrintln\n(\n\"rollback 3\"\n)\nreturn\nstate\n-\n42\n},\n    )\n_\n,\n_\n=\ntransaction\n.\nProcess\n(\n-\n5\n)\n// Output:\n// step 1\n// step 2\n// step 3\n// rollback 2\n// rollback 1\nWaitFor\nRuns periodically until a condition is validated.\nalwaysTrue\n:=\nfunc\n(\ni\nint\n)\nbool\n{\nreturn\ntrue\n}\nalwaysFalse\n:=\nfunc\n(\ni\nint\n)\nbool\n{\nreturn\nfalse\n}\nlaterTrue\n:=\nfunc\n(\ni\nint\n)\nbool\n{\nreturn\ni\n>\n5\n}\niterations\n,\nduration\n,\nok\n:=\nlo\n.\nWaitFor\n(\nalwaysTrue\n,\n10\n*\ntime\n.\nMillisecond\n,\n2\n*\ntime\n.\nMillisecond\n)\n// 1\n// 1ms\n// true\niterations\n,\nduration\n,\nok\n:=\nlo\n.\nWaitFor\n(\nalwaysFalse\n,\n10\n*\ntime\n.\nMillisecond\n,\ntime\n.\nMillisecond\n)\n// 10\n// 10ms\n// false\niterations\n,\nduration\n,\nok\n:=\nlo\n.\nWaitFor\n(\nlaterTrue\n,\n10\n*\ntime\n.\nMillisecond\n,\ntime\n.\nMillisecond\n)\n// 7\n// 7ms\n// true\niterations\n,\nduration\n,\nok\n:=\nlo\n.\nWaitFor\n(\nlaterTrue\n,\n10\n*\ntime\n.\nMillisecond\n,\n5\n*\ntime\n.\nMillisecond\n)\n// 2\n// 10ms\n// false\n[\nplay\n]\nWaitForWithContext\nRuns periodically until a condition is validated or context is invalid.\nThe condition receives also the context, so it can invalidate the process in the condition checker\nctx\n:=\ncontext\n.\nBackground\n()\nalwaysTrue\n:=\nfunc\n(\n_\ncontext.\nContext\n,\ni\nint\n)\nbool\n{\nreturn\ntrue\n}\nalwaysFalse\n:=\nfunc\n(\n_\ncontext.\nContext\n,\ni\nint\n)\nbool\n{\nreturn\nfalse\n}\nlaterTrue\n:=\nfunc\n(\n_\ncontext.\nContext\n,\ni\nint\n)\nbool\n{\nreturn\ni\n>=\n5\n}\niterations\n,\nduration\n,\nok\n:=\nlo\n.\nWaitForWithContext\n(\nctx\n,\nalwaysTrue\n,\n10\n*\ntime\n.\nMillisecond\n,\n2\n*\ntime\n.\nMillisecond\n)\n// 1\n// 1ms\n// true\niterations\n,\nduration\n,\nok\n:=\nlo\n.\nWaitForWithContext\n(\nctx\n,\nalwaysFalse\n,\n10\n*\ntime\n.\nMillisecond\n,\ntime\n.\nMillisecond\n)\n// 10\n// 10ms\n// false\niterations\n,\nduration\n,\nok\n:=\nlo\n.\nWaitForWithContext\n(\nctx\n,\nlaterTrue\n,\n10\n*\ntime\n.\nMillisecond\n,\ntime\n.\nMillisecond\n)\n// 5\n// 5ms\n// true\niterations\n,\nduration\n,\nok\n:=\nlo\n.\nWaitForWithContext\n(\nctx\n,\nlaterTrue\n,\n10\n*\ntime\n.\nMillisecond\n,\n5\n*\ntime\n.\nMillisecond\n)\n// 2\n// 10ms\n// false\nexpiringCtx\n,\ncancel\n:=\ncontext\n.\nWithTimeout\n(\nctx\n,\n5\n*\ntime\n.\nMillisecond\n)\niterations\n,\nduration\n,\nok\n:=\nlo\n.\nWaitForWithContext\n(\nexpiringCtx\n,\nalwaysFalse\n,\n100\n*\ntime\n.\nMillisecond\n,\ntime\n.\nMillisecond\n)\n// 5\n// 5.1ms\n// false\n[\nplay\n]\nValidate\nHelper function that creates an error when a condition is not met.\nslice\n:=\n[]\nstring\n{\n\"a\"\n}\nval\n:=\nlo\n.\nValidate\n(\nlen\n(\nslice\n)\n==\n0\n,\n\"Slice should be empty but contains %v\"\n,\nslice\n)\n// error(\"Slice should be empty but contains [a]\")\nslice\n:=\n[]\nstring\n{}\nval\n:=\nlo\n.\nValidate\n(\nlen\n(\nslice\n)\n==\n0\n,\n\"Slice should be empty but contains %v\"\n,\nslice\n)\n// nil\n[\nplay\n]\nMust\nWraps a function call and panics if second argument is\nerror\nor\nfalse\n, returns the value otherwise.\nval\n:=\nlo\n.\nMust\n(\ntime\n.\nParse\n(\n\"2006-01-02\"\n,\n\"2022-01-15\"\n))\n// 2022-01-15\nval\n:=\nlo\n.\nMust\n(\ntime\n.\nParse\n(\n\"2006-01-02\"\n,\n\"bad-value\"\n))\n// panics\n[\nplay\n]\nMust{0->6}\nMust* has the same behavior as Must but returns multiple values.\nfunc\nexample0\n() (\nerror\n)\nfunc\nexample1\n() (\nint\n,\nerror\n)\nfunc\nexample2\n() (\nint\n,\nstring\n,\nerror\n)\nfunc\nexample3\n() (\nint\n,\nstring\n, time.\nDate\n,\nerror\n)\nfunc\nexample4\n() (\nint\n,\nstring\n, time.\nDate\n,\nbool\n,\nerror\n)\nfunc\nexample5\n() (\nint\n,\nstring\n, time.\nDate\n,\nbool\n,\nfloat64\n,\nerror\n)\nfunc\nexample6\n() (\nint\n,\nstring\n, time.\nDate\n,\nbool\n,\nfloat64\n,\nbyte\n,\nerror\n)\nlo\n.\nMust0\n(\nexample0\n())\nval1\n:=\nlo\n.\nMust1\n(\nexample1\n())\n// alias to Must\nval1\n,\nval2\n:=\nlo\n.\nMust2\n(\nexample2\n())\nval1\n,\nval2\n,\nval3\n:=\nlo\n.\nMust3\n(\nexample3\n())\nval1\n,\nval2\n,\nval3\n,\nval4\n:=\nlo\n.\nMust4\n(\nexample4\n())\nval1\n,\nval2\n,\nval3\n,\nval4\n,\nval5\n:=\nlo\n.\nMust5\n(\nexample5\n())\nval1\n,\nval2\n,\nval3\n,\nval4\n,\nval5\n,\nval6\n:=\nlo\n.\nMust6\n(\nexample6\n())\nYou can wrap functions like\nfunc (...) (..., ok bool)\n.\n// math.Signbit(float64) bool\nlo\n.\nMust0\n(\nmath\n.\nSignbit\n(\nv\n))\n// bytes.Cut([]byte,[]byte) ([]byte, []byte, bool)\nbefore\n,\nafter\n:=\nlo\n.\nMust2\n(\nbytes\n.\nCut\n(\ns\n,\nsep\n))\nYou can give context to the panic message by adding some printf-like arguments.\nval\n,\nok\n:=\nlo\n.\nFind\n(\nmyString\n,\nfunc\n(\ni\nstring\n)\nbool\n{\nreturn\ni\n==\nrequiredChar\n})\nlo\n.\nMust0\n(\nok\n,\n\"'%s' must always contain '%s'\"\n,\nmyString\n,\nrequiredChar\n)\nlist\n:=\n[]\nint\n{\n0\n,\n1\n,\n2\n}\nitem\n:=\n5\nlo\n.\nMust0\n(\nlo\n.\nContains\n(\nlist\n,\nitem\n),\n\"'%s' must always contain '%s'\"\n,\nlist\n,\nitem\n)\n...\n[\nplay\n]\nTry\nCalls the function and returns false in case of error and panic.\nok\n:=\nlo\n.\nTry\n(\nfunc\n()\nerror\n{\npanic\n(\n\"error\"\n)\nreturn\nnil\n})\n// false\nok\n:=\nlo\n.\nTry\n(\nfunc\n()\nerror\n{\nreturn\nnil\n})\n// true\nok\n:=\nlo\n.\nTry\n(\nfunc\n()\nerror\n{\nreturn\nerrors\n.\nNew\n(\n\"error\"\n)\n})\n// false\n[\nplay\n]\nTry{0->6}\nThe same behavior as\nTry\n, but the callback returns 2 variables.\nok\n:=\nlo\n.\nTry2\n(\nfunc\n() (\nstring\n,\nerror\n) {\npanic\n(\n\"error\"\n)\nreturn\n\"\"\n,\nnil\n})\n// false\n[\nplay\n]\nTryOr\nCalls the function and return a default value in case of error and on panic.\nstr\n,\nok\n:=\nlo\n.\nTryOr\n(\nfunc\n() (\nstring\n,\nerror\n) {\npanic\n(\n\"error\"\n)\nreturn\n\"hello\"\n,\nnil\n},\n\"world\"\n)\n// world\n// false\nstr\n,\nok\n:=\nlo\n.\nTryOr\n(\nfunc\n()\nerror\n{\nreturn\n\"hello\"\n,\nnil\n},\n\"world\"\n)\n// hello\n// true\nstr\n,\nok\n:=\nlo\n.\nTryOr\n(\nfunc\n()\nerror\n{\nreturn\n\"hello\"\n,\nerrors\n.\nNew\n(\n\"error\"\n)\n},\n\"world\"\n)\n// world\n// false\n[\nplay\n]\nTryOr{0->6}\nThe same behavior as\nTryOr\n, but the callback returns\nX\nvariables.\nstr\n,\nnbr\n,\nok\n:=\nlo\n.\nTryOr2\n(\nfunc\n() (\nstring\n,\nint\n,\nerror\n) {\npanic\n(\n\"error\"\n)\nreturn\n\"hello\"\n,\n42\n,\nnil\n},\n\"world\"\n,\n21\n)\n// world\n// 21\n// false\n[\nplay\n]\nTryWithErrorValue\nThe same behavior as\nTry\n, but also returns the value passed to panic.\nerr\n,\nok\n:=\nlo\n.\nTryWithErrorValue\n(\nfunc\n()\nerror\n{\npanic\n(\n\"error\"\n)\nreturn\nnil\n})\n// \"error\", false\n[\nplay\n]\nTryCatch\nThe same behavior as\nTry\n, but calls the catch function in case of error.\ncaught\n:=\nfalse\nok\n:=\nlo\n.\nTryCatch\n(\nfunc\n()\nerror\n{\npanic\n(\n\"error\"\n)\nreturn\nnil\n},\nfunc\n() {\ncaught\n=\ntrue\n})\n// false\n// caught == true\n[\nplay\n]\nTryCatchWithErrorValue\nThe same behavior as\nTryWithErrorValue\n, but calls the catch function in case of error.\ncaught\n:=\nfalse\nok\n:=\nlo\n.\nTryCatchWithErrorValue\n(\nfunc\n()\nerror\n{\npanic\n(\n\"error\"\n)\nreturn\nnil\n},\nfunc\n(\nval\nany\n) {\ncaught\n=\nval\n==\n\"error\"\n})\n// false\n// caught == true\n[\nplay\n]\nErrorsAs\nA shortcut for:\nerr\n:=\ndoSomething\n()\nvar\nrateLimitErr\n*\nRateLimitError\nif\nok\n:=\nerrors\n.\nAs\n(\nerr\n,\n&\nrateLimitErr\n);\nok\n{\n// retry later\n}\nsingle line\nlo\nhelper:\nerr\n:=\ndoSomething\n()\nif\nrateLimitErr\n,\nok\n:=\nlo.\nErrorsAs\n[\n*\nRateLimitError\n](\nerr\n);\nok\n{\n// retry later\n}\n[\nplay\n]\nAssert\nDoes nothing when the condition is\ntrue\n, otherwise it panics with an optional message.\nThink twice before using it, given that\nGo intentionally omits assertions from its standard library\n.\nage\n:=\ngetUserAge\n()\nlo\n.\nAssert\n(\nage\n>=\n15\n)\nage\n:=\ngetUserAge\n()\nlo\n.\nAssert\n(\nage\n>=\n15\n,\n\"user age must be >= 15\"\n)\n[\nplay\n]\nAssertf\nLike\nAssert\n, but with\nfmt.Printf\n-like formatting.\nThink twice before using it, given that\nGo intentionally omits assertions from its standard library\n.\nage\n:=\ngetUserAge\n()\nlo\n.\nAssertf\n(\nage\n>=\n15\n,\n\"user age must be >= 15, got %d\"\n,\nage\n)\n[\nplay\n]\nüõ© Benchmark\nWe executed a simple benchmark with a dead-simple\nlo.Map\nloop:\nSee the full implementation\nhere\n.\n_\n=\nlo\n.\nMap\n[\nint64\n](\narr\n,\nfunc\n(\nx\nint64\n,\ni\nint\n)\nstring\n{\nreturn\nstrconv\n.\nFormatInt\n(\nx\n,\n10\n)\n})\nResult:\nHere is a comparison between\nlo.Map\n,\nlop.Map\n,\ngo-funk\nlibrary and a simple Go\nfor\nloop.\n$ go\ntest\n-benchmem -bench ./...\ngoos: linux\ngoarch: amd64\npkg: github.com/samber/lo\ncpu: Intel(R) Core(TM) i5-7267U CPU @ 3.10GHz\ncpu: Intel(R) Core(TM) i7 CPU         920  @ 2.67GHz\nBenchmarkMap/lo.Map-8         \t       8\t 132728237 ns/op\t39998945 B/op\t 1000002 allocs/op\nBenchmarkMap/lop.Map-8        \t       2\t 503947830 ns/op\t119999956 B/op\t 3000007 allocs/op\nBenchmarkMap/reflect-8        \t       2\t 826400560 ns/op\t170326512 B/op\t 4000042 allocs/op\nBenchmarkMap/for-8            \t       9\t 126252954 ns/op\t39998674 B/op\t 1000001 allocs/op\nPASS\nok  \tgithub.com/samber/lo\t6.657s\nlo.Map\nis way faster (x7) than\ngo-funk\n, a reflection-based Map implementation.\nlo.Map\nhas the same allocation profile as\nfor\n.\nlo.Map\nis 4% slower than\nfor\n.\nlop.Map\nis slower than\nlo.Map\nbecause it implies more memory allocation and locks.\nlop.Map\nis useful for long-running callbacks, such as i/o bound processing.\nfor\nbeats other implementations for memory and CPU.\nü§ù Contributing\nPing me on Twitter\n@samuelberthe\n(DMs, mentions, whatever :))\nFork the\nproject\nFix\nopen issues\nor request new features\nDon't hesitate ;)\nHelper naming: helpers must be self-explanatory and respect standards (other languages, libraries...). Feel free to suggest many names in your contributions.\n#\nInstall some dev dependencies\nmake tools\n#\nRun tests\nmake\ntest\n#\nor\nmake watch-test\nüë§ Contributors\nüí´ Show your support\nGive a ‚≠êÔ∏è if this project helped you!\nüìù License\nCopyright ¬© 2022\nSamuel Berthe\n.\nThis project is under\nMIT\nlicense.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 64",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 20,337"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/samber/lo"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/aaPanel/BillionMail",
      "title": "aaPanel/BillionMail",
      "date": null,
      "executive_summary": [
        "BillionMail gives you open-source MailServer, NewsLetter, Email Marketing ‚Äî fully self-hosted, dev-friendly, and free from monthly fees. Join the discord: https://discord.gg/asfXzBUhZr",
        "---",
        "BillionMail üìß\nAn Open-Source MailServer, NewsLetter, Email Marketing Solution for Smarter Campaigns\nEnglish |\nÁÆÄ‰Ωì‰∏≠Êñá\n|\nÊó•Êú¨Ë™û\n|\nT√ºrk√ße\nWhat is BillionMail?\nBillionMail is a\nfuture open-source Mail server, Email marketing platform\ndesigned to help businesses and individuals manage their email campaigns with ease. Whether you're sending newsletters, promotional emails, or transactional messages, this tool will provide\nfull control\nover your email marketing efforts. With features like\nadvanced analytics\n, and\ncustomer management\n, you'll be able to create, send, and track emails like a pro.\nJust 3 steps to send a billion emails!\nBillion emails. Any business. Guaranteed.\nStep 1Ô∏è‚É£ Install BillionMail:\n‚úÖ It takes\nonly 8Ô∏è‚É£ minutes\nfrom installation to\n‚úÖ successful email sending\ncd\n/opt\n&&\ngit clone https://github.com/aaPanel/BillionMail\n&&\ncd\nBillionMail\n&&\nbash install.sh\nStep 2Ô∏è‚É£: Connect Your Domain\nAdd the sending domain\nVerify DNS records\nAuto-enable free SSL\nStep 3Ô∏è‚É£: Build Your Campaign\nWrite or paste your email\nChoose list & tags\nSet send time or send now\nWatch on Youtube\nOther installation methods\nOne-click installation on aaPanel\nüëâ\nhttps://www.aapanel.com/new/download.html\n(Log in to ‚úÖaaPanel --> üê≥Docker --> 1Ô∏è‚É£OneClick install)\nDocker\ncd\n/opt\n&&\ngit clone https://github.com/aaPanel/BillionMail\n&&\ncd\nBillionMail\n&&\ncp env_init .env\n&&\ndocker compose up -d\n||\ndocker-compose up -d\nManagement script\nManagement help\nbm help\nView Login default info\nbm default\nShow domain DNS record\nbm show-record\nUpdate BillionMail\nbm update\nLive Demo\nBillionMail Demo:\nhttps://demo.billionmail.com/billionmail\nUsername:\nbillionmail\nPassword:\nbillionmail\nWebMail\nBillionMail has integrated\nRoundCube\n, you can access WebMail via\n/roundcube/\n.\nWhy BillionMail?\nMost email marketing platforms are either\nexpensive\n,\nclosed-source\n, or\nlack essential features\n. BillionMail aims to be different:\n‚úÖ\nFully Open-Source\n‚Äì No hidden costs, no vendor lock-in.\nüìä\nAdvanced Analytics\n‚Äì Track email delivery, open rates, click-through rates, and more.\nüìß\nUnlimited Sending\n‚Äì No restrictions on the number of emails you can send.\nüé®\nCustomizable Templates\n‚Äì Custom professional marketing templates for reuse.\nüîí\nPrivacy-First\n‚Äì Your data stays with you, no third-party tracking.\nüöÄ\nSelf-Hosted\n‚Äì Run it on your own server for complete control.\nHow You Can Help üåü\nBillionMail is a\ncommunity-driven project\n, and we need your support to get started! Here's how you can help:\nStar This Repository\n: Show your interest by starring this repo.\nSpread the Word\n: Share BillionMail with your network‚Äîdevelopers, marketers, and open-source enthusiasts.\nShare Feedback\n: Let us know what features you'd like to see in BillionMail by opening an issue or joining the discussion.\nContribute\n: Once development begins, we'll welcome contributions from the community. Stay tuned for updates!\nüìß\nBillionMail ‚Äì The Future of Open-Source Email Marketing.\nIssues\nIf you encounter any issues or have feature requests, please\nopen an issue\n. Be sure to include:\nA clear description of the problem or request.\nSteps to reproduce the issue (if applicable).\nScreenshots or error logs (if applicable).\nInstall Now:\n‚úÖIt takes\nonly 8 minutes\nfrom installation to\nsuccessful email sending\ncd\n/opt\n&&\ngit clone https://github.com/aaPanel/BillionMail\n&&\ncd\nBillionMail\n&&\nbash install.sh\nInstall with Docker:\n(Please install Docker and docker-compose-plugin manually, and modify .env file)\ncd\n/opt\n&&\ngit clone https://github.com/aaPanel/BillionMail\n&&\ncd\nBillionMail\n&&\ncp env_init .env\n&&\ndocker compose up -d\n||\ndocker-compose up -d\nStar History\nLicense\nBillionMail is licensed under the\nAGPLv3 License\n. This means you can:\n‚úÖ Use the software for free.\n‚úÖ Modify and distribute the code.\n‚úÖ Use it privately without restrictions.\nSee the\nLICENSE\nfile for more details.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 54",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 11,553"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/aaPanel/BillionMail"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/ruvnet/claude-flow",
      "title": "ruvnet/claude-flow",
      "date": null,
      "executive_summary": [
        "üåä The leading agent orchestration platform for Claude. Deploy intelligent multi-agent swarms, coordinate autonomous workflows, and build conversational AI systems. Features enterprise-grade architecture, distributed swarm intelligence, RAG integration, and native Claude Code support via MCP protocol. Ranked #1 in agent-based frameworks.",
        "---",
        "üåä Claude-Flow v2.5.0 Alpha 140: AI Orchestration Platform\nüåü\nOverview\nClaude-Flow v2 Alpha\nis an enterprise-grade AI orchestration platform that reimagines how developers build with AI. By combining\nhive-mind swarm intelligence\n,\nneural pattern recognition\n, and\n87 advanced MCP tools\n, Claude-Flow enables unprecedented AI-powered development workflows.\nüéØ\nKey Features\nüêù Hive-Mind Intelligence\n: Queen-led AI coordination with specialized worker agents\nüß† Neural Networks\n: 27+ cognitive models with WASM SIMD acceleration\nüîß 87 MCP Tools\n: Comprehensive toolkit for swarm orchestration, memory, and automation\nüîÑ Dynamic Agent Architecture (DAA)\n: Self-organizing agents with fault tolerance\nüíæ SQLite Memory System\n: Persistent\n.swarm/memory.db\nwith 12 specialized tables\nü™ù Advanced Hooks System\n: Automated workflows with pre/post operation hooks\nüìä GitHub Integration\n: 6 specialized modes for repository management\nüåê Flow Nexus Cloud Platform\n: E2B sandboxes, AI swarms, challenges, and marketplace integration\nüéØ PreToolUse Modification Hooks\n: NEW - Claude Code v2.0.10+ intelligent input modification (safety, organization, optimization)\nüî•\nRevolutionary AI Coordination\n: Build faster, smarter, and more efficiently with AI-powered development orchestration\nüéØ\nNEW: PreToolUse Modification Hooks Plugin\n(v2.5.0-alpha.140)\nFirst Claude Code plugin with intelligent tool input modification\n- automatically enhances commands and files before execution.\nKey Features:\nüõ°Ô∏è\nSafety\n: Auto-adds\n-i\nto\nrm\ncommands, detects sensitive keywords\nüìÅ\nOrganization\n: Auto-routes files (tests‚Üí\n/tests/\n, src‚Üí\n/src/\n)\n‚ö°\nProductivity\n: Alias expansion (\nll\n‚Üí\nls -lah\n), conventional commits\nQuick Start:\nOption 1: Direct Plugin Installation\n(Recommended)\n#\nIn Claude Code, run:\n/plugin ruvnet/claude-flow\nOption 2: Via NPM\nnpx claude-flow@alpha init --force\n#\nAuto-configures .claude-plugin/hooks/hooks.json\nExamples:\nrm test.txt          ‚Üí rm -i test.txt\n#\nSafety\ntest.js             ‚Üí src/test.js\n#\nOrganization\ngit commit -m\n\"\nfix\n\"\n‚Üí [fix] fix + co-author\n#\nCommits\nüìö\nDocs\n:\nHOOKS-V2-MODIFICATION.md\n|\nPlugin\n:\n.claude-plugin/\n|\nComposable\nwith\nagent-booster\nüåê\nFlow Nexus Cloud Platform\nNEW\n: Claude-Flow v2.0.0 now includes\nFlow Nexus integration\n- a cloud-powered AI development platform featuring:\nE2B Sandboxes\n: Secure isolated environments for Node.js, Python, React, Next.js\nAI Swarms\n: Deploy multi-agent systems in cloud infrastructure\nNeural Training\n: Distributed machine learning with custom model deployment\nChallenges & Marketplace\n: Coding challenges with rUv credit rewards and template marketplace\nWorkflow Automation\n: Event-driven automation with message queue processing\nüìö\nComplete documentation\n: Visit\nflow-nexus.ruv.io\nfor comprehensive guides, tutorials, and API reference. Also see issue #\n#732\n‚ö°\nTry v2.0.0 Alpha in 4 Commands\nüìã\nPrerequisites\nNode.js 18+\n(LTS recommended)\nnpm 9+\nor equivalent package manager\nWindows users\n: See\nWindows Installation Guide\nfor special instructions\n‚ö†Ô∏è\nIMPORTANT\n: Claude Code must be installed first:\n#\n1. Install Claude Code globally\nnpm install -g @anthropic-ai/claude-code\n#\n2. (Optional) Skip permissions check for faster setup\n#\nOnly use if you understand the security implications\nclaude --dangerously-skip-permissions\nüí°\nWindows Note\n: If you encounter SQLite errors, Claude Flow will automatically use in-memory storage. For persistent storage options, see our\nWindows guide\n.\nüéØ\nInstant Alpha Testing\nMethod 1: Plugin Installation\n(Easiest - includes PreToolUse hooks!)\n#\nIn Claude Code:\n/plugin ruvnet/claude-flow\nMethod 2: NPM Installation\n(For MCP server + CLI)\n#\n1. Initialize Claude Flow with enhanced MCP setup (auto-configures permissions!)\nnpx claude-flow@alpha init --force\n#\n2. Explore all revolutionary capabilities\nnpx claude-flow@alpha --help\n#\n3a. Quick AI coordination (recommended for most tasks)\nnpx claude-flow@alpha swarm\n\"\nbuild me a REST API\n\"\n--claude\n#\n3b. OR launch the full hive-mind system (for complex projects)\nnpx claude-flow@alpha hive-mind wizard\nnpx claude-flow@alpha hive-mind spawn\n\"\nbuild enterprise system\n\"\n--claude\nüöÄ\nQuick Start with Flow Nexus\n#\n1. Initialize Flow Nexus only (minimal setup)\nnpx claude-flow init --flow-nexus\n#\n2. Register and login (use MCP tools in Claude Code)\nmcp__flow-nexus__user_register({ email:\n\"\nyour@email.com\n\"\n, password:\n\"\nsecure\n\"\n})\nmcp__flow-nexus__user_login({ email:\n\"\nyour@email.com\n\"\n, password:\n\"\nsecure\n\"\n})\n#\n3. Deploy your first cloud swarm\nmcp__flow-nexus__swarm_init({ topology:\n\"\nmesh\n\"\n, maxAgents: 5 })\nmcp__flow-nexus__sandbox_create({ template:\n\"\nnode\n\"\n, name:\n\"\napi-dev\n\"\n})\nü§î\nSwarm vs Hive-Mind: Which to Use?\nFeature\nswarm\nCommand\nhive-mind\nCommand\nBest For\nQuick tasks, single objectives\nComplex projects, persistent sessions\nSetup\nInstant - no configuration needed\nInteractive wizard setup\nSession\nTemporary coordination\nPersistent with resume capability\nMemory\nTask-scoped\nProject-wide with SQLite storage\nAgents\nAuto-spawned for task\nManual control with specializations\nUse When\n\"Build X\", \"Fix Y\", \"Analyze Z\"\nMulti-feature projects, team coordination\nQuick Rule:\nStart with\nswarm\nfor most tasks. Use\nhive-mind\nwhen you need persistent sessions or complex multi-agent coordination.\nüéØ\nTypical Workflows - Your \"Happy Path\" Guide\nNew to Claude-Flow? Start Here!\nConfused about\n.hive-mind\nand\n.swarm\ndirectories? Not sure when to create new hives? Here are the most common workflow patterns:\nüöÄ Pattern 1: Single Feature Development\n#\nInitialize once per feature/task\nnpx claude-flow@alpha init --force\nnpx claude-flow@alpha hive-mind spawn\n\"\nImplement user authentication\n\"\n--claude\n#\nContinue working on SAME feature (reuse existing hive)\nnpx claude-flow@alpha hive-mind status\nnpx claude-flow@alpha memory query\n\"\nauthentication\n\"\n--recent\nnpx claude-flow@alpha swarm\n\"\nAdd password reset functionality\n\"\n--continue-session\nüèóÔ∏è Pattern 2: Multi-Feature Project\n#\nProject-level initialization (once per project)\nnpx claude-flow@alpha init --force --project-name\n\"\nmy-app\n\"\n#\nFeature 1: Authentication (new hive)\nnpx claude-flow@alpha hive-mind spawn\n\"\nauth-system\n\"\n--namespace auth --claude\n#\nFeature 2: User management (separate hive)\nnpx claude-flow@alpha hive-mind spawn\n\"\nuser-management\n\"\n--namespace users --claude\n#\nResume Feature 1 later (use session ID from spawn output)\nnpx claude-flow@alpha hive-mind resume session-xxxxx-xxxxx\nüîç Pattern 3: Research & Analysis\n#\nStart research session\nnpx claude-flow@alpha hive-mind spawn\n\"\nResearch microservices patterns\n\"\n--agents researcher,analyst --claude\n#\nContinue research in SAME session\nnpx claude-flow@alpha memory stats\n#\nSee what's been learned\nnpx claude-flow@alpha swarm\n\"\nDeep dive into API gateway patterns\n\"\n--continue-session\nü§î When Should I Create a New Hive?\nSituation\nAction\nCommand\nSame objective/feature\nContinue existing hive\nnpx claude-flow@alpha hive-mind resume <session-id>\nNew feature in same project\nCreate new hive with namespace\nnpx claude-flow@alpha hive-mind spawn \"new-feature\" --namespace feature-name\nCompletely different project\nNew directory + init\nmkdir new-project && cd new-project && npx claude-flow@alpha init\nExperimenting/testing\nTemporary hive\nnpx claude-flow@alpha hive-mind spawn \"experiment\" --temp\nüìÅ Understanding \"Empty\" Directories\nDon't panic if directories seem empty!\nClaude-Flow uses SQLite databases that may not show files in directory listings:\n#\nCheck what's actually stored (even if directories look empty)\nnpx claude-flow@alpha memory stats\n#\nSee memory data\nnpx claude-flow@alpha memory list\n#\nList all namespaces\nnpx claude-flow@alpha hive-mind status\n#\nSee active hives\n#\nYour project structure after initialization:\n#\n.hive-mind/     <- Contains config.json + SQLite session data\n#\n.swarm/         <- Contains memory.db (SQLite database)\n#\nmemory/         <- Agent-specific memories (created when agents spawn)\n#\ncoordination/   <- Active workflow files (created during tasks)\nüîÑ Continuing Previous Work\n#\nSee what you were working on\nnpx claude-flow@alpha hive-mind status\nnpx claude-flow@alpha memory query --recent --limit 5\n#\nList all sessions to find the one you want\nnpx claude-flow@alpha hive-mind sessions\n#\nResume specific session by ID\nnpx claude-flow@alpha hive-mind resume session-xxxxx-xxxxx\nü™ù\nAdvanced Hooks System\nAutomated Workflow Enhancement\nClaude-Flow v2.0.0 introduces a powerful hooks system that automates coordination and enhances every operation:\n#\nHooks automatically trigger on operations\nnpx claude-flow@alpha init --force\n#\nAuto-configures MCP servers & hooks\nAvailable Hooks\nPre-Operation Hooks\npre-task\n: Auto-assigns agents based on task complexity\npre-search\n: Caches searches for improved performance\npre-edit\n: Validates files and prepares resources\npre-command\n: Security validation before execution\nPost-Operation Hooks\npost-edit\n: Auto-formats code using language-specific tools\npost-task\n: Trains neural patterns from successful operations\npost-command\n: Updates memory with operation context\nnotification\n: Real-time progress updates\nSession Hooks\nsession-start\n: Restores previous context automatically\nsession-end\n: Generates summaries and persists state\nsession-restore\n: Loads memory from previous sessions\nHook Configuration\n// .claude/settings.json (auto-configured)\n{\n\"hooks\"\n: {\n\"preEditHook\"\n: {\n\"command\"\n:\n\"\nnpx\n\"\n,\n\"args\"\n: [\n\"\nclaude-flow\n\"\n,\n\"\nhooks\n\"\n,\n\"\npre-edit\n\"\n,\n\"\n--file\n\"\n,\n\"\n${file}\n\"\n,\n\"\n--auto-assign-agents\n\"\n,\n\"\ntrue\n\"\n],\n\"alwaysRun\"\n:\nfalse\n},\n\"postEditHook\"\n: {\n\"command\"\n:\n\"\nnpx\n\"\n,\n\"args\"\n: [\n\"\nclaude-flow\n\"\n,\n\"\nhooks\n\"\n,\n\"\npost-edit\n\"\n,\n\"\n--file\n\"\n,\n\"\n${file}\n\"\n,\n\"\n--format\n\"\n,\n\"\ntrue\n\"\n],\n\"alwaysRun\"\n:\ntrue\n},\n\"sessionEndHook\"\n: {\n\"command\"\n:\n\"\nnpx\n\"\n,\n\"args\"\n: [\n\"\nclaude-flow\n\"\n,\n\"\nhooks\n\"\n,\n\"\nsession-end\n\"\n,\n\"\n--generate-summary\n\"\n,\n\"\ntrue\n\"\n],\n\"alwaysRun\"\n:\ntrue\n}\n  }\n}\nüìö\nComplete Documentation\nFor detailed information about all features, advanced usage, and comprehensive guides, visit our\nGitHub Wiki\n:\nü§ñ\nCore Features\nNeural Module\n- SAFLA self-learning systems with 4-tier memory architecture\nGoal Module\n- GOAP intelligent planning with A* pathfinding\nAgent System Overview\n- Complete catalog of all 64 agents\nHive-Mind Intelligence\n- Queen-led AI coordination patterns\n‚ö°\nAdvanced Topics\nMemory System\n- SQLite-based persistent memory\nMCP Tools Reference\n- Complete guide to all 87 tools\nGitHub Integration\n- Repository management automation\nPerformance Benchmarking\n- Optimization strategies\nüìã\nConfiguration & Templates\nCLAUDE.md Templates\n- Project-specific configurations\nSPARC Methodology\n- Test-driven development patterns\nDevelopment Patterns\n- Best practices\nüõ†Ô∏è\nSetup & Troubleshooting\nInstallation Guide\n- Detailed setup instructions\nWindows Installation\n- Windows-specific setup\nTroubleshooting\n- Common issues and solutions\nNon-Interactive Mode\n- CI/CD automation\nü§ù\nCommunity & Support\nGitHub Issues\n:\nReport bugs or request features\nDiscord\n:\nJoin the Agentics Foundation community\nWiki\n:\nComprehensive documentation\nExamples\n:\nReal-world usage patterns\nüìä\nPerformance & Stats\n84.8% SWE-Bench solve rate\n- Industry-leading problem-solving capability\n32.3% token reduction\n- Efficient context management\n2.8-4.4x speed improvement\n- Parallel coordination strategies\n64 specialized agents\n- Complete development ecosystem\n87 MCP tools\n- Comprehensive automation toolkit\nüìä Targets (Month 12)\n5K+ GitHub stars, 50K npm downloads/month\n$25K MRR, 15 enterprise customers\n90%+ error prevention, 30+ min saved/dev/week\nStar History\nBuilt with ‚ù§Ô∏è by\nrUv\n| Powered by Revolutionary AI\nv2.5.0-alpha.140 - The Future of AI Orchestration with PreToolUse Modification Hooks",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 54",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 8,772"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/ruvnet/claude-flow"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/google/langextract",
      "title": "google/langextract",
      "date": null,
      "executive_summary": [
        "A Python library for extracting structured information from unstructured text using LLMs with precise source grounding and interactive visualization.",
        "---",
        "LangExtract\nTable of Contents\nIntroduction\nWhy LangExtract?\nQuick Start\nInstallation\nAPI Key Setup for Cloud Models\nAdding Custom Model Providers\nUsing OpenAI Models\nUsing Local LLMs with Ollama\nMore Examples\nRomeo and Juliet\nFull Text Extraction\nMedication Extraction\nRadiology Report Structuring: RadExtract\nCommunity Providers\nContributing\nTesting\nDisclaimer\nIntroduction\nLangExtract is a Python library that uses LLMs to extract structured information from unstructured text documents based on user-defined instructions. It processes materials such as clinical notes or reports, identifying and organizing key details while ensuring the extracted data corresponds to the source text.\nWhy LangExtract?\nPrecise Source Grounding:\nMaps every extraction to its exact location in the source text, enabling visual highlighting for easy traceability and verification.\nReliable Structured Outputs:\nEnforces a consistent output schema based on your few-shot examples, leveraging controlled generation in supported models like Gemini to guarantee robust, structured results.\nOptimized for Long Documents:\nOvercomes the \"needle-in-a-haystack\" challenge of large document extraction by using an optimized strategy of text chunking, parallel processing, and multiple passes for higher recall.\nInteractive Visualization:\nInstantly generates a self-contained, interactive HTML file to visualize and review thousands of extracted entities in their original context.\nFlexible LLM Support:\nSupports your preferred models, from cloud-based LLMs like the Google Gemini family to local open-source models via the built-in Ollama interface.\nAdaptable to Any Domain:\nDefine extraction tasks for any domain using just a few examples. LangExtract adapts to your needs without requiring any model fine-tuning.\nLeverages LLM World Knowledge:\nUtilize precise prompt wording and few-shot examples to influence how the extraction task may utilize LLM knowledge. The accuracy of any inferred information and its adherence to the task specification are contingent upon the selected LLM, the complexity of the task, the clarity of the prompt instructions, and the nature of the prompt examples.\nQuick Start\nNote:\nUsing cloud-hosted models like Gemini requires an API key. See the\nAPI Key Setup\nsection for instructions on how to get and configure your key.\nExtract structured information with just a few lines of code.\n1. Define Your Extraction Task\nFirst, create a prompt that clearly describes what you want to extract. Then, provide a high-quality example to guide the model.\nimport\nlangextract\nas\nlx\nimport\ntextwrap\n# 1. Define the prompt and extraction rules\nprompt\n=\ntextwrap\n.\ndedent\n(\n\"\"\"\n\\\nExtract characters, emotions, and relationships in order of appearance.\nUse exact text for extractions. Do not paraphrase or overlap entities.\nProvide meaningful attributes for each entity to add context.\"\"\"\n)\n# 2. Provide a high-quality example to guide the model\nexamples\n=\n[\nlx\n.\ndata\n.\nExampleData\n(\ntext\n=\n\"ROMEO. But soft! What light through yonder window breaks? It is the east, and Juliet is the sun.\"\n,\nextractions\n=\n[\nlx\n.\ndata\n.\nExtraction\n(\nextraction_class\n=\n\"character\"\n,\nextraction_text\n=\n\"ROMEO\"\n,\nattributes\n=\n{\n\"emotional_state\"\n:\n\"wonder\"\n}\n            ),\nlx\n.\ndata\n.\nExtraction\n(\nextraction_class\n=\n\"emotion\"\n,\nextraction_text\n=\n\"But soft!\"\n,\nattributes\n=\n{\n\"feeling\"\n:\n\"gentle awe\"\n}\n            ),\nlx\n.\ndata\n.\nExtraction\n(\nextraction_class\n=\n\"relationship\"\n,\nextraction_text\n=\n\"Juliet is the sun\"\n,\nattributes\n=\n{\n\"type\"\n:\n\"metaphor\"\n}\n            ),\n        ]\n    )\n]\n2. Run the Extraction\nProvide your input text and the prompt materials to the\nlx.extract\nfunction.\n# The input text to be processed\ninput_text\n=\n\"Lady Juliet gazed longingly at the stars, her heart aching for Romeo\"\n# Run the extraction\nresult\n=\nlx\n.\nextract\n(\ntext_or_documents\n=\ninput_text\n,\nprompt_description\n=\nprompt\n,\nexamples\n=\nexamples\n,\nmodel_id\n=\n\"gemini-2.5-flash\"\n,\n)\nModel Selection\n:\ngemini-2.5-flash\nis the recommended default, offering an excellent balance of speed, cost, and quality. For highly complex tasks requiring deeper reasoning,\ngemini-2.5-pro\nmay provide superior results. For large-scale or production use, a Tier 2 Gemini quota is suggested to increase throughput and avoid rate limits. See the\nrate-limit documentation\nfor details.\nModel Lifecycle\n: Note that Gemini models have a lifecycle with defined retirement dates. Users should consult the\nofficial model version documentation\nto stay informed about the latest stable and legacy versions.\n3. Visualize the Results\nThe extractions can be saved to a\n.jsonl\nfile, a popular format for working with language model data. LangExtract can then generate an interactive HTML visualization from this file to review the entities in context.\n# Save the results to a JSONL file\nlx\n.\nio\n.\nsave_annotated_documents\n([\nresult\n],\noutput_name\n=\n\"extraction_results.jsonl\"\n,\noutput_dir\n=\n\".\"\n)\n# Generate the visualization from the file\nhtml_content\n=\nlx\n.\nvisualize\n(\n\"extraction_results.jsonl\"\n)\nwith\nopen\n(\n\"visualization.html\"\n,\n\"w\"\n)\nas\nf\n:\nif\nhasattr\n(\nhtml_content\n,\n'data'\n):\nf\n.\nwrite\n(\nhtml_content\n.\ndata\n)\n# For Jupyter/Colab\nelse\n:\nf\n.\nwrite\n(\nhtml_content\n)\nThis creates an animated and interactive HTML file:\nNote on LLM Knowledge Utilization:\nThis example demonstrates extractions that stay close to the text evidence - extracting \"longing\" for Lady Juliet's emotional state and identifying \"yearning\" from \"gazed longingly at the stars.\" The task could be modified to generate attributes that draw more heavily from the LLM's world knowledge (e.g., adding\n\"identity\": \"Capulet family daughter\"\nor\n\"literary_context\": \"tragic heroine\"\n). The balance between text-evidence and knowledge-inference is controlled by your prompt instructions and example attributes.\nScaling to Longer Documents\nFor larger texts, you can process entire documents directly from URLs with parallel processing and enhanced sensitivity:\n# Process Romeo & Juliet directly from Project Gutenberg\nresult\n=\nlx\n.\nextract\n(\ntext_or_documents\n=\n\"https://www.gutenberg.org/files/1513/1513-0.txt\"\n,\nprompt_description\n=\nprompt\n,\nexamples\n=\nexamples\n,\nmodel_id\n=\n\"gemini-2.5-flash\"\n,\nextraction_passes\n=\n3\n,\n# Improves recall through multiple passes\nmax_workers\n=\n20\n,\n# Parallel processing for speed\nmax_char_buffer\n=\n1000\n# Smaller contexts for better accuracy\n)\nThis approach can extract hundreds of entities from full novels while maintaining high accuracy. The interactive visualization seamlessly handles large result sets, making it easy to explore hundreds of entities from the output JSONL file.\nSee the full\nRomeo and Juliet\nextraction example ‚Üí\nfor detailed results and performance insights.\nInstallation\nFrom PyPI\npip install langextract\nRecommended for most users. For isolated environments, consider using a virtual environment:\npython -m venv langextract_env\nsource\nlangextract_env/bin/activate\n#\nOn Windows: langextract_env\\Scripts\\activate\npip install langextract\nFrom Source\nLangExtract uses modern Python packaging with\npyproject.toml\nfor dependency management:\nInstalling with\n-e\nputs the package in development mode, allowing you to modify the code without reinstalling.\ngit clone https://github.com/google/langextract.git\ncd\nlangextract\n#\nFor basic installation:\npip install -e\n.\n#\nFor development (includes linting tools):\npip install -e\n\"\n.[dev]\n\"\n#\nFor testing (includes pytest):\npip install -e\n\"\n.[test]\n\"\nDocker\ndocker build -t langextract\n.\ndocker run --rm -e LANGEXTRACT_API_KEY=\n\"\nyour-api-key\n\"\nlangextract python your_script.py\nAPI Key Setup for Cloud Models\nWhen using LangExtract with cloud-hosted models (like Gemini or OpenAI), you'll need to\nset up an API key. On-device models don't require an API key. For developers\nusing local LLMs, LangExtract offers built-in support for Ollama and can be\nextended to other third-party APIs by updating the inference endpoints.\nAPI Key Sources\nGet API keys from:\nAI Studio\nfor Gemini models\nVertex AI\nfor enterprise use\nOpenAI Platform\nfor OpenAI models\nSetting up API key in your environment\nOption 1: Environment Variable\nexport\nLANGEXTRACT_API_KEY=\n\"\nyour-api-key-here\n\"\nOption 2: .env File (Recommended)\nAdd your API key to a\n.env\nfile:\n#\nAdd API key to .env file\ncat\n>>\n.env\n<<\n'\nEOF\n'\nLANGEXTRACT_API_KEY=your-api-key-here\nEOF\n#\nKeep your API key secure\necho\n'\n.env\n'\n>>\n.gitignore\nIn your Python code:\nimport\nlangextract\nas\nlx\nresult\n=\nlx\n.\nextract\n(\ntext_or_documents\n=\ninput_text\n,\nprompt_description\n=\n\"Extract information...\"\n,\nexamples\n=\n[...],\nmodel_id\n=\n\"gemini-2.5-flash\"\n)\nOption 3: Direct API Key (Not Recommended for Production)\nYou can also provide the API key directly in your code, though this is not recommended for production use:\nresult\n=\nlx\n.\nextract\n(\ntext_or_documents\n=\ninput_text\n,\nprompt_description\n=\n\"Extract information...\"\n,\nexamples\n=\n[...],\nmodel_id\n=\n\"gemini-2.5-flash\"\n,\napi_key\n=\n\"your-api-key-here\"\n# Only use this for testing/development\n)\nOption 4: Vertex AI (Service Accounts)\nUse\nVertex AI\nfor authentication with service accounts:\nresult\n=\nlx\n.\nextract\n(\ntext_or_documents\n=\ninput_text\n,\nprompt_description\n=\n\"Extract information...\"\n,\nexamples\n=\n[...],\nmodel_id\n=\n\"gemini-2.5-flash\"\n,\nlanguage_model_params\n=\n{\n\"vertexai\"\n:\nTrue\n,\n\"project\"\n:\n\"your-project-id\"\n,\n\"location\"\n:\n\"global\"\n# or regional endpoint\n}\n)\nAdding Custom Model Providers\nLangExtract supports custom LLM providers via a lightweight plugin system. You can add support for new models without changing core code.\nAdd new model support independently of the core library\nDistribute your provider as a separate Python package\nKeep custom dependencies isolated\nOverride or extend built-in providers via priority-based resolution\nSee the detailed guide in\nProvider System Documentation\nto learn how to:\nRegister a provider with\n@registry.register(...)\nPublish an entry point for discovery\nOptionally provide a schema with\nget_schema_class()\nfor structured output\nIntegrate with the factory via\ncreate_model(...)\nUsing OpenAI Models\nLangExtract supports OpenAI models (requires optional dependency:\npip install langextract[openai]\n):\nimport\nlangextract\nas\nlx\nresult\n=\nlx\n.\nextract\n(\ntext_or_documents\n=\ninput_text\n,\nprompt_description\n=\nprompt\n,\nexamples\n=\nexamples\n,\nmodel_id\n=\n\"gpt-4o\"\n,\n# Automatically selects OpenAI provider\napi_key\n=\nos\n.\nenviron\n.\nget\n(\n'OPENAI_API_KEY'\n),\nfence_output\n=\nTrue\n,\nuse_schema_constraints\n=\nFalse\n)\nNote: OpenAI models require\nfence_output=True\nand\nuse_schema_constraints=False\nbecause LangExtract doesn't implement schema constraints for OpenAI yet.\nUsing Local LLMs with Ollama\nLangExtract supports local inference using Ollama, allowing you to run models without API keys:\nimport\nlangextract\nas\nlx\nresult\n=\nlx\n.\nextract\n(\ntext_or_documents\n=\ninput_text\n,\nprompt_description\n=\nprompt\n,\nexamples\n=\nexamples\n,\nmodel_id\n=\n\"gemma2:2b\"\n,\n# Automatically selects Ollama provider\nmodel_url\n=\n\"http://localhost:11434\"\n,\nfence_output\n=\nFalse\n,\nuse_schema_constraints\n=\nFalse\n)\nQuick setup:\nInstall Ollama from\nollama.com\n, run\nollama pull gemma2:2b\n, then\nollama serve\n.\nFor detailed installation, Docker setup, and examples, see\nexamples/ollama/\n.\nMore Examples\nAdditional examples of LangExtract in action:\nRomeo and Juliet\nFull Text Extraction\nLangExtract can process complete documents directly from URLs. This example demonstrates extraction from the full text of\nRomeo and Juliet\nfrom Project Gutenberg (147,843 characters), showing parallel processing, sequential extraction passes, and performance optimization for long document processing.\nView\nRomeo and Juliet\nFull Text Example ‚Üí\nMedication Extraction\nDisclaimer:\nThis demonstration is for illustrative purposes of LangExtract's baseline capability only. It does not represent a finished or approved product, is not intended to diagnose or suggest treatment of any disease or condition, and should not be used for medical advice.\nLangExtract excels at extracting structured medical information from clinical text. These examples demonstrate both basic entity recognition (medication names, dosages, routes) and relationship extraction (connecting medications to their attributes), showing LangExtract's effectiveness for healthcare applications.\nView Medication Examples ‚Üí\nRadiology Report Structuring: RadExtract\nExplore RadExtract, a live interactive demo on HuggingFace Spaces that shows how LangExtract can automatically structure radiology reports. Try it directly in your browser with no setup required.\nView RadExtract Demo ‚Üí\nCommunity Providers\nExtend LangExtract with custom model providers! Check out our\nCommunity Provider Plugins\nregistry to discover providers created by the community or add your own.\nFor detailed instructions on creating a provider plugin, see the\nCustom Provider Plugin Example\n.\nContributing\nContributions are welcome! See\nCONTRIBUTING.md\nto get started\nwith development, testing, and pull requests. You must sign a\nContributor License Agreement\nbefore submitting patches.\nTesting\nTo run tests locally from the source:\n#\nClone the repository\ngit clone https://github.com/google/langextract.git\ncd\nlangextract\n#\nInstall with test dependencies\npip install -e\n\"\n.[test]\n\"\n#\nRun all tests\npytest tests\nOr reproduce the full CI matrix locally with tox:\ntox\n#\nruns pylint + pytest on Python 3.10 and 3.11\nOllama Integration Testing\nIf you have Ollama installed locally, you can run integration tests:\n#\nTest Ollama integration (requires Ollama running with gemma2:2b model)\ntox -e ollama-integration\nThis test will automatically detect if Ollama is available and run real inference tests.\nDevelopment\nCode Formatting\nThis project uses automated formatting tools to maintain consistent code style:\n#\nAuto-format all code\n./autoformat.sh\n#\nOr run formatters separately\nisort langextract tests --profile google --line-length 80\npyink langextract tests --config pyproject.toml\nPre-commit Hooks\nFor automatic formatting checks:\npre-commit install\n#\nOne-time setup\npre-commit run --all-files\n#\nManual run\nLinting\nRun linting before submitting PRs:\npylint --rcfile=.pylintrc langextract tests\nSee\nCONTRIBUTING.md\nfor full development guidelines.\nDisclaimer\nThis is not an officially supported Google product. If you use\nLangExtract in production or publications, please cite accordingly and\nacknowledge usage. Use is subject to the\nApache 2.0 License\n.\nFor health-related applications, use of LangExtract is also subject to the\nHealth AI Developer Foundations Terms of Use\n.\nHappy Extracting!",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 52",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 16,257"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/google/langextract"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/vercel/ai",
      "title": "vercel/ai",
      "date": null,
      "executive_summary": [
        "The AI Toolkit for TypeScript. From the creators of Next.js, the AI SDK is a free open-source library for building AI-powered applications and agents",
        "---",
        "AI SDK\nThe\nAI SDK\nis a TypeScript toolkit designed to help you build AI-powered applications and agents using popular frameworks like Next.js, React, Svelte, Vue and runtimes like Node.js.\nTo learn more about how to use the AI SDK, check out our\nAPI Reference\nand\nDocumentation\n.\nInstallation\nYou will need Node.js 18+ and npm (or another package manager) installed on your local development machine.\nnpm install ai\nUnified Provider Architecture\nThe AI SDK provides a\nunified API\nto interact with model providers like\nOpenAI\n,\nAnthropic\n,\nGoogle\n, and\nmore\n.\nnpm install @ai-sdk/openai @ai-sdk/anthropic @ai-sdk/google\nAlternatively you can use the\nVercel AI Gateway\n.\nUsage\nGenerating Text\nimport\n{\ngenerateText\n}\nfrom\n'ai'\n;\nconst\n{\ntext\n}\n=\nawait\ngenerateText\n(\n{\nmodel\n:\n'openai/gpt-5'\n,\n// use Vercel AI Gateway\nprompt\n:\n'What is an agent?'\n,\n}\n)\n;\nimport\n{\ngenerateText\n}\nfrom\n'ai'\n;\nimport\n{\nopenai\n}\nfrom\n'@ai-sdk/openai'\n;\nconst\n{\ntext\n}\n=\nawait\ngenerateText\n(\n{\nmodel\n:\nopenai\n(\n'gpt-5'\n)\n,\n// use OpenAI Responses API\nprompt\n:\n'What is an agent?'\n,\n}\n)\n;\nGenerating Structured Data\nimport\n{\ngenerateObject\n}\nfrom\n'ai'\n;\nimport\n{\nz\n}\nfrom\n'zod'\n;\nconst\n{\nobject\n}\n=\nawait\ngenerateObject\n(\n{\nmodel\n:\n'openai/gpt-4.1'\n,\nschema\n:\nz\n.\nobject\n(\n{\nrecipe\n:\nz\n.\nobject\n(\n{\nname\n:\nz\n.\nstring\n(\n)\n,\ningredients\n:\nz\n.\narray\n(\nz\n.\nobject\n(\n{\nname\n:\nz\n.\nstring\n(\n)\n,\namount\n:\nz\n.\nstring\n(\n)\n}\n)\n)\n,\nsteps\n:\nz\n.\narray\n(\nz\n.\nstring\n(\n)\n)\n,\n}\n)\n,\n}\n)\n,\nprompt\n:\n'Generate a lasagna recipe.'\n,\n}\n)\n;\nAgents\nimport\n{\nAgent\n}\nfrom\n'ai'\n;\nconst\nsandboxAgent\n=\nnew\nAgent\n(\n{\nmodel\n:\n'openai/gpt-5-codex'\n,\nsystem\n:\n'You are an agent with access to a shell environment.'\n,\ntools\n:\n{\nlocal_shell\n:\nopenai\n.\ntools\n.\nlocalShell\n(\n{\nexecute\n:\nasync\n(\n{\naction\n}\n)\n=>\n{\nconst\n[\ncmd\n,\n...\nargs\n]\n=\naction\n.\ncommand\n;\nconst\nsandbox\n=\nawait\ngetSandbox\n(\n)\n;\n// Vercel Sandbox\nconst\ncommand\n=\nawait\nsandbox\n.\nrunCommand\n(\n{\ncmd\n,\nargs\n}\n)\n;\nreturn\n{\noutput\n:\nawait\ncommand\n.\nstdout\n(\n)\n}\n;\n}\n,\n}\n)\n,\n}\n,\n}\n)\n;\nUI Integration\nThe\nAI SDK UI\nmodule provides a set of hooks that help you build chatbots and generative user interfaces. These hooks are framework agnostic, so they can be used in Next.js, React, Svelte, and Vue.\nYou need to install the package for your framework, e.g.:\nnpm install @ai-sdk/react\nAgent @/agent/image-generation-agent.ts\nimport\n{\nopenai\n}\nfrom\n'@ai-sdk/openai'\n;\nimport\n{\nAgent\n,\nInferAgentUIMessage\n}\nfrom\n'ai'\n;\nexport\nconst\nimageGenerationAgent\n=\nnew\nAgent\n(\n{\nmodel\n:\nopenai\n(\n'gpt-5'\n)\n,\ntools\n:\n{\nimage_generation\n:\nopenai\n.\ntools\n.\nimageGeneration\n(\n{\npartialImages\n:\n3\n,\n}\n)\n,\n}\n,\n}\n)\n;\nexport\ntype\nImageGenerationAgentMessage\n=\nInferAgentUIMessage\n<\ntypeof\nimageGenerationAgent\n>\n;\nRoute (Next.js App Router) @/app/api/chat/route.ts\nimport\n{\nimageGenerationAgent\n}\nfrom\n'@/agent/image-generation-agent'\n;\nimport\n{\nvalidateUIMessages\n}\nfrom\n'ai'\n;\nexport\nasync\nfunction\nPOST\n(\nreq\n:\nRequest\n)\n{\nconst\n{\nmessages\n}\n=\nawait\nreq\n.\njson\n(\n)\n;\nreturn\nimageGenerationAgent\n.\nrespond\n(\n{\nmessages\n:\nawait\nvalidateUIMessages\n(\n{\nmessages\n}\n)\n,\n}\n)\n;\n}\nUI Component for Tool @/component/image-generation-view.tsx\nimport\n{\nopenai\n}\nfrom\n'@ai-sdk/openai'\n;\nimport\n{\nUIToolInvocation\n}\nfrom\n'ai'\n;\nexport\ndefault\nfunction\nImageGenerationView\n(\n{\ninvocation\n,\n}\n:\n{\ninvocation\n:\nUIToolInvocation\n<\nReturnType\n<\ntypeof\nopenai\n.\ntools\n.\nimageGeneration\n>\n>\n;\n}\n)\n{\nswitch\n(\ninvocation\n.\nstate\n)\n{\ncase\n'input-available'\n:\nreturn\n<\ndiv\n>\nGenerating image...\n</\ndiv\n>\n;\ncase\n'output-available'\n:\nreturn\n<\nimg\nsrc\n=\n{\n`data:image/png;base64,\n${\ninvocation\n.\noutput\n.\nresult\n}\n`\n}\n/>\n;\n}\n}\nPage @/app/page.tsx\n'use client'\n;\nimport\n{\nImageGenerationAgentMessage\n}\nfrom\n'@/agent/image-generation-agent'\n;\nimport\nImageGenerationView\nfrom\n'@/component/image-generation-view'\n;\nimport\n{\nuseChat\n}\nfrom\n'@ai-sdk/react'\n;\nexport\ndefault\nfunction\nPage\n(\n)\n{\nconst\n{\nmessages\n,\nstatus\n,\nsendMessage\n}\n=\nuseChat\n<\nImageGenerationAgentMessage\n>\n(\n)\n;\nconst\n[\ninput\n,\nsetInput\n]\n=\nuseState\n(\n''\n)\n;\nconst\nhandleSubmit\n=\ne\n=>\n{\ne\n.\npreventDefault\n(\n)\n;\nsendMessage\n(\n{\ntext\n:\ninput\n}\n)\n;\nsetInput\n(\n''\n)\n;\n}\n;\nreturn\n(\n<\ndiv\n>\n{\nmessages\n.\nmap\n(\nmessage\n=>\n(\n<\ndiv\nkey\n=\n{\nmessage\n.\nid\n}\n>\n<\nstrong\n>\n{\n`\n${\nmessage\n.\nrole\n}\n: `\n}\n</\nstrong\n>\n{\nmessage\n.\nparts\n.\nmap\n(\n(\npart\n,\nindex\n)\n=>\n{\nswitch\n(\npart\n.\ntype\n)\n{\ncase\n'text'\n:\nreturn\n<\ndiv\nkey\n=\n{\nindex\n}\n>\n{\npart\n.\ntext\n}\n</\ndiv\n>\n;\ncase\n'tool-image_generation'\n:\nreturn\n<\nImageGenerationView\nkey\n=\n{\nindex\n}\ninvocation\n=\n{\npart\n}\n/>\n;\n}\n}\n)\n}\n</\ndiv\n>\n)\n)\n}\n<\nform\nonSubmit\n=\n{\nhandleSubmit\n}\n>\n<\ninput\nvalue\n=\n{\ninput\n}\nonChange\n=\n{\ne\n=>\nsetInput\n(\ne\n.\ntarget\n.\nvalue\n)\n}\ndisabled\n=\n{\nstatus\n!==\n'ready'\n}\n/>\n</\nform\n>\n</\ndiv\n>\n)\n;\n}\nTemplates\nWe've built\ntemplates\nthat include AI SDK integrations for different use cases, providers, and frameworks. You can use these templates to get started with your AI-powered application.\nCommunity\nThe AI SDK community can be found on\nGitHub Discussions\nwhere you can ask questions, voice ideas, and share your projects with other people.\nContributing\nContributions to the AI SDK are welcome and highly appreciated. However, before you jump right into it, we would like you to review our\nContribution Guidelines\nto make sure you have smooth experience contributing to AI SDK.\nAuthors\nThis library is created by\nVercel\nand\nNext.js\nteam members, with contributions from the\nOpen Source Community\n.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 51",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 18,328"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/vercel/ai"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/sapientinc/HRM",
      "title": "sapientinc/HRM",
      "date": null,
      "executive_summary": [
        "Hierarchical Reasoning Model Official Release",
        "---",
        "Hierarchical Reasoning Model\nReasoning, the process of devising and executing complex goal-oriented action sequences, remains a critical challenge in AI.\nCurrent large language models (LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from brittle task decomposition, extensive data requirements, and high latency. Inspired by the hierarchical and multi-timescale processing in the human brain, we propose the Hierarchical Reasoning Model (HRM), a novel recurrent architecture that attains significant computational depth while maintaining both training stability and efficiency.\nHRM executes sequential reasoning tasks in a single forward pass without explicit supervision of the intermediate process, through two interdependent recurrent modules: a high-level module responsible for slow, abstract planning, and a low-level module handling rapid, detailed computations. With only 27 million parameters, HRM achieves exceptional performance on complex reasoning tasks using only 1000 training samples. The model operates without pre-training or CoT data, yet achieves nearly perfect performance on challenging tasks including complex Sudoku puzzles and optimal path finding in large mazes.\nFurthermore, HRM outperforms much larger models with significantly longer context windows on the Abstraction and Reasoning Corpus (ARC), a key benchmark for measuring artificial general intelligence capabilities.\nThese results underscore HRM‚Äôs potential as a transformative advancement toward universal computation and general-purpose reasoning systems.\nJoin our Discord Community:\nhttps://discord.gg/sapient\nQuick Start Guide üöÄ\nPrerequisites ‚öôÔ∏è\nEnsure PyTorch and CUDA are installed. The repo needs CUDA extensions to be built. If not present, run the following commands:\n#\nInstall CUDA 12.6\nCUDA_URL=https://developer.download.nvidia.com/compute/cuda/12.6.3/local_installers/cuda_12.6.3_560.35.05_linux.run\n\nwget -q --show-progress --progress=bar:force:noscroll -O cuda_installer.run\n$CUDA_URL\nsudo sh cuda_installer.run --silent --toolkit --override\nexport\nCUDA_HOME=/usr/local/cuda-12.6\n#\nInstall PyTorch with CUDA 12.6\nPYTORCH_INDEX_URL=https://download.pytorch.org/whl/cu126\n\npip3 install torch torchvision torchaudio --index-url\n$PYTORCH_INDEX_URL\n#\nAdditional packages for building extensions\npip3 install packaging ninja wheel setuptools setuptools-scm\nThen install FlashAttention. For Hopper GPUs, install FlashAttention 3\ngit clone git@github.com:Dao-AILab/flash-attention.git\ncd\nflash-attention/hopper\npython setup.py install\nFor Ampere or earlier GPUs, install FlashAttention 2\npip3 install flash-attn\nInstall Python Dependencies üêç\npip install -r requirements.txt\nW&B Integration üìà\nThis project uses\nWeights & Biases\nfor experiment tracking and metric visualization. Ensure you're logged in:\nwandb login\nRun Experiments\nQuick Demo: Sudoku Solver üíªüó≤\nTrain a master-level Sudoku AI capable of solving extremely difficult puzzles on a modern laptop GPU. üß©\n#\nDownload and build Sudoku dataset\npython dataset/build_sudoku_dataset.py --output-dir data/sudoku-extreme-1k-aug-1000  --subsample-size 1000 --num-aug 1000\n#\nStart training (single GPU, smaller batch size)\nOMP_NUM_THREADS=8 python pretrain.py data_path=data/sudoku-extreme-1k-aug-1000 epochs=20000 eval_interval=2000 global_batch_size=384 lr=7e-5 puzzle_emb_lr=7e-5 weight_decay=1.0 puzzle_emb_weight_decay=1.0\nRuntime: ~10 hours on a RTX 4070 laptop GPU\nTrained Checkpoints üöß\nARC-AGI-2\nSudoku 9x9 Extreme (1000 examples)\nMaze 30x30 Hard (1000 examples)\nTo use the checkpoints, see Evaluation section below.\nFull-scale Experiments üîµ\nExperiments below assume an 8-GPU setup.\nDataset Preparation\n#\nInitialize submodules\ngit submodule update --init --recursive\n#\nARC-1\npython dataset/build_arc_dataset.py\n#\nARC offical + ConceptARC, 960 examples\n#\nARC-2\npython dataset/build_arc_dataset.py --dataset-dirs dataset/raw-data/ARC-AGI-2/data --output-dir data/arc-2-aug-1000\n#\nARC-2 official, 1120 examples\n#\nSudoku-Extreme\npython dataset/build_sudoku_dataset.py\n#\nFull version\npython dataset/build_sudoku_dataset.py --output-dir data/sudoku-extreme-1k-aug-1000  --subsample-size 1000 --num-aug 1000\n#\n1000 examples\n#\nMaze\npython dataset/build_maze_dataset.py\n#\n1000 examples\nDataset Visualization\nExplore the puzzles visually:\nOpen\npuzzle_visualizer.html\nin your browser.\nUpload the generated dataset folder located in\ndata/...\n.\nLaunch experiments\nSmall-sample (1K)\nARC-1:\nOMP_NUM_THREADS=8 torchrun --nproc-per-node 8 pretrain.py\nRuntime:\n~24 hours\nARC-2:\nOMP_NUM_THREADS=8 torchrun --nproc-per-node 8 pretrain.py data_path=data/arc-2-aug-1000\nRuntime:\n~24 hours (checkpoint after 8 hours is often sufficient)\nSudoku Extreme (1k):\nOMP_NUM_THREADS=8 torchrun --nproc-per-node 8 pretrain.py data_path=data/sudoku-extreme-1k-aug-1000 epochs=20000 eval_interval=2000 lr=1e-4 puzzle_emb_lr=1e-4 weight_decay=1.0 puzzle_emb_weight_decay=1.0\nRuntime:\n~10 minutes\nMaze 30x30 Hard (1k):\nOMP_NUM_THREADS=8 torchrun --nproc-per-node 8 pretrain.py data_path=data/maze-30x30-hard-1k epochs=20000 eval_interval=2000 lr=1e-4 puzzle_emb_lr=1e-4 weight_decay=1.0 puzzle_emb_weight_decay=1.0\nRuntime:\n~1 hour\nFull Sudoku-Hard\nOMP_NUM_THREADS=8 torchrun --nproc-per-node 8 pretrain.py data_path=data/sudoku-hard-full epochs=100 eval_interval=10 lr_min_ratio=0.1 global_batch_size=2304 lr=3e-4 puzzle_emb_lr=3e-4 weight_decay=0.1 puzzle_emb_weight_decay=0.1 arch.loss.loss_type=softmax_cross_entropy arch.L_cycles=8 arch.halt_max_steps=8 arch.pos_encodings=learned\nRuntime:\n~2 hours\nEvaluation\nEvaluate your trained models:\nCheck\neval/exact_accuracy\nin W&B.\nFor ARC-AGI, follow these additional steps:\nOMP_NUM_THREADS=8 torchrun --nproc-per-node 8 evaluate.py checkpoint=\n<\nCHECKPOINT_PATH\n>\nThen use the provided\narc_eval.ipynb\nnotebook to finalize and inspect your results.\nNotes\nSmall-sample learning typically exhibits accuracy variance of around ¬±2 points.\nFor Sudoku-Extreme (1,000-example dataset), late-stage overfitting may cause numerical instability during training and Q-learning. It is advisable to use early stopping once the training accuracy approaches 100%.\nCitation üìú\n@misc\n{\nwang2025hierarchicalreasoningmodel\n,\ntitle\n=\n{\nHierarchical Reasoning Model\n}\n,\nauthor\n=\n{\nGuan Wang and Jin Li and Yuhao Sun and Xing Chen and Changling Liu and Yue Wu and Meng Lu and Sen Song and Yasin Abbasi Yadkori\n}\n,\nyear\n=\n{\n2025\n}\n,\neprint\n=\n{\n2506.21734\n}\n,\narchivePrefix\n=\n{\narXiv\n}\n,\nprimaryClass\n=\n{\ncs.AI\n}\n,\nurl\n=\n{\nhttps://arxiv.org/abs/2506.21734\n}\n, \n}",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 51",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 10,867"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/sapientinc/HRM"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/BerriAI/litellm",
      "title": "BerriAI/litellm",
      "date": null,
      "executive_summary": [
        "Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq]",
        "---",
        "üöÖ LiteLLM\nCall all LLM APIs using the OpenAI format [Bedrock, Huggingface, VertexAI, TogetherAI, Azure, OpenAI, Groq etc.]\nLiteLLM Proxy Server (LLM Gateway)\n|\nHosted Proxy (Preview)\n|\nEnterprise Tier\nLiteLLM manages:\nTranslate inputs to provider's\ncompletion\n,\nembedding\n, and\nimage_generation\nendpoints\nConsistent output\n, text responses will always be available at\n['choices'][0]['message']['content']\nRetry/fallback logic across multiple deployments (e.g. Azure/OpenAI) -\nRouter\nSet Budgets & Rate limits per project, api key, model\nLiteLLM Proxy Server (LLM Gateway)\nJump to LiteLLM Proxy (LLM Gateway) Docs\nJump to Supported LLM Providers\nüö®\nStable Release:\nUse docker images with the\n-stable\ntag. These have undergone 12 hour load tests, before being published.\nMore information about the release cycle here\nSupport for more providers. Missing a provider or LLM Platform, raise a\nfeature request\n.\nUsage (\nDocs\n)\nImportant\nLiteLLM v1.0.0 now requires\nopenai>=1.0.0\n. Migration guide\nhere\nLiteLLM v1.40.14+ now requires\npydantic>=2.0.0\n. No changes required.\npip install litellm\nfrom\nlitellm\nimport\ncompletion\nimport\nos\n## set ENV variables\nos\n.\nenviron\n[\n\"OPENAI_API_KEY\"\n]\n=\n\"your-openai-key\"\nos\n.\nenviron\n[\n\"ANTHROPIC_API_KEY\"\n]\n=\n\"your-anthropic-key\"\nmessages\n=\n[{\n\"content\"\n:\n\"Hello, how are you?\"\n,\n\"role\"\n:\n\"user\"\n}]\n# openai call\nresponse\n=\ncompletion\n(\nmodel\n=\n\"openai/gpt-4o\"\n,\nmessages\n=\nmessages\n)\n# anthropic call\nresponse\n=\ncompletion\n(\nmodel\n=\n\"anthropic/claude-sonnet-4-20250514\"\n,\nmessages\n=\nmessages\n)\nprint\n(\nresponse\n)\nResponse (OpenAI Format)\n{\n\"id\"\n:\n\"\nchatcmpl-1214900a-6cdd-4148-b663-b5e2f642b4de\n\"\n,\n\"created\"\n:\n1751494488\n,\n\"model\"\n:\n\"\nclaude-sonnet-4-20250514\n\"\n,\n\"object\"\n:\n\"\nchat.completion\n\"\n,\n\"system_fingerprint\"\n:\nnull\n,\n\"choices\"\n: [\n        {\n\"finish_reason\"\n:\n\"\nstop\n\"\n,\n\"index\"\n:\n0\n,\n\"message\"\n: {\n\"content\"\n:\n\"\nHello! I'm doing well, thank you for asking. I'm here and ready to help with whatever you'd like to discuss or work on. How are you doing today?\n\"\n,\n\"role\"\n:\n\"\nassistant\n\"\n,\n\"tool_calls\"\n:\nnull\n,\n\"function_call\"\n:\nnull\n}\n        }\n    ],\n\"usage\"\n: {\n\"completion_tokens\"\n:\n39\n,\n\"prompt_tokens\"\n:\n13\n,\n\"total_tokens\"\n:\n52\n,\n\"completion_tokens_details\"\n:\nnull\n,\n\"prompt_tokens_details\"\n: {\n\"audio_tokens\"\n:\nnull\n,\n\"cached_tokens\"\n:\n0\n},\n\"cache_creation_input_tokens\"\n:\n0\n,\n\"cache_read_input_tokens\"\n:\n0\n}\n}\nCall any model supported by a provider, with\nmodel=<provider_name>/<model_name>\n. There might be provider-specific details here, so refer to\nprovider docs for more information\nAsync (\nDocs\n)\nfrom\nlitellm\nimport\nacompletion\nimport\nasyncio\nasync\ndef\ntest_get_response\n():\nuser_message\n=\n\"Hello, how are you?\"\nmessages\n=\n[{\n\"content\"\n:\nuser_message\n,\n\"role\"\n:\n\"user\"\n}]\nresponse\n=\nawait\nacompletion\n(\nmodel\n=\n\"openai/gpt-4o\"\n,\nmessages\n=\nmessages\n)\nreturn\nresponse\nresponse\n=\nasyncio\n.\nrun\n(\ntest_get_response\n())\nprint\n(\nresponse\n)\nStreaming (\nDocs\n)\nliteLLM supports streaming the model response back, pass\nstream=True\nto get a streaming iterator in response.\nStreaming is supported for all models (Bedrock, Huggingface, TogetherAI, Azure, OpenAI, etc.)\nfrom\nlitellm\nimport\ncompletion\nresponse\n=\ncompletion\n(\nmodel\n=\n\"openai/gpt-4o\"\n,\nmessages\n=\nmessages\n,\nstream\n=\nTrue\n)\nfor\npart\nin\nresponse\n:\nprint\n(\npart\n.\nchoices\n[\n0\n].\ndelta\n.\ncontent\nor\n\"\"\n)\n# claude sonnet 4\nresponse\n=\ncompletion\n(\n'anthropic/claude-sonnet-4-20250514'\n,\nmessages\n,\nstream\n=\nTrue\n)\nfor\npart\nin\nresponse\n:\nprint\n(\npart\n)\nResponse chunk (OpenAI Format)\n{\n\"id\"\n:\n\"\nchatcmpl-fe575c37-5004-4926-ae5e-bfbc31f356ca\n\"\n,\n\"created\"\n:\n1751494808\n,\n\"model\"\n:\n\"\nclaude-sonnet-4-20250514\n\"\n,\n\"object\"\n:\n\"\nchat.completion.chunk\n\"\n,\n\"system_fingerprint\"\n:\nnull\n,\n\"choices\"\n: [\n        {\n\"finish_reason\"\n:\nnull\n,\n\"index\"\n:\n0\n,\n\"delta\"\n: {\n\"provider_specific_fields\"\n:\nnull\n,\n\"content\"\n:\n\"\nHello\n\"\n,\n\"role\"\n:\n\"\nassistant\n\"\n,\n\"function_call\"\n:\nnull\n,\n\"tool_calls\"\n:\nnull\n,\n\"audio\"\n:\nnull\n},\n\"logprobs\"\n:\nnull\n}\n    ],\n\"provider_specific_fields\"\n:\nnull\n,\n\"stream_options\"\n:\nnull\n,\n\"citations\"\n:\nnull\n}\nLogging Observability (\nDocs\n)\nLiteLLM exposes pre defined callbacks to send data to Lunary, MLflow, Langfuse, DynamoDB, s3 Buckets, Helicone, Promptlayer, Traceloop, Athina, Slack\nfrom\nlitellm\nimport\ncompletion\n## set env variables for logging tools (when using MLflow, no API key set up is required)\nos\n.\nenviron\n[\n\"LUNARY_PUBLIC_KEY\"\n]\n=\n\"your-lunary-public-key\"\nos\n.\nenviron\n[\n\"HELICONE_API_KEY\"\n]\n=\n\"your-helicone-auth-key\"\nos\n.\nenviron\n[\n\"LANGFUSE_PUBLIC_KEY\"\n]\n=\n\"\"\nos\n.\nenviron\n[\n\"LANGFUSE_SECRET_KEY\"\n]\n=\n\"\"\nos\n.\nenviron\n[\n\"ATHINA_API_KEY\"\n]\n=\n\"your-athina-api-key\"\nos\n.\nenviron\n[\n\"OPENAI_API_KEY\"\n]\n=\n\"your-openai-key\"\n# set callbacks\nlitellm\n.\nsuccess_callback\n=\n[\n\"lunary\"\n,\n\"mlflow\"\n,\n\"langfuse\"\n,\n\"athina\"\n,\n\"helicone\"\n]\n# log input/output to lunary, langfuse, supabase, athina, helicone etc\n#openai call\nresponse\n=\ncompletion\n(\nmodel\n=\n\"openai/gpt-4o\"\n,\nmessages\n=\n[{\n\"role\"\n:\n\"user\"\n,\n\"content\"\n:\n\"Hi üëã - i'm openai\"\n}])\nLiteLLM Proxy Server (LLM Gateway) - (\nDocs\n)\nTrack spend + Load Balance across multiple projects\nHosted Proxy (Preview)\nThe proxy provides:\nHooks for auth\nHooks for logging\nCost tracking\nRate Limiting\nüìñ Proxy Endpoints -\nSwagger Docs\nQuick Start Proxy - CLI\npip install\n'\nlitellm[proxy]\n'\nStep 1: Start litellm proxy\n$ litellm --model huggingface/bigcode/starcoder\n#\nINFO: Proxy running on http://0.0.0.0:4000\nStep 2: Make ChatCompletions Request to Proxy\nImportant\nüí°\nUse LiteLLM Proxy with Langchain (Python, JS), OpenAI SDK (Python, JS) Anthropic SDK, Mistral SDK, LlamaIndex, Instructor, Curl\nimport\nopenai\n# openai v1.0.0+\nclient\n=\nopenai\n.\nOpenAI\n(\napi_key\n=\n\"anything\"\n,\nbase_url\n=\n\"http://0.0.0.0:4000\"\n)\n# set proxy to base_url\n# request sent to model set on litellm proxy, `litellm --model`\nresponse\n=\nclient\n.\nchat\n.\ncompletions\n.\ncreate\n(\nmodel\n=\n\"gpt-3.5-turbo\"\n,\nmessages\n=\n[\n    {\n\"role\"\n:\n\"user\"\n,\n\"content\"\n:\n\"this is a test request, write a short poem\"\n}\n])\nprint\n(\nresponse\n)\nProxy Key Management (\nDocs\n)\nConnect the proxy with a Postgres DB to create proxy keys\n#\nGet the code\ngit clone https://github.com/BerriAI/litellm\n#\nGo to folder\ncd\nlitellm\n#\nAdd the master key - you can change this after setup\necho\n'\nLITELLM_MASTER_KEY=\"sk-1234\"\n'\n>\n.env\n#\nAdd the litellm salt key - you cannot change this after adding a model\n#\nIt is used to encrypt / decrypt your LLM API Key credentials\n#\nWe recommend - https://1password.com/password-generator/\n#\npassword generator to get a random hash for litellm salt key\necho\n'\nLITELLM_SALT_KEY=\"sk-1234\"\n'\n>>\n.env\nsource\n.env\n#\nStart\ndocker compose up\nUI on\n/ui\non your proxy server\nSet budgets and rate limits across multiple projects\nPOST /key/generate\nRequest\ncurl\n'\nhttp://0.0.0.0:4000/key/generate\n'\n\\\n--header\n'\nAuthorization: Bearer sk-1234\n'\n\\\n--header\n'\nContent-Type: application/json\n'\n\\\n--data-raw\n'\n{\"models\": [\"gpt-3.5-turbo\", \"gpt-4\", \"claude-2\"], \"duration\": \"20m\",\"metadata\": {\"user\": \"ishaan@berri.ai\", \"team\": \"core-infra\"}}\n'\nExpected Response\n{\n\"\nkey\n\"\n:\n\"\nsk-kdEXbIqZRwEeEiHwdg7sFA\n\"\n,\n#\nBearer token\n\"\nexpires\n\"\n:\n\"\n2023-11-19T01:38:25.838000+00:00\n\"\n#\ndatetime object\n}\nSupported Providers (\nDocs\n)\nProvider\nCompletion\nStreaming\nAsync Completion\nAsync Streaming\nAsync Embedding\nAsync Image Generation\nopenai\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nMeta - Llama API\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nazure\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nAI/ML API\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\naws - sagemaker\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\naws - bedrock\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\ngoogle - vertex_ai\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\ngoogle - palm\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\ngoogle AI Studio - gemini\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nmistral ai api\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\ncloudflare AI Workers\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nCompactifAI\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\ncohere\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nanthropic\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nempower\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nhuggingface\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nreplicate\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\ntogether_ai\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nopenrouter\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nai21\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nbaseten\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nvllm\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nnlp_cloud\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\naleph alpha\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\npetals\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nollama\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\ndeepinfra\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nperplexity-ai\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nGroq AI\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nDeepseek\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nanyscale\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nIBM - watsonx.ai\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nvoyage ai\n‚úÖ\nxinference [Xorbits Inference]\n‚úÖ\nFriendliAI\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nGaladriel\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nGradientAI\n‚úÖ\n‚úÖ\nNovita AI\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nFeatherless AI\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nNebius AI Studio\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\n‚úÖ\nHeroku\n‚úÖ\n‚úÖ\nOVHCloud AI Endpoints\n‚úÖ\n‚úÖ\nRead the Docs\nRun in Developer mode\nServices\nSetup .env file in root\nRun dependant services\ndocker-compose up db prometheus\nBackend\n(In root) create virtual environment\npython -m venv .venv\nActivate virtual environment\nsource .venv/bin/activate\nInstall dependencies\npip install -e \".[all]\"\nStart proxy backend\npython litellm/proxy_cli.py\nFrontend\nNavigate to\nui/litellm-dashboard\nInstall dependencies\nnpm install\nRun\nnpm run dev\nto start the dashboard\nEnterprise\nFor companies that need better security, user management and professional support\nTalk to founders\nThis covers:\n‚úÖ\nFeatures under the\nLiteLLM Commercial License\n:\n‚úÖ\nFeature Prioritization\n‚úÖ\nCustom Integrations\n‚úÖ\nProfessional Support - Dedicated discord + slack\n‚úÖ\nCustom SLAs\n‚úÖ\nSecure access with Single Sign-On\nContributing\nWe welcome contributions to LiteLLM! Whether you're fixing bugs, adding features, or improving documentation, we appreciate your help.\nQuick Start for Contributors\nThis requires poetry to be installed.\ngit clone https://github.com/BerriAI/litellm.git\ncd\nlitellm\nmake install-dev\n#\nInstall development dependencies\nmake format\n#\nFormat your code\nmake lint\n#\nRun all linting checks\nmake test-unit\n#\nRun unit tests\nmake format-check\n#\nCheck formatting only\nFor detailed contributing guidelines, see\nCONTRIBUTING.md\n.\nCode Quality / Linting\nLiteLLM follows the\nGoogle Python Style Guide\n.\nOur automated checks include:\nBlack\nfor code formatting\nRuff\nfor linting and code quality\nMyPy\nfor type checking\nCircular import detection\nImport safety checks\nAll these checks must pass before your PR can be merged.\nSupport / talk with founders\nSchedule Demo üëã\nCommunity Discord üí≠\nCommunity Slack üí≠\nOur numbers üìû +1 (770) 8783-106 / ‚Ä≠+1 (412) 618-6238‚Ä¨\nOur emails ‚úâÔ∏è\nishaan@berri.ai\n/\nkrrish@berri.ai\nWhy did we build this\nNeed for simplicity\n: Our code started to get extremely complicated managing & translating calls between Azure, OpenAI and Cohere.\nContributors",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 42",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 29,706"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/BerriAI/litellm"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/astral-sh/ruff",
      "title": "astral-sh/ruff",
      "date": null,
      "executive_summary": [
        "An extremely fast Python linter and code formatter, written in Rust.",
        "---",
        "Ruff\nDocs\n|\nPlayground\nAn extremely fast Python linter and code formatter, written in Rust.\nLinting the CPython codebase from scratch.\n‚ö°Ô∏è 10-100x faster than existing linters (like Flake8) and formatters (like Black)\nüêç Installable via\npip\nüõ†Ô∏è\npyproject.toml\nsupport\nü§ù Python 3.13 compatibility\n‚öñÔ∏è Drop-in parity with\nFlake8\n, isort, and\nBlack\nüì¶ Built-in caching, to avoid re-analyzing unchanged files\nüîß Fix support, for automatic error correction (e.g., automatically remove unused imports)\nüìè Over\n800 built-in rules\n, with native re-implementations\nof popular Flake8 plugins, like flake8-bugbear\n‚å®Ô∏è First-party\neditor integrations\nfor\nVS Code\nand\nmore\nüåé Monorepo-friendly, with\nhierarchical and cascading configuration\nRuff aims to be orders of magnitude faster than alternative tools while integrating more\nfunctionality behind a single, common interface.\nRuff can be used to replace\nFlake8\n(plus dozens of plugins),\nBlack\n,\nisort\n,\npydocstyle\n,\npyupgrade\n,\nautoflake\n, and more, all while executing tens or hundreds of\ntimes faster than any individual tool.\nRuff is extremely actively developed and used in major open-source projects like:\nApache Airflow\nApache Superset\nFastAPI\nHugging Face\nPandas\nSciPy\n...and\nmany more\n.\nRuff is backed by\nAstral\n. Read the\nlaunch post\n,\nor the original\nproject announcement\n.\nTestimonials\nSebasti√°n Ram√≠rez\n, creator\nof\nFastAPI\n:\nRuff is so fast that sometimes I add an intentional bug in the code just to confirm it's actually\nrunning and checking the code.\nNick Schrock\n, founder of\nElementl\n,\nco-creator of\nGraphQL\n:\nWhy is Ruff a gamechanger? Primarily because it is nearly 1000x faster. Literally. Not a typo. On\nour largest module (dagster itself, 250k LOC) pylint takes about 2.5 minutes, parallelized across 4\ncores on my M1. Running ruff against our\nentire\ncodebase takes .4 seconds.\nBryan Van de Ven\n, co-creator\nof\nBokeh\n, original author\nof\nConda\n:\nRuff is ~150-200x faster than flake8 on my machine, scanning the whole repo takes ~0.2s instead of\n~20s. This is an enormous quality of life improvement for local dev. It's fast enough that I added\nit as an actual commit hook, which is terrific.\nTimothy Crosley\n,\ncreator of\nisort\n:\nJust switched my first project to Ruff. Only one downside so far: it's so fast I couldn't believe\nit was working till I intentionally introduced some errors.\nTim Abbott\n, lead\ndeveloper of\nZulip\n:\nThis is just ridiculously fast...\nruff\nis amazing.\nTable of Contents\nFor more, see the\ndocumentation\n.\nGetting Started\nConfiguration\nRules\nContributing\nSupport\nAcknowledgements\nWho's Using Ruff?\nLicense\nGetting Started\nFor more, see the\ndocumentation\n.\nInstallation\nRuff is available as\nruff\non PyPI.\nInvoke Ruff directly with\nuvx\n:\nuvx ruff check\n#\nLint all files in the current directory.\nuvx ruff format\n#\nFormat all files in the current directory.\nOr install Ruff with\nuv\n(recommended),\npip\n, or\npipx\n:\n#\nWith uv.\nuv tool install ruff@latest\n#\nInstall Ruff globally.\nuv add --dev ruff\n#\nOr add Ruff to your project.\n#\nWith pip.\npip install ruff\n#\nWith pipx.\npipx install ruff\nStarting with version\n0.5.0\n, Ruff can be installed with our standalone installers:\n#\nOn macOS and Linux.\ncurl -LsSf https://astral.sh/ruff/install.sh\n|\nsh\n#\nOn Windows.\npowershell -c\n\"\nirm https://astral.sh/ruff/install.ps1 | iex\n\"\n#\nFor a specific version.\ncurl -LsSf https://astral.sh/ruff/0.14.0/install.sh\n|\nsh\npowershell -c\n\"\nirm https://astral.sh/ruff/0.14.0/install.ps1 | iex\n\"\nYou can also install Ruff via\nHomebrew\n,\nConda\n,\nand with\na variety of other package managers\n.\nUsage\nTo run Ruff as a linter, try any of the following:\nruff check\n#\nLint all files in the current directory (and any subdirectories).\nruff check path/to/code/\n#\nLint all files in `/path/to/code` (and any subdirectories).\nruff check path/to/code/\n*\n.py\n#\nLint all `.py` files in `/path/to/code`.\nruff check path/to/code/to/file.py\n#\nLint `file.py`.\nruff check @arguments.txt\n#\nLint using an input file, treating its contents as newline-delimited command-line arguments.\nOr, to run Ruff as a formatter:\nruff format\n#\nFormat all files in the current directory (and any subdirectories).\nruff format path/to/code/\n#\nFormat all files in `/path/to/code` (and any subdirectories).\nruff format path/to/code/\n*\n.py\n#\nFormat all `.py` files in `/path/to/code`.\nruff format path/to/code/to/file.py\n#\nFormat `file.py`.\nruff format @arguments.txt\n#\nFormat using an input file, treating its contents as newline-delimited command-line arguments.\nRuff can also be used as a\npre-commit\nhook via\nruff-pre-commit\n:\n-\nrepo\n:\nhttps://github.com/astral-sh/ruff-pre-commit\n#\nRuff version.\nrev\n:\nv0.14.0\nhooks\n:\n#\nRun the linter.\n-\nid\n:\nruff-check\nargs\n:\n[ --fix ]\n#\nRun the formatter.\n-\nid\n:\nruff-format\nRuff can also be used as a\nVS Code extension\nor with\nvarious other editors\n.\nRuff can also be used as a\nGitHub Action\nvia\nruff-action\n:\nname\n:\nRuff\non\n:\n[ push, pull_request ]\njobs\n:\nruff\n:\nruns-on\n:\nubuntu-latest\nsteps\n:\n      -\nuses\n:\nactions/checkout@v4\n-\nuses\n:\nastral-sh/ruff-action@v3\nConfiguration\nRuff can be configured through a\npyproject.toml\n,\nruff.toml\n, or\n.ruff.toml\nfile (see:\nConfiguration\n, or\nSettings\nfor a complete list of all configuration options).\nIf left unspecified, Ruff's default configuration is equivalent to the following\nruff.toml\nfile:\n#\nExclude a variety of commonly ignored directories.\nexclude\n= [\n\"\n.bzr\n\"\n,\n\"\n.direnv\n\"\n,\n\"\n.eggs\n\"\n,\n\"\n.git\n\"\n,\n\"\n.git-rewrite\n\"\n,\n\"\n.hg\n\"\n,\n\"\n.ipynb_checkpoints\n\"\n,\n\"\n.mypy_cache\n\"\n,\n\"\n.nox\n\"\n,\n\"\n.pants.d\n\"\n,\n\"\n.pyenv\n\"\n,\n\"\n.pytest_cache\n\"\n,\n\"\n.pytype\n\"\n,\n\"\n.ruff_cache\n\"\n,\n\"\n.svn\n\"\n,\n\"\n.tox\n\"\n,\n\"\n.venv\n\"\n,\n\"\n.vscode\n\"\n,\n\"\n__pypackages__\n\"\n,\n\"\n_build\n\"\n,\n\"\nbuck-out\n\"\n,\n\"\nbuild\n\"\n,\n\"\ndist\n\"\n,\n\"\nnode_modules\n\"\n,\n\"\nsite-packages\n\"\n,\n\"\nvenv\n\"\n,\n]\n#\nSame as Black.\nline-length\n=\n88\nindent-width\n=\n4\n#\nAssume Python 3.9\ntarget-version\n=\n\"\npy39\n\"\n[\nlint\n]\n#\nEnable Pyflakes (`F`) and a subset of the pycodestyle (`E`) codes by default.\nselect\n= [\n\"\nE4\n\"\n,\n\"\nE7\n\"\n,\n\"\nE9\n\"\n,\n\"\nF\n\"\n]\nignore\n= []\n#\nAllow fix for all enabled rules (when `--fix`) is provided.\nfixable\n= [\n\"\nALL\n\"\n]\nunfixable\n= []\n#\nAllow unused variables when underscore-prefixed.\ndummy-variable-rgx\n=\n\"\n^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$\n\"\n[\nformat\n]\n#\nLike Black, use double quotes for strings.\nquote-style\n=\n\"\ndouble\n\"\n#\nLike Black, indent with spaces, rather than tabs.\nindent-style\n=\n\"\nspace\n\"\n#\nLike Black, respect magic trailing commas.\nskip-magic-trailing-comma\n=\nfalse\n#\nLike Black, automatically detect the appropriate line ending.\nline-ending\n=\n\"\nauto\n\"\nNote that, in a\npyproject.toml\n, each section header should be prefixed with\ntool.ruff\n. For\nexample,\n[lint]\nshould be replaced with\n[tool.ruff.lint]\n.\nSome configuration options can be provided via dedicated command-line arguments, such as those\nrelated to rule enablement and disablement, file discovery, and logging level:\nruff check --select F401 --select F403 --quiet\nThe remaining configuration options can be provided through a catch-all\n--config\nargument:\nruff check --config\n\"\nlint.per-file-ignores = {'some_file.py' = ['F841']}\n\"\nTo opt in to the latest lint rules, formatter style changes, interface updates, and more, enable\npreview mode\nby setting\npreview = true\nin your configuration\nfile or passing\n--preview\non the command line. Preview mode enables a collection of unstable\nfeatures that may change prior to stabilization.\nSee\nruff help\nfor more on Ruff's top-level commands, or\nruff help check\nand\nruff help format\nfor more on the linting and formatting commands, respectively.\nRules\nRuff supports over 800 lint rules\n, many of which are inspired by popular tools like Flake8,\nisort, pyupgrade, and others. Regardless of the rule's origin, Ruff re-implements every rule in\nRust as a first-party feature.\nBy default, Ruff enables Flake8's\nF\nrules, along with a subset of the\nE\nrules, omitting any\nstylistic rules that overlap with the use of a formatter, like\nruff format\nor\nBlack\n.\nIf you're just getting started with Ruff,\nthe default rule set is a great place to start\n: it\ncatches a wide variety of common errors (like unused imports) with zero configuration.\nBeyond the defaults, Ruff re-implements some of the most popular Flake8 plugins and related code\nquality tools, including:\nautoflake\neradicate\nflake8-2020\nflake8-annotations\nflake8-async\nflake8-bandit\n(\n#1646\n)\nflake8-blind-except\nflake8-boolean-trap\nflake8-bugbear\nflake8-builtins\nflake8-commas\nflake8-comprehensions\nflake8-copyright\nflake8-datetimez\nflake8-debugger\nflake8-django\nflake8-docstrings\nflake8-eradicate\nflake8-errmsg\nflake8-executable\nflake8-future-annotations\nflake8-gettext\nflake8-implicit-str-concat\nflake8-import-conventions\nflake8-logging\nflake8-logging-format\nflake8-no-pep420\nflake8-pie\nflake8-print\nflake8-pyi\nflake8-pytest-style\nflake8-quotes\nflake8-raise\nflake8-return\nflake8-self\nflake8-simplify\nflake8-slots\nflake8-super\nflake8-tidy-imports\nflake8-todos\nflake8-type-checking\nflake8-use-pathlib\nflynt\n(\n#2102\n)\nisort\nmccabe\npandas-vet\npep8-naming\npydocstyle\npygrep-hooks\npylint-airflow\npyupgrade\ntryceratops\nyesqa\nFor a complete enumeration of the supported rules, see\nRules\n.\nContributing\nContributions are welcome and highly appreciated. To get started, check out the\ncontributing guidelines\n.\nYou can also join us on\nDiscord\n.\nSupport\nHaving trouble? Check out the existing issues on\nGitHub\n,\nor feel free to\nopen a new one\n.\nYou can also ask for help on\nDiscord\n.\nAcknowledgements\nRuff's linter draws on both the APIs and implementation details of many other\ntools in the Python ecosystem, especially\nFlake8\n,\nPyflakes\n,\npycodestyle\n,\npydocstyle\n,\npyupgrade\n, and\nisort\n.\nIn some cases, Ruff includes a \"direct\" Rust port of the corresponding tool.\nWe're grateful to the maintainers of these tools for their work, and for all\nthe value they've provided to the Python community.\nRuff's formatter is built on a fork of Rome's\nrome_formatter\n,\nand again draws on both API and implementation details from\nRome\n,\nPrettier\n, and\nBlack\n.\nRuff's import resolver is based on the import resolution algorithm from\nPyright\n.\nRuff is also influenced by a number of tools outside the Python ecosystem, like\nClippy\nand\nESLint\n.\nRuff is the beneficiary of a large number of\ncontributors\n.\nRuff is released under the MIT license.\nWho's Using Ruff?\nRuff is used by a number of major open-source projects and companies, including:\nAlbumentations\nAmazon (\nAWS SAM\n)\nAnki\nAnthropic (\nPython SDK\n)\nApache Airflow\nAstraZeneca (\nMagnus\n)\nBabel\nBenchling (\nRefac\n)\nBokeh\nCapital One (\ndatacompy\n)\nCrowdCent (\nNumerBlox\n)\nCryptography (PyCA)\nCERN (\nIndico\n)\nDVC\nDagger\nDagster\nDatabricks (\nMLflow\n)\nDify\nFastAPI\nGodot\nGradio\nGreat Expectations\nHTTPX\nHatch\nHome Assistant\nHugging Face (\nTransformers\n,\nDatasets\n,\nDiffusers\n)\nIBM (\nQiskit\n)\nING Bank (\npopmon\n,\nprobatus\n)\nIbis\nivy\nJAX\nJupyter\nKraken Tech\nLangChain\nLitestar\nLlamaIndex\nMatrix (\nSynapse\n)\nMegaLinter\nMeltano (\nMeltano CLI\n,\nSinger SDK\n)\nMicrosoft (\nSemantic Kernel\n,\nONNX Runtime\n,\nLightGBM\n)\nModern Treasury (\nPython SDK\n)\nMozilla (\nFirefox\n)\nMypy\nNautobot\nNetflix (\nDispatch\n)\nNeon\nNokia\nNoneBot\nNumPyro\nONNX\nOpenBB\nOpen Wine Components\nPDM\nPaddlePaddle\nPandas\nPillow\nPoetry\nPolars\nPostHog\nPrefect (\nPython SDK\n,\nMarvin\n)\nPyInstaller\nPyMC\nPyMC-Marketing\npytest\nPyTorch\nPydantic\nPylint\nPyVista\nReflex\nRiver\nRippling\nRobyn\nSaleor\nScale AI (\nLaunch SDK\n)\nSciPy\nSnowflake (\nSnowCLI\n)\nSphinx\nStable Baselines3\nStarlette\nStreamlit\nThe Algorithms\nVega-Altair\nWeblate\nWordPress (\nOpenverse\n)\nZenML\nZulip\nbuild (PyPA)\ncibuildwheel (PyPA)\ndelta-rs\nfeaturetools\nmeson-python\nnox\npip\nShow Your Support\nIf you're using Ruff, consider adding the Ruff badge to your project's\nREADME.md\n:\n[\n![\nRuff\n]\n(\nhttps://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json\n)]\n(\nhttps://github.com/astral-sh/ruff\n)\n...or\nREADME.rst\n:\n..\nimage\n::\nhttps://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json\n:target:\nhttps://github.com/astral-sh/ruff\n:alt:\nRuff\n...or, as HTML:\n<\na\nhref\n=\"\nhttps://github.com/astral-sh/ruff\n\"\n>\n<\nimg\nsrc\n=\"\nhttps://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json\n\"\nalt\n=\"\nRuff\n\"\nstyle\n=\"\nmax-width:100%;\n\"\n>\n</\na\n>\nLicense\nThis repository is licensed under the\nMIT License",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 41",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 42,956"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/astral-sh/ruff"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/JannisX11/blockbench",
      "title": "JannisX11/blockbench",
      "date": null,
      "executive_summary": [
        "Blockbench - A low poly 3D model editor",
        "---",
        "Blockbench\nBlockbench is a free and open source model editor for low-poly models with pixel art textures.\nModels can be exported into standardized formats, to be shared, rendered, 3D-printed, or used in game engines. There are also multiple dedicated formats for Minecraft Java and Bedrock Edition with format-specific features.\nBlockbench features a modern and beginner friendly interface, but also offers lots of customization and advanced features for experienced 3D artists. Plugins can extend the functionality of the program even further.\nWebsite and download:\nblockbench.net\nContribution\nCheck out the\nContribution Guidelines\n.\nLaunching Blockbench\nTo launch Blockbench from source, you can clone the repository, navigate to the correct branch and launch the program in development mode using the instructions below. If you just want to use the latest version, please download the app from the website.\nInstall\nNodeJS\n.\nThen install all dependencies via\nnpm install\nBundle the code via\nnpm run bundle\nFinally, launch Blockbench using\nnpm run dev\nPlugins\nBlockbench supports Javascript-based plugins. Learn more about creating plugins on\nhttps://www.blockbench.net/wiki/docs/plugin\n.\nLicense\nThe Blockbench source-code is licensed under the GPL license version 3. See\nLICENSE.MD\n.\nModifications to the source code can be made under the terms of that license.\nBlockbench plugins (external scripts) and themes (theme files to customize the design) that interact with the Blockbench API are an exception. Plugins and themes can be created and/or published as open source, proprietary or paid software.\nAll assets created with Blockbench (models, textures, animations, screenshots etc.) are your own!",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 41",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 4,413"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/JannisX11/blockbench"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/jgraph/drawio-desktop",
      "title": "jgraph/drawio-desktop",
      "date": null,
      "executive_summary": [
        "Official electron build of draw.io",
        "---",
        "About\ndrawio-desktop\nis a diagramming desktop app based on\nElectron\nthat wraps the\ncore draw.io editor\n.\nDownload built binaries from the\nreleases section\n.\nCan I use this app for free?\nYes, under the apache 2.0 license. If you don't change the code and accept it is provided \"as-is\", you can use it for any purpose.\nSecurity\ndraw.io Desktop is designed to be completely isolated from the Internet, apart from the update process. This checks github.com at startup for a newer version and downloads it from an AWS S3 bucket owned by Github. All JavaScript files are self-contained, the Content Security Policy forbids running remotely loaded JavaScript.\nNo diagram data is ever sent externally, nor do we send any analytics about app usage externally. There is a Content Security Policy in place on the web part of the interface to ensure external transmission cannot happen, even by accident.\nSecurity and isolating the app are the primarily objectives of draw.io desktop. If you ask for anything that involves external connections enabled in the app by default, the answer will be no.\nSupport\nSupport is provided on a reasonable business constraints basis, but without anything contractually binding. All support is provided via this repo. There is no private ticketing support for non-paying users.\nPurchasing draw.io for Confluence or Jira does not entitle you to commercial support for draw.io desktop.\nDeveloping\ndraw.io\nis a git submodule of\ndrawio-desktop\n. To get both you need to clone recursively:\ngit clone --recursive https://github.com/jgraph/drawio-desktop.git\nTo run this:\nnpm install\n(in the root directory of this repo)\n[internal use only] export DRAWIO_ENV=dev if you want to develop/debug in dev mode.\nnpm start\nin the root directory of this repo\nruns the app. For debugging, use\nnpm start --enable-logging\n.\nNote: If a symlink is used to refer to drawio repo (instead of the submodule), then symlink the\nnode_modules\ndirectory inside\ndrawio/src/main/webapp\nalso.\nTo release:\nUpdate the draw.io sub-module and push the change. Add version tag before pushing to origin.\nWait for the builds to complete (\nhttps://travis-ci.org/jgraph/drawio-desktop\nand\nhttps://ci.appveyor.com/project/davidjgraph/drawio-desktop\n)\nGo to\nhttps://github.com/jgraph/drawio-desktop/releases\n, edit the preview release.\nDownload the windows exe and windows portable, sign them using\nsigntool sign /a /tr http://rfc3161timestamp.globalsign.com/advanced /td SHA256 c:/path/to/your/file.exe\nRe-upload signed file as\ndraw.io-windows-installer-x.y.z.exe\nand\ndraw.io-windows-no-installer-x.y.z.exe\nAdd release notes\nPublish release\nNote\n: In Windows release, when using both x64 and is32 as arch, the result is one big file with both archs. This is why we split them.\nLocal Storage and Session Storage is stored in the AppData folder:\nmacOS:\n~/Library/Application Support/draw.io\nWindows:\nC:\\Users\\<USER-NAME>\\AppData\\Roaming\\draw.io\\\nNot open-contribution\ndraw.io is closed to contributions (unless a maintainer permits it, which is extremely rare).\nThe level of complexity of this project means that even simple changes\ncan break a\nlot\nof other moving parts. The amount of testing required\nis far more than it first seems. If we were to receive a PR, we'd have\nto basically throw it away and write it how we want it to be implemented.\nWe are grateful for community involvement, bug reports, & feature requests. We do\nnot wish to come off as anything but welcoming, however, we've\nmade the decision to keep this project closed to contributions for\nthe long term viability of the project.",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 38",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 57,185"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/jgraph/drawio-desktop"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/linshenkx/prompt-optimizer",
      "title": "linshenkx/prompt-optimizer",
      "date": null,
      "executive_summary": [
        "‰∏ÄÊ¨æÊèêÁ§∫ËØç‰ºòÂåñÂô®ÔºåÂä©Âäõ‰∫éÁºñÂÜôÈ´òË¥®ÈáèÁöÑÊèêÁ§∫ËØç",
        "---",
        "Prompt Optimizer (ÊèêÁ§∫ËØç‰ºòÂåñÂô®) üöÄ\nEnglish\n|\n‰∏≠Êñá\nÂú®Á∫ø‰ΩìÈ™å\n|\nÂø´ÈÄüÂºÄÂßã\n|\nÂ∏∏ËßÅÈóÆÈ¢ò\n|\nChromeÊèí‰ª∂\n|\nüíñËµûÂä©ÊîØÊåÅ\nÂºÄÂèëÊñáÊ°£\n|\nVercelÈÉ®ÁΩ≤ÊåáÂçó\n|\nMCPÈÉ®ÁΩ≤‰ΩøÁî®ËØ¥Êòé\n|\nDeepWikiÊñáÊ°£\n|\nZReadÊñáÊ°£\nüìñ È°πÁõÆÁÆÄ‰ªã\nPrompt OptimizerÊòØ‰∏Ä‰∏™Âº∫Â§ßÁöÑAIÊèêÁ§∫ËØç‰ºòÂåñÂ∑•ÂÖ∑ÔºåÂ∏ÆÂä©‰Ω†ÁºñÂÜôÊõ¥Â•ΩÁöÑAIÊèêÁ§∫ËØçÔºåÊèêÂçáAIËæìÂá∫Ë¥®Èáè„ÄÇÊîØÊåÅWebÂ∫îÁî®„ÄÅÊ°åÈù¢Â∫îÁî®„ÄÅChromeÊèí‰ª∂ÂíåDockerÈÉ®ÁΩ≤ÂõõÁßç‰ΩøÁî®ÊñπÂºè„ÄÇ\nüé• ÂäüËÉΩÊºîÁ§∫\n1. ËßíËâ≤ÊâÆÊºîÂØπËØùÔºöÊøÄÂèëÂ∞èÊ®°ÂûãÊΩúÂäõ\nÂú®ËøΩÊ±ÇÊàêÊú¨ÊïàÁõäÁöÑÁîü‰∫ßÊàñÊ≥®ÈáçÈöêÁßÅÁöÑÊú¨Âú∞ÂåñÂú∫ÊôØ‰∏≠ÔºåÁªìÊûÑÂåñÁöÑÊèêÁ§∫ËØçËÉΩËÆ©Â∞èÊ®°ÂûãÁ®≥ÂÆöÂú∞ËøõÂÖ•ËßíËâ≤ÔºåÊèê‰æõÊ≤âÊµ∏Âºè„ÄÅÈ´ò‰∏ÄËá¥ÊÄßÁöÑËßíËâ≤ÊâÆÊºî‰ΩìÈ™åÔºåÊúâÊïàÊøÄÂèëÂÖ∂ÊΩúÂäõ„ÄÇ\n2. Áü•ËØÜÂõæË∞±ÊèêÂèñÔºö‰øùÈöúÁîü‰∫ßÁéØÂ¢ÉÁöÑÁ®≥ÂÆöÊÄß\nÂú®ÈúÄË¶ÅÁ®ãÂ∫èÂåñÂ§ÑÁêÜÁöÑÁîü‰∫ßÁéØÂ¢É‰∏≠ÔºåÈ´òË¥®ÈáèÁöÑÊèêÁ§∫ËØçËÉΩÊòæËëóÈôç‰ΩéÂØπÊ®°ÂûãÊô∫ËÉΩÁ®ãÂ∫¶ÁöÑË¶ÅÊ±ÇÔºå‰ΩøÂæóÊõ¥ÁªèÊµéÁöÑÂ∞èÊ®°Âûã‰πüËÉΩÁ®≥ÂÆöËæìÂá∫ÂèØÈù†ÁöÑÊåáÂÆöÊ†ºÂºè„ÄÇÊú¨Â∑•ÂÖ∑Êó®Âú®ËæÖÂä©ÂºÄÂèëËÄÖÂø´ÈÄüËææÂà∞Ê≠§ÁõÆÁöÑÔºå‰ªéËÄåÂä†ÈÄüÂºÄÂèë„ÄÅ‰øùÈöúÁ®≥ÂÆöÔºåÂÆûÁé∞ÈôçÊú¨Â¢ûÊïà„ÄÇ\n3. ËØóÊ≠åÂÜô‰ΩúÔºöËæÖÂä©ÂàõÊÑèÊé¢Á¥¢‰∏éÈúÄÊ±ÇÂÆöÂà∂\nÂΩìÈù¢ÂØπ‰∏Ä‰∏™Âº∫Â§ßÁöÑAIÔºåÊàë‰ª¨ÁöÑÁõÆÊ†á‰∏çÂè™ÊòØÂæóÂà∞‰∏Ä‰∏™‚ÄúÂ•Ω‚ÄùÁ≠îÊ°àÔºåËÄåÊòØÂæóÂà∞‰∏Ä‰∏™‚ÄúÊàë‰ª¨ÊÉ≥Ë¶ÅÁöÑ‚ÄùÁã¨ÁâπÁ≠îÊ°à„ÄÇÊú¨Â∑•ÂÖ∑ËÉΩÂ∏ÆÂä©Áî®Êà∑Â∞Ü‰∏Ä‰∏™Ê®°Á≥äÁöÑÁÅµÊÑüÔºàÂ¶Ç‚ÄúÂÜôÈ¶ñËØó‚ÄùÔºâÁªÜÂåñ‰∏∫ÂÖ∑‰ΩìÁöÑÈúÄÊ±ÇÔºàÂÖ≥‰∫é‰ªÄ‰πà‰∏ªÈ¢ò„ÄÅ‰ΩïÁßçÊÑèË±°„ÄÅ‰ΩïÁßçÊÉÖÊÑüÔºâÔºåËæÖÂä©ÊÇ®Êé¢Á¥¢„ÄÅÂèëÊéòÂπ∂Á≤æÁ°ÆË°®ËææËá™Â∑±ÁöÑÂàõÊÑèÔºå‰∏éAIÂÖ±ÂàõÁã¨‰∏ÄÊó†‰∫åÁöÑ‰ΩúÂìÅ„ÄÇ\n‚ú® Ê†∏ÂøÉÁâπÊÄß\nüéØ\nÊô∫ËÉΩ‰ºòÂåñ\nÔºö‰∏ÄÈîÆ‰ºòÂåñÊèêÁ§∫ËØçÔºåÊîØÊåÅÂ§öËΩÆËø≠‰ª£ÊîπËøõÔºåÊèêÂçáAIÂõûÂ§çÂáÜÁ°ÆÂ∫¶\nüìù\nÂèåÊ®°Âºè‰ºòÂåñ\nÔºöÊîØÊåÅÁ≥ªÁªüÊèêÁ§∫ËØç‰ºòÂåñÂíåÁî®Êà∑ÊèêÁ§∫ËØç‰ºòÂåñÔºåÊª°Ë∂≥‰∏çÂêå‰ΩøÁî®Âú∫ÊôØ\nüîÑ\nÂØπÊØîÊµãËØï\nÔºöÊîØÊåÅÂéüÂßãÊèêÁ§∫ËØçÂíå‰ºòÂåñÂêéÊèêÁ§∫ËØçÁöÑÂÆûÊó∂ÂØπÊØîÔºåÁõ¥ËßÇÂ±ïÁ§∫‰ºòÂåñÊïàÊûú\nü§ñ\nÂ§öÊ®°ÂûãÈõÜÊàê\nÔºöÊîØÊåÅOpenAI„ÄÅGemini„ÄÅDeepSeek„ÄÅÊô∫Ë∞±AI„ÄÅSiliconFlowÁ≠â‰∏ªÊµÅAIÊ®°Âûã\nüñºÔ∏è\nÂõæÂÉèÁîüÊàê\nÔºöÊîØÊåÅÊñáÁîüÂõæÔºàT2IÔºâÂíåÂõæÁîüÂõæÔºàI2IÔºâÔºåÈõÜÊàêGemini„ÄÅSeedreamÁ≠âÂõæÂÉèÊ®°Âûã\nüìä\nÈ´òÁ∫ßÊµãËØïÊ®°Âºè\nÔºö‰∏ä‰∏ãÊñáÂèòÈáèÁÆ°ÁêÜ„ÄÅÂ§öËΩÆ‰ºöËØùÊµãËØï„ÄÅÂ∑•ÂÖ∑Ë∞ÉÁî®ÔºàFunction CallingÔºâÊîØÊåÅ\nüîí\nÂÆâÂÖ®Êû∂ÊûÑ\nÔºöÁ∫ØÂÆ¢Êà∑Á´ØÂ§ÑÁêÜÔºåÊï∞ÊçÆÁõ¥Êé•‰∏éAIÊúçÂä°ÂïÜ‰∫§‰∫íÔºå‰∏çÁªèËøá‰∏≠Èó¥ÊúçÂä°Âô®\nüì±\nÂ§öÁ´ØÊîØÊåÅ\nÔºöÂêåÊó∂Êèê‰æõWebÂ∫îÁî®„ÄÅÊ°åÈù¢Â∫îÁî®„ÄÅChromeÊèí‰ª∂ÂíåDockerÈÉ®ÁΩ≤ÂõõÁßç‰ΩøÁî®ÊñπÂºè\nüîê\nËÆøÈóÆÊéßÂà∂\nÔºöÊîØÊåÅÂØÜÁ†Å‰øùÊä§ÂäüËÉΩÔºå‰øùÈöúÈÉ®ÁΩ≤ÂÆâÂÖ®\nüß©\nMCPÂçèËÆÆÊîØÊåÅ\nÔºöÊîØÊåÅModel Context Protocol (MCP) ÂçèËÆÆÔºåÂèØ‰∏éClaude DesktopÁ≠âMCPÂÖºÂÆπÂ∫îÁî®ÈõÜÊàê\nüöÄ È´òÁ∫ßÂäüËÉΩ\nÂõæÂÉèÁîüÊàêÊ®°Âºè\nüñºÔ∏è\nÊñáÁîüÂõæÔºàT2IÔºâ\nÔºöÈÄöËøáÊñáÊú¨ÊèêÁ§∫ËØçÁîüÊàêÂõæÂÉè\nüé®\nÂõæÁîüÂõæÔºàI2IÔºâ\nÔºöÂü∫‰∫éÊú¨Âú∞ÂõæÁâáËøõË°åÂõæÂÉèÂèòÊç¢Âíå‰ºòÂåñ\nüîå\nÂ§öÊ®°ÂûãÊîØÊåÅ\nÔºöÈõÜÊàêGemini„ÄÅSeedreamÁ≠â‰∏ªÊµÅÂõæÂÉèÁîüÊàêÊ®°Âûã\n‚öôÔ∏è\nÊ®°ÂûãÂèÇÊï∞\nÔºöÊîØÊåÅÂêÑÊ®°ÂûãÁâπÊúâÂèÇÊï∞ÈÖçÁΩÆÔºàÂ¶ÇÂ∞∫ÂØ∏„ÄÅÈ£éÊ†ºÁ≠âÔºâ\nüì•\nÈ¢ÑËßà‰∏é‰∏ãËΩΩ\nÔºöÂÆûÊó∂È¢ÑËßàÁîüÊàêÁªìÊûúÔºåÊîØÊåÅ‰∏ãËΩΩ‰øùÂ≠ò\nÈ´òÁ∫ßÊµãËØïÊ®°Âºè\nüìä\n‰∏ä‰∏ãÊñáÂèòÈáèÁÆ°ÁêÜ\nÔºöËá™ÂÆö‰πâÂèòÈáè„ÄÅÊâπÈáèÊõøÊç¢„ÄÅÂèòÈáèÈ¢ÑËßà\nüí¨\nÂ§öËΩÆ‰ºöËØùÊµãËØï\nÔºöÊ®°ÊãüÁúüÂÆûÂØπËØùÂú∫ÊôØÔºåÊµãËØïÊèêÁ§∫ËØçÂú®Â§öËΩÆ‰∫§‰∫í‰∏≠ÁöÑË°®Áé∞\nüõ†Ô∏è\nÂ∑•ÂÖ∑Ë∞ÉÁî®ÊîØÊåÅ\nÔºöFunction CallingÈõÜÊàêÔºåÊîØÊåÅOpenAIÂíåGeminiÂ∑•ÂÖ∑Ë∞ÉÁî®\nüéØ\nÁÅµÊ¥ªË∞ÉËØï\nÔºöÊõ¥Âº∫Â§ßÁöÑÊèêÁ§∫ËØçÊµãËØïÂíåË∞ÉËØïËÉΩÂäõ\nËØ¶ÁªÜ‰ΩøÁî®ËØ¥ÊòéËØ∑Êü•Áúã\nÂõæÂÉèÊ®°ÂºèÊñáÊ°£\nÂø´ÈÄüÂºÄÂßã\n1. ‰ΩøÁî®Âú®Á∫øÁâàÊú¨ÔºàÊé®ËçêÔºâ\nÁõ¥Êé•ËÆøÈóÆÔºö\nhttps://prompt.always200.com\nÈ°πÁõÆÊòØÁ∫ØÂâçÁ´ØÈ°πÁõÆÔºåÊâÄÊúâÊï∞ÊçÆÂè™Â≠òÂÇ®Âú®ÊµèËßàÂô®Êú¨Âú∞Ôºå‰∏ç‰ºö‰∏ä‰º†Ëá≥‰ªª‰ΩïÊúçÂä°Âô®ÔºåÂõ†Ê≠§Áõ¥Êé•‰ΩøÁî®Âú®Á∫øÁâàÊú¨‰πüÊòØÂÆâÂÖ®ÂèØÈù†ÁöÑ\n2. VercelÈÉ®ÁΩ≤\nÊñπÂºè1Ôºö‰∏ÄÈîÆÈÉ®ÁΩ≤Âà∞Ëá™Â∑±ÁöÑVercel(Êñπ‰æøÔºå‰ΩÜÂêéÁª≠Êó†Ê≥ïËá™Âä®Êõ¥Êñ∞)Ôºö\nÊñπÂºè2: ForkÈ°πÁõÆÂêéÂú®Vercel‰∏≠ÂØºÂÖ•ÔºàÊé®ËçêÔºå‰ΩÜÈúÄÂèÇËÄÉÈÉ®ÁΩ≤ÊñáÊ°£ËøõË°åÊâãÂä®ËÆæÁΩÆÔºâÔºö\nÂÖàForkÈ°πÁõÆÂà∞Ëá™Â∑±ÁöÑGitHub\nÁÑ∂ÂêéÂú®Vercel‰∏≠ÂØºÂÖ•ËØ•È°πÁõÆ\nÂèØË∑üË∏™Ê∫êÈ°πÁõÆÊõ¥Êñ∞Ôºå‰æø‰∫éÂêåÊ≠•ÊúÄÊñ∞ÂäüËÉΩÂíå‰øÆÂ§ç\nÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáèÔºö\nACCESS_PASSWORD\nÔºöËÆæÁΩÆËÆøÈóÆÂØÜÁ†ÅÔºåÂêØÁî®ËÆøÈóÆÈôêÂà∂\nVITE_OPENAI_API_KEY\nÁ≠âÔºöÈÖçÁΩÆÂêÑAIÊúçÂä°ÂïÜÁöÑAPIÂØÜÈí•\nÊõ¥Â§öËØ¶ÁªÜÁöÑÈÉ®ÁΩ≤Ê≠•È™§ÂíåÊ≥®ÊÑè‰∫ãÈ°πÔºåËØ∑Êü•ÁúãÔºö\nVercelÈÉ®ÁΩ≤ÊåáÂçó\n3. ‰∏ãËΩΩÊ°åÈù¢Â∫îÁî®\n‰ªé\nGitHub Releases\n‰∏ãËΩΩÊúÄÊñ∞ÁâàÊú¨„ÄÇÊàë‰ª¨‰∏∫ÂêÑÂπ≥Âè∞Êèê‰æõ\nÂÆâË£ÖÁ®ãÂ∫è\nÂíå\nÂéãÁº©ÂåÖ\n‰∏§ÁßçÊ†ºÂºè„ÄÇ\nÂÆâË£ÖÁ®ãÂ∫è (Êé®Ëçê)\n: Â¶Ç\n*.exe\n,\n*.dmg\n,\n*.AppImage\nÁ≠â„ÄÇ\nÂº∫ÁÉàÊé®Ëçê‰ΩøÁî®Ê≠§ÊñπÂºèÔºåÂõ†‰∏∫ÂÆÉÊîØÊåÅËá™Âä®Êõ¥Êñ∞\n„ÄÇ\nÂéãÁº©ÂåÖ\n: Â¶Ç\n*.zip\n„ÄÇËß£ÂéãÂç≥Áî®Ôºå‰ΩÜÊó†Ê≥ïËá™Âä®Êõ¥Êñ∞„ÄÇ\nÊ°åÈù¢Â∫îÁî®Ê†∏ÂøÉ‰ºòÂäø\n:\n‚úÖ\nÊó†Ë∑®ÂüüÈôêÂà∂\nÔºö‰Ωú‰∏∫ÂéüÁîüÊ°åÈù¢Â∫îÁî®ÔºåÂÆÉËÉΩÂΩªÂ∫ïÊëÜËÑ±ÊµèËßàÂô®Ë∑®ÂüüÔºàCORSÔºâÈóÆÈ¢òÁöÑÂõ∞Êâ∞„ÄÇËøôÊÑèÂë≥ÁùÄÊÇ®ÂèØ‰ª•Áõ¥Êé•ËøûÊé•‰ªª‰ΩïAIÊúçÂä°Êèê‰æõÂïÜÁöÑAPIÔºåÂåÖÊã¨Êú¨Âú∞ÈÉ®ÁΩ≤ÁöÑOllamaÊàñÊúâ‰∏•Ê†ºÂÆâÂÖ®Á≠ñÁï•ÁöÑÂïÜ‰∏öAPIÔºåËé∑ÂæóÊúÄÂÆåÊï¥„ÄÅÊúÄÁ®≥ÂÆöÁöÑÂäüËÉΩ‰ΩìÈ™å„ÄÇ\n‚úÖ\nËá™Âä®Êõ¥Êñ∞\nÔºöÈÄöËøáÂÆâË£ÖÁ®ãÂ∫èÔºàÂ¶Ç\n.exe\n,\n.dmg\nÔºâÂÆâË£ÖÁöÑÁâàÊú¨ÔºåËÉΩÂ§üËá™Âä®Ê£ÄÊü•Âπ∂Êõ¥Êñ∞Âà∞ÊúÄÊñ∞Áâà„ÄÇ\n‚úÖ\nÁã¨Á´ãËøêË°å\nÔºöÊó†ÈúÄ‰æùËµñÊµèËßàÂô®ÔºåÊèê‰æõÊõ¥Âø´ÁöÑÂìçÂ∫îÂíåÊõ¥‰Ω≥ÁöÑÊÄßËÉΩ„ÄÇ\n4. ÂÆâË£ÖChromeÊèí‰ª∂\n‰ªéChromeÂïÜÂ∫óÂÆâË£ÖÔºàÁî±‰∫éÂÆ°ÊâπËæÉÊÖ¢ÔºåÂèØËÉΩ‰∏çÊòØÊúÄÊñ∞ÁöÑÔºâÔºö\nChromeÂïÜÂ∫óÂú∞ÂùÄ\nÁÇπÂáªÂõæÊ†áÂç≥ÂèØÊâìÂºÄÊèêÁ§∫ËØç‰ºòÂåñÂô®\n5. DockerÈÉ®ÁΩ≤\nÁÇπÂáªÊü•Áúã Docker ÈÉ®ÁΩ≤ÂëΩ‰ª§\n#\nËøêË°åÂÆπÂô®ÔºàÈªòËÆ§ÈÖçÁΩÆÔºâ\ndocker run -d -p 8081:80 --restart unless-stopped --name prompt-optimizer linshen/prompt-optimizer\n#\nËøêË°åÂÆπÂô®ÔºàÈÖçÁΩÆAPIÂØÜÈí•ÂíåËÆøÈóÆÂØÜÁ†ÅÔºâ\ndocker run -d -p 8081:80 \\\n  -e VITE_OPENAI_API_KEY=your_key \\\n  -e ACCESS_USERNAME=your_username\n\\\n#\nÂèØÈÄâÔºåÈªòËÆ§‰∏∫\"admin\"\n-e ACCESS_PASSWORD=your_password\n\\\n#\nËÆæÁΩÆËÆøÈóÆÂØÜÁ†Å\n--restart unless-stopped \\\n  --name prompt-optimizer \\\n  linshen/prompt-optimizer\nÂõΩÂÜÖÈïúÂÉè\n: Â¶ÇÊûúDocker HubËÆøÈóÆËæÉÊÖ¢ÔºåÂèØ‰ª•Â∞Ü‰∏äËø∞ÂëΩ‰ª§‰∏≠ÁöÑ\nlinshen/prompt-optimizer\nÊõøÊç¢‰∏∫\nregistry.cn-guangzhou.aliyuncs.com/prompt-optimizer/prompt-optimizer\n6. Docker ComposeÈÉ®ÁΩ≤\nÁÇπÂáªÊü•Áúã Docker Compose ÈÉ®ÁΩ≤Ê≠•È™§\n#\n1. ÂÖãÈöÜ‰ªìÂ∫ì\ngit clone https://github.com/linshenkx/prompt-optimizer.git\ncd\nprompt-optimizer\n#\n2. ÂèØÈÄâÔºöÂàõÂª∫.envÊñá‰ª∂ÈÖçÁΩÆAPIÂØÜÈí•ÂíåËÆøÈóÆËÆ§ËØÅ\ncp env.local.example .env\n#\nÁºñËæë .env Êñá‰ª∂ÔºåÂ°´ÂÖ•ÂÆûÈôÖÁöÑ API ÂØÜÈí•ÂíåÈÖçÁΩÆ\n#\n3. ÂêØÂä®ÊúçÂä°\ndocker compose up -d\n#\n4. Êü•ÁúãÊó•Âøó\ndocker compose logs -f\n#\n5. ËÆøÈóÆÊúçÂä°\nWeb ÁïåÈù¢Ôºöhttp://localhost:8081\nMCP ÊúçÂä°Âô®Ôºöhttp://localhost:8081/mcp\n‰Ω†ËøòÂèØ‰ª•Áõ¥Êé•ÁºñËæëdocker-compose.ymlÊñá‰ª∂ÔºåËá™ÂÆö‰πâÈÖçÁΩÆÔºö\nÁÇπÂáªÊü•Áúã docker-compose.yml Á§∫‰æã\nservices\n:\nprompt-optimizer\n:\n#\n‰ΩøÁî®Docker HubÈïúÂÉè\nimage\n:\nlinshen/prompt-optimizer:latest\n#\nÊàñ‰ΩøÁî®ÈòøÈáå‰∫ëÈïúÂÉèÔºàÂõΩÂÜÖÁî®Êà∑Êé®ËçêÔºâ\n#\nimage: registry.cn-guangzhou.aliyuncs.com/prompt-optimizer/prompt-optimizer:latest\ncontainer_name\n:\nprompt-optimizer\nrestart\n:\nunless-stopped\nports\n:\n      -\n\"\n8081:80\n\"\n#\nWebÂ∫îÁî®Á´ØÂè£ÔºàÂåÖÂê´MCPÊúçÂä°Âô®ÔºåÈÄöËøá/mcpË∑ØÂæÑËÆøÈóÆÔºâ\nenvironment\n:\n#\nAPIÂØÜÈí•ÈÖçÁΩÆ\n-\nVITE_OPENAI_API_KEY=your_openai_key\n-\nVITE_GEMINI_API_KEY=your_gemini_key\n#\nËÆøÈóÆÊéßÂà∂ÔºàÂèØÈÄâÔºâ\n-\nACCESS_USERNAME=admin\n-\nACCESS_PASSWORD=your_password\n7. MCP Server ‰ΩøÁî®ËØ¥Êòé\nÁÇπÂáªÊü•Áúã MCP Server ‰ΩøÁî®ËØ¥Êòé\nPrompt Optimizer Áé∞Âú®ÊîØÊåÅ Model Context Protocol (MCP) ÂçèËÆÆÔºåÂèØ‰ª•‰∏é Claude Desktop Á≠âÊîØÊåÅ MCP ÁöÑ AI Â∫îÁî®ÈõÜÊàê„ÄÇ\nÂΩìÈÄöËøá Docker ËøêË°åÊó∂ÔºåMCP Server ‰ºöËá™Âä®ÂêØÂä®ÔºåÂπ∂ÂèØÈÄöËøá\nhttp://ip:port/mcp\nËÆøÈóÆ„ÄÇ\nÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ\nMCP Server ÈúÄË¶ÅÈÖçÁΩÆ API ÂØÜÈí•ÊâçËÉΩÊ≠£Â∏∏Â∑•‰Ωú„ÄÇ‰∏ªË¶ÅÁöÑ MCP ‰∏ìÂ±ûÈÖçÁΩÆÔºö\n#\nMCP ÊúçÂä°Âô®ÈÖçÁΩÆ\nMCP_DEFAULT_MODEL_PROVIDER=openai\n#\nÂèØÈÄâÂÄºÔºöopenai, gemini, deepseek, siliconflow, zhipu, custom\nMCP_LOG_LEVEL=info\n#\nÊó•ÂøóÁ∫ßÂà´\nDocker ÁéØÂ¢É‰∏ã‰ΩøÁî® MCP\nÂú® Docker ÁéØÂ¢É‰∏≠ÔºåMCP Server ‰ºö‰∏é Web Â∫îÁî®‰∏ÄËµ∑ËøêË°åÔºåÊÇ®ÂèØ‰ª•ÈÄöËøá Web Â∫îÁî®ÁöÑÁõ∏ÂêåÁ´ØÂè£ËÆøÈóÆ MCP ÊúçÂä°ÔºåË∑ØÂæÑ‰∏∫\n/mcp\n„ÄÇ\n‰æãÂ¶ÇÔºåÂ¶ÇÊûúÊÇ®Â∞ÜÂÆπÂô®ÁöÑ 80 Á´ØÂè£Êò†Â∞ÑÂà∞‰∏ªÊú∫ÁöÑ 8081 Á´ØÂè£Ôºö\ndocker run -d -p 8081:80 \\\n  -e VITE_OPENAI_API_KEY=your-openai-key \\\n  -e MCP_DEFAULT_MODEL_PROVIDER=openai \\\n  --name prompt-optimizer \\\n  linshen/prompt-optimizer\nÈÇ£‰πà MCP Server Â∞ÜÂèØ‰ª•ÈÄöËøá\nhttp://localhost:8081/mcp\nËÆøÈóÆ„ÄÇ\nClaude Desktop ÈõÜÊàêÁ§∫‰æã\nË¶ÅÂú® Claude Desktop ‰∏≠‰ΩøÁî® Prompt OptimizerÔºåÊÇ®ÈúÄË¶ÅÂú® Claude Desktop ÁöÑÈÖçÁΩÆÊñá‰ª∂‰∏≠Ê∑ªÂä†ÊúçÂä°ÈÖçÁΩÆ„ÄÇ\nÊâæÂà∞ Claude Desktop ÁöÑÈÖçÁΩÆÁõÆÂΩïÔºö\nWindows:\n%APPDATA%\\Claude\\services\nmacOS:\n~/Library/Application Support/Claude/services\nLinux:\n~/.config/Claude/services\nÁºñËæëÊàñÂàõÂª∫\nservices.json\nÊñá‰ª∂ÔºåÊ∑ªÂä†‰ª•‰∏ãÂÜÖÂÆπÔºö\n{\n\"services\"\n: [\n    {\n\"name\"\n:\n\"\nPrompt Optimizer\n\"\n,\n\"url\"\n:\n\"\nhttp://localhost:8081/mcp\n\"\n}\n  ]\n}\nËØ∑Á°Æ‰øùÂ∞Ü\nlocalhost:8081\nÊõøÊç¢‰∏∫ÊÇ®ÂÆûÈôÖÈÉ®ÁΩ≤ Prompt Optimizer ÁöÑÂú∞ÂùÄÂíåÁ´ØÂè£„ÄÇ\nÂèØÁî®Â∑•ÂÖ∑\noptimize-user-prompt\n: ‰ºòÂåñÁî®Êà∑ÊèêÁ§∫ËØç‰ª•ÊèêÈ´ò LLM ÊÄßËÉΩ\noptimize-system-prompt\n: ‰ºòÂåñÁ≥ªÁªüÊèêÁ§∫ËØç‰ª•ÊèêÈ´ò LLM ÊÄßËÉΩ\niterate-prompt\n: ÂØπÂ∑≤ÁªèÊàêÁÜü/ÂÆåÂñÑÁöÑÊèêÁ§∫ËØçËøõË°åÂÆöÂêëËø≠‰ª£‰ºòÂåñ\nÊõ¥Â§öËØ¶ÁªÜ‰ø°ÊÅØÔºåËØ∑Êü•Áúã\nMCP ÊúçÂä°Âô®Áî®Êà∑ÊåáÂçó\n„ÄÇ\n‚öôÔ∏è APIÂØÜÈí•ÈÖçÁΩÆ\nÁÇπÂáªÊü•ÁúãAPIÂØÜÈí•ÈÖçÁΩÆÊñπÊ≥ï\nÊñπÂºè‰∏ÄÔºöÈÄöËøáÁïåÈù¢ÈÖçÁΩÆÔºàÊé®ËçêÔºâ\nÁÇπÂáªÁïåÈù¢Âè≥‰∏äËßíÁöÑ\"‚öôÔ∏èËÆæÁΩÆ\"ÊåâÈíÆ\nÈÄâÊã©\"Ê®°ÂûãÁÆ°ÁêÜ\"ÈÄâÈ°πÂç°\nÁÇπÂáªÈúÄË¶ÅÈÖçÁΩÆÁöÑÊ®°ÂûãÔºàÂ¶ÇOpenAI„ÄÅGemini„ÄÅDeepSeekÁ≠âÔºâ\nÂú®ÂºπÂá∫ÁöÑÈÖçÁΩÆÊ°Ü‰∏≠ËæìÂÖ•ÂØπÂ∫îÁöÑAPIÂØÜÈí•\nÁÇπÂáª\"‰øùÂ≠ò\"Âç≥ÂèØ\nÊîØÊåÅÁöÑÊ®°ÂûãÔºöOpenAI„ÄÅGemini„ÄÅDeepSeek„ÄÅZhipuÊô∫Ë∞±„ÄÅSiliconFlow„ÄÅËá™ÂÆö‰πâAPIÔºàOpenAIÂÖºÂÆπÊé•Âè£Ôºâ\nÈô§‰∫ÜAPIÂØÜÈí•ÔºåÊÇ®ËøòÂèØ‰ª•Âú®Ê®°ÂûãÈÖçÁΩÆÁïåÈù¢‰∏∫ÊØè‰∏™Ê®°ÂûãÂçïÁã¨ËÆæÁΩÆÈ´òÁ∫ßLLMÂèÇÊï∞„ÄÇËøô‰∫õÂèÇÊï∞ÈÄöËøá‰∏Ä‰∏™Âêç‰∏∫\nllmParams\nÁöÑÂ≠óÊÆµËøõË°åÈÖçÁΩÆÔºåÂÆÉÂÖÅËÆ∏ÊÇ®‰ª•ÈîÆÂÄºÂØπÁöÑÂΩ¢ÂºèÊåáÂÆöLLM SDKÊîØÊåÅÁöÑ‰ªª‰ΩïÂèÇÊï∞Ôºå‰ªéËÄåÊõ¥Á≤æÁªÜÂú∞ÊéßÂà∂Ê®°ÂûãË°å‰∏∫„ÄÇ\nÈ´òÁ∫ßLLMÂèÇÊï∞ÈÖçÁΩÆÁ§∫‰æãÔºö\nOpenAI/ÂÖºÂÆπAPI\n:\n{\"temperature\": 0.7, \"max_tokens\": 4096, \"timeout\": 60000}\nGemini\n:\n{\"temperature\": 0.8, \"maxOutputTokens\": 2048, \"topP\": 0.95}\nDeepSeek\n:\n{\"temperature\": 0.5, \"top_p\": 0.9, \"frequency_penalty\": 0.1}\nÊúâÂÖ≥\nllmParams\nÁöÑÊõ¥ËØ¶ÁªÜËØ¥ÊòéÂíåÈÖçÁΩÆÊåáÂçóÔºåËØ∑ÂèÇÈòÖ\nLLMÂèÇÊï∞ÈÖçÁΩÆÊåáÂçó\n„ÄÇ\nÊñπÂºè‰∫åÔºöÈÄöËøáÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ\nDockerÈÉ®ÁΩ≤Êó∂ÈÄöËøá\n-e\nÂèÇÊï∞ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáèÔºö\n-e VITE_OPENAI_API_KEY=your_key\n-e VITE_GEMINI_API_KEY=your_key\n-e VITE_DEEPSEEK_API_KEY=your_key\n-e VITE_ZHIPU_API_KEY=your_key\n-e VITE_SILICONFLOW_API_KEY=your_key\n#\nÂ§öËá™ÂÆö‰πâÊ®°ÂûãÈÖçÁΩÆÔºàÊîØÊåÅÊó†ÈôêÊï∞ÈáèÔºâ\n-e VITE_CUSTOM_API_KEY_ollama=dummy_key\n-e VITE_CUSTOM_API_BASE_URL_ollama=http://localhost:11434/v1\n-e VITE_CUSTOM_API_MODEL_ollama=qwen2.5:7b\nüìñ\nËØ¶ÁªÜÈÖçÁΩÆÊåáÂçó\n: Êü•Áúã\nÂ§öËá™ÂÆö‰πâÊ®°ÂûãÈÖçÁΩÆÊñáÊ°£\n‰∫ÜËß£ÂÆåÊï¥ÁöÑÈÖçÁΩÆÊñπÊ≥ïÂíåÈ´òÁ∫ßÁî®Ê≥ï\nÊú¨Âú∞ÂºÄÂèë\nËØ¶ÁªÜÊñáÊ°£ÂèØÊü•Áúã\nÂºÄÂèëÊñáÊ°£\nÁÇπÂáªÊü•ÁúãÊú¨Âú∞ÂºÄÂèëÂëΩ‰ª§\n#\n1. ÂÖãÈöÜÈ°πÁõÆ\ngit clone https://github.com/linshenkx/prompt-optimizer.git\ncd\nprompt-optimizer\n#\n2. ÂÆâË£Ö‰æùËµñ\npnpm install\n#\n3. ÂêØÂä®ÂºÄÂèëÊúçÂä°\npnpm dev\n#\n‰∏ªÂºÄÂèëÂëΩ‰ª§ÔºöÊûÑÂª∫core/uiÂπ∂ËøêË°åwebÂ∫îÁî®\npnpm dev:web\n#\n‰ªÖËøêË°åwebÂ∫îÁî®\npnpm dev:fresh\n#\nÂÆåÊï¥ÈáçÁΩÆÂπ∂ÈáçÊñ∞ÂêØÂä®ÂºÄÂèëÁéØÂ¢É\nüó∫Ô∏è ÂºÄÂèëË∑ØÁ∫ø\nÂü∫Á°ÄÂäüËÉΩÂºÄÂèë\nWebÂ∫îÁî®ÂèëÂ∏É\nChromeÊèí‰ª∂ÂèëÂ∏É\nÂõΩÈôÖÂåñÊîØÊåÅ\nÊîØÊåÅÁ≥ªÁªüÊèêÁ§∫ËØç‰ºòÂåñÂíåÁî®Êà∑ÊèêÁ§∫ËØç‰ºòÂåñ\nÊ°åÈù¢Â∫îÁî®ÂèëÂ∏É\nMCPÊúçÂä°ÂèëÂ∏É\nÈ´òÁ∫ßÊ®°ÂºèÔºöÂèòÈáèÁÆ°ÁêÜ„ÄÅ‰∏ä‰∏ãÊñáÊµãËØï„ÄÅÂ∑•ÂÖ∑Ë∞ÉÁî®\nÂõæÂÉèÁîüÊàêÔºöÊñáÁîüÂõæÔºàT2IÔºâÂíåÂõæÁîüÂõæÔºàI2IÔºâÊîØÊåÅ\nÊîØÊåÅÂ∑•‰ΩúÂå∫/È°πÁõÆÁÆ°ÁêÜ\nÊîØÊåÅÊèêÁ§∫ËØçÊî∂ËóèÂíåÊ®°ÊùøÁÆ°ÁêÜ\nËØ¶ÁªÜÁöÑÈ°πÁõÆÁä∂ÊÄÅÂèØÊü•Áúã\nÈ°πÁõÆÁä∂ÊÄÅÊñáÊ°£\nüìñ Áõ∏ÂÖ≥ÊñáÊ°£\nÊñáÊ°£Á¥¢Âºï\n- ÊâÄÊúâÊñáÊ°£ÁöÑÁ¥¢Âºï\nÊäÄÊúØÂºÄÂèëÊåáÂçó\n- ÊäÄÊúØÊ†àÂíåÂºÄÂèëËßÑËåÉ\nLLMÂèÇÊï∞ÈÖçÁΩÆÊåáÂçó\n- È´òÁ∫ßLLMÂèÇÊï∞ÈÖçÁΩÆËØ¶ÁªÜËØ¥Êòé\nÈ°πÁõÆÁªìÊûÑ\n- ËØ¶ÁªÜÁöÑÈ°πÁõÆÁªìÊûÑËØ¥Êòé\nÈ°πÁõÆÁä∂ÊÄÅ\n- ÂΩìÂâçËøõÂ∫¶ÂíåËÆ°Âàí\n‰∫ßÂìÅÈúÄÊ±Ç\n- ‰∫ßÂìÅÈúÄÊ±ÇÊñáÊ°£\nVercelÈÉ®ÁΩ≤ÊåáÂçó\n- VercelÈÉ®ÁΩ≤ËØ¶ÁªÜËØ¥Êòé\nStar History\nÂ∏∏ËßÅÈóÆÈ¢ò\nÁÇπÂáªÊü•ÁúãÂ∏∏ËßÅÈóÆÈ¢òËß£Á≠î\nAPIËøûÊé•ÈóÆÈ¢ò\nQ1: ‰∏∫‰ªÄ‰πàÈÖçÁΩÆÂ•ΩAPIÂØÜÈí•Âêé‰ªçÁÑ∂Êó†Ê≥ïËøûÊé•Âà∞Ê®°ÂûãÊúçÂä°Ôºü\nA\n: Â§ßÂ§öÊï∞ËøûÊé•Â§±Ë¥•ÊòØÁî±\nË∑®ÂüüÈóÆÈ¢ò\nÔºàCORSÔºâÂØºËá¥ÁöÑ„ÄÇÁî±‰∫éÊú¨È°πÁõÆÊòØÁ∫ØÂâçÁ´ØÂ∫îÁî®ÔºåÊµèËßàÂô®Âá∫‰∫éÂÆâÂÖ®ËÄÉËôë‰ºöÈòªÊ≠¢Áõ¥Êé•ËÆøÈóÆ‰∏çÂêåÊ∫êÁöÑAPIÊúçÂä°„ÄÇÊ®°ÂûãÊúçÂä°Â¶ÇÊú™Ê≠£Á°ÆÈÖçÁΩÆCORSÁ≠ñÁï•Ôºå‰ºöÊãíÁªùÊù•Ëá™ÊµèËßàÂô®ÁöÑÁõ¥Êé•ËØ∑Ê±Ç„ÄÇ\nQ2: Â¶Ç‰ΩïËß£ÂÜ≥Êú¨Âú∞OllamaÁöÑËøûÊé•ÈóÆÈ¢òÔºü\nA\n: OllamaÂÆåÂÖ®ÊîØÊåÅOpenAIÊ†áÂáÜÊé•Âè£ÔºåÂè™ÈúÄÈÖçÁΩÆÊ≠£Á°ÆÁöÑË∑®ÂüüÁ≠ñÁï•Ôºö\nËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè\nOLLAMA_ORIGINS=*\nÂÖÅËÆ∏‰ªªÊÑèÊù•Ê∫êÁöÑËØ∑Ê±Ç\nÂ¶Ç‰ªçÊúâÈóÆÈ¢òÔºåËÆæÁΩÆ\nOLLAMA_HOST=0.0.0.0:11434\nÁõëÂê¨‰ªªÊÑèIPÂú∞ÂùÄ\nQ3: Â¶Ç‰ΩïËß£ÂÜ≥ÂïÜ‰∏öAPIÔºàÂ¶ÇNvidiaÁöÑDS API„ÄÅÂ≠óËäÇË∑≥Âä®ÁöÑÁÅ´Â±±APIÔºâÁöÑË∑®ÂüüÈóÆÈ¢òÔºü\nA\n: Ëøô‰∫õÂπ≥Âè∞ÈÄöÂ∏∏Êúâ‰∏•Ê†ºÁöÑË∑®ÂüüÈôêÂà∂ÔºåÊé®Ëçê‰ª•‰∏ãËß£ÂÜ≥ÊñπÊ°àÔºö\n‰ΩøÁî®Ê°åÈù¢ÁâàÂ∫îÁî®\nÔºàÊúÄÊé®ËçêÔºâ\nÊ°åÈù¢Â∫îÁî®‰Ωú‰∏∫ÂéüÁîüÂ∫îÁî®ÔºåÂÆåÂÖ®Ê≤°ÊúâË∑®ÂüüÈôêÂà∂\nÂèØ‰ª•Áõ¥Êé•ËøûÊé•‰ªª‰ΩïAPIÊúçÂä°ÔºåÂåÖÊã¨Êú¨Âú∞ÈÉ®ÁΩ≤ÁöÑÊ®°Âûã\nÊèê‰æõÊúÄÂÆåÊï¥„ÄÅÊúÄÁ®≥ÂÆöÁöÑÂäüËÉΩ‰ΩìÈ™å\n‰ªé\nGitHub Releases\n‰∏ãËΩΩ\n‰ΩøÁî®Ëá™ÈÉ®ÁΩ≤ÁöÑAPI‰∏≠ËΩ¨ÊúçÂä°\nÔºà‰∏ì‰∏öÊñπÊ°àÔºâ\nÈÉ®ÁΩ≤Â¶ÇOneAPI„ÄÅNewAPIÁ≠âÂºÄÊ∫êAPIËÅöÂêà/‰ª£ÁêÜÂ∑•ÂÖ∑\nÂú®ËÆæÁΩÆ‰∏≠ÈÖçÁΩÆ‰∏∫Ëá™ÂÆö‰πâAPIÁ´ØÁÇπ\nËØ∑Ê±ÇÊµÅÂêëÔºöÊµèËßàÂô®‚Üí‰∏≠ËΩ¨ÊúçÂä°‚ÜíÊ®°ÂûãÊúçÂä°Êèê‰æõÂïÜ\nÂÆåÂÖ®ÊéßÂà∂ÂÆâÂÖ®Á≠ñÁï•ÂíåËÆøÈóÆÊùÉÈôê\nÊ≥®ÊÑè\nÔºöWebÁâàÔºàÂåÖÊã¨Âú®Á∫øÁâà„ÄÅVercelÈÉ®ÁΩ≤„ÄÅDockerÈÉ®ÁΩ≤ÔºâÈÉΩÊòØÁ∫ØÂâçÁ´ØÂ∫îÁî®ÔºåÈÉΩ‰ºöÂèóÂà∞ÊµèËßàÂô®CORSÈôêÂà∂„ÄÇÂè™ÊúâÊ°åÈù¢ÁâàÊàñ‰ΩøÁî®API‰∏≠ËΩ¨ÊúçÂä°ÊâçËÉΩËß£ÂÜ≥Ë∑®ÂüüÈóÆÈ¢ò„ÄÇ\nQ4: ÊàëÂ∑≤Ê≠£Á°ÆÈÖçÁΩÆÊú¨Âú∞Ê®°ÂûãÔºàÂ¶ÇOllamaÔºâÁöÑË∑®ÂüüÁ≠ñÁï•Ôºå‰∏∫‰ªÄ‰πà‰ΩøÁî®Âú®Á∫øÁâà‰æùÁÑ∂Êó†Ê≥ïËøûÊé•Ôºü\nA\n: ËøôÊòØÁî±ÊµèËßàÂô®ÁöÑ\nÊ∑∑ÂêàÂÜÖÂÆπÔºàMixed ContentÔºâÂÆâÂÖ®Á≠ñÁï•\nÂØºËá¥ÁöÑ„ÄÇÂá∫‰∫éÂÆâÂÖ®ËÄÉËôëÔºåÊµèËßàÂô®‰ºöÈòªÊ≠¢ÂÆâÂÖ®ÁöÑHTTPSÈ°µÈù¢ÔºàÂ¶ÇÂú®Á∫øÁâàÔºâÂêë‰∏çÂÆâÂÖ®ÁöÑHTTPÂú∞ÂùÄÔºàÂ¶ÇÊÇ®ÁöÑÊú¨Âú∞OllamaÊúçÂä°ÔºâÂèëÈÄÅËØ∑Ê±Ç„ÄÇ\nËß£ÂÜ≥ÊñπÊ°à\nÔºö\n‰∏∫‰∫ÜÁªïËøáÊ≠§ÈôêÂà∂ÔºåÊÇ®ÈúÄË¶ÅËÆ©Â∫îÁî®ÂíåAPIÂ§Ñ‰∫éÂêå‰∏ÄÁßçÂçèËÆÆ‰∏ãÔºà‰æãÂ¶ÇÔºåÈÉΩÊòØHTTPÔºâ„ÄÇÊé®Ëçê‰ª•‰∏ãÊñπÂºèÔºö\n‰ΩøÁî®Ê°åÈù¢Áâà\nÔºöÊ°åÈù¢Â∫îÁî®Ê≤°ÊúâÊµèËßàÂô®ÈôêÂà∂ÔºåÊòØËøûÊé•Êú¨Âú∞Ê®°ÂûãÊúÄÁ®≥ÂÆöÂèØÈù†ÁöÑÊñπÂºè\n‰ΩøÁî®DockerÈÉ®ÁΩ≤ÔºàHTTPÔºâ\nÔºöÈÄöËøá\nhttp://localhost:8081\nËÆøÈóÆÔºå‰∏éÊú¨Âú∞OllamaÈÉΩÊòØHTTP\n‰ΩøÁî®ChromeÊèí‰ª∂\nÔºöÊèí‰ª∂Âú®Êüê‰∫õÊÉÖÂÜµ‰∏ã‰πüÂèØ‰ª•ÁªïËøáÈÉ®ÂàÜÂÆâÂÖ®ÈôêÂà∂\nü§ù ÂèÇ‰∏éË¥°ÁåÆ\nÁÇπÂáªÊü•ÁúãË¥°ÁåÆÊåáÂçó\nFork Êú¨‰ªìÂ∫ì\nÂàõÂª∫ÁâπÊÄßÂàÜÊîØ (\ngit checkout -b feature/AmazingFeature\n)\nÊèê‰∫§Êõ¥Êîπ (\ngit commit -m 'Ê∑ªÂä†Êüê‰∏™ÁâπÊÄß'\n)\nÊé®ÈÄÅÂà∞ÂàÜÊîØ (\ngit push origin feature/AmazingFeature\n)\nÊèê‰∫§ Pull Request\nÊèêÁ§∫Ôºö‰ΩøÁî®cursorÂ∑•ÂÖ∑ÂºÄÂèëÊó∂ÔºåÂª∫ËÆÆÂú®Êèê‰∫§Ââç:\n‰ΩøÁî®\"code_review\"ËßÑÂàôËøõË°å‰ª£Á†ÅÂÆ°Êü•\nÊåâÁÖßÂÆ°Êü•Êä•ÂëäÊ†ºÂºèÊ£ÄÊü•:\nÂèòÊõ¥ÁöÑÊï¥‰Ωì‰∏ÄËá¥ÊÄß\n‰ª£Á†ÅË¥®ÈáèÂíåÂÆûÁé∞ÊñπÂºè\nÊµãËØïË¶ÜÁõñÊÉÖÂÜµ\nÊñáÊ°£ÂÆåÂñÑÁ®ãÂ∫¶\nÊ†πÊçÆÂÆ°Êü•ÁªìÊûúËøõË°å‰ºòÂåñÂêéÂÜçÊèê‰∫§\nüëè Ë¥°ÁåÆËÄÖÂêçÂçï\nÊÑüË∞¢ÊâÄÊúâ‰∏∫È°πÁõÆÂÅöÂá∫Ë¥°ÁåÆÁöÑÂºÄÂèëËÄÖÔºÅ\nüìÑ ÂºÄÊ∫êÂçèËÆÆ\nÊú¨È°πÁõÆÈááÁî®\nMIT\nÂçèËÆÆÂºÄÊ∫ê„ÄÇ\nÂ¶ÇÊûúËøô‰∏™È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåËØ∑ËÄÉËôëÁªôÂÆÉ‰∏Ä‰∏™ Star ‚≠êÔ∏è\nüë• ËÅîÁ≥ªÊàë‰ª¨\nÊèê‰∫§ Issue\nÂèëËµ∑ Pull Request\nÂä†ÂÖ•ËÆ®ËÆ∫ÁªÑ",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 36",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 15,876"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/linshenkx/prompt-optimizer"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/keycloak/keycloak",
      "title": "keycloak/keycloak",
      "date": null,
      "executive_summary": [
        "Open Source Identity and Access Management For Modern Applications and Services",
        "---",
        "Open Source Identity and Access Management\nAdd authentication to applications and secure services with minimum effort. No need to deal with storing users or authenticating users.\nKeycloak provides user federation, strong authentication, user management, fine-grained authorization, and more.\nHelp and Documentation\nDocumentation\nUser Mailing List\n- Mailing list for help and general questions about Keycloak\nJoin\n#keycloak\nfor general questions, or\n#keycloak-dev\non Slack for design and development discussions, by creating an account at\nhttps://slack.cncf.io/\n.\nReporting Security Vulnerabilities\nIf you have found a security vulnerability, please look at the\ninstructions on how to properly report it\n.\nReporting an issue\nIf you believe you have discovered a defect in Keycloak, please open\nan issue\n.\nPlease remember to provide a good summary, description as well as steps to reproduce the issue.\nGetting started\nTo run Keycloak, download the distribution from our\nwebsite\n. Unzip and run:\nbin/kc.[sh|bat] start-dev\nAlternatively, you can use the Docker image by running:\ndocker run quay.io/keycloak/keycloak start-dev\nFor more details refer to the\nKeycloak Documentation\n.\nBuilding from Source\nTo build from source, refer to the\nbuilding and working with the code base\nguide.\nTesting\nTo run tests, refer to the\nrunning tests\nguide.\nWriting Tests\nTo write tests, refer to the\nwriting tests\nguide.\nContributing\nBefore contributing to Keycloak, please read our\ncontributing guidelines\n. Participation in the Keycloak project is governed by the\nCNCF Code of Conduct\n.\nJoining a\ncommunity meeting\nis a great way to get involved and help shape the future of Keycloak.\nOther Keycloak Projects\nKeycloak\n- Keycloak Server and Java adapters\nKeycloak QuickStarts\n- QuickStarts for getting started with Keycloak\nKeycloak Node.js Connect\n- Node.js adapter for Keycloak\nLicense\nApache License, Version 2.0",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 34",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 30,042"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/keycloak/keycloak"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/qaiu/netdisk-fast-download",
      "title": "qaiu/netdisk-fast-download",
      "date": null,
      "executive_summary": [
        "ÂêÑÁ±ªÁΩëÁõòÁõ¥ÈìæËß£ÊûêÊúçÂä°, Â∑≤ÊîØÊåÅËìùÂ•è‰∫ë/ËìùÂ•è‰ºò‰∫´/Â∞èÈ£ûÊú∫Áõò/123‰∫ëÁõò/ÁßªÂä®ËÅîÈÄö/Â§©Áøº‰∫ëÁ≠â. ÊîØÊåÅÊñá‰ª∂Â§πÂàÜ‰∫´Ëß£Êûê. ‰ΩìÈ™åÂú∞ÂùÄ: https://lz.qaiu.top http://www.722shop.top:6401",
        "---",
        "netdisk-fast-download ÁΩëÁõòÂàÜ‰∫´ÈìæÊé•‰∫ëËß£ÊûêÊúçÂä°\nQQÁæ§Ôºö1017480890\nnetdisk-fast-downloadÁΩëÁõòÁõ¥Èìæ‰∫ëËß£Êûê(nfd‰∫ëËß£Êûê)ËÉΩÊääÁΩëÁõòÂàÜ‰∫´‰∏ãËΩΩÈìæÊé•ËΩ¨Âåñ‰∏∫Áõ¥ÈìæÔºåÊîØÊåÅÂ§öÊ¨æ‰∫ëÁõòÔºåÂ∑≤ÊîØÊåÅËìùÂ•è‰∫ë/ËìùÂ•è‰∫ë‰ºò‰∫´/Â•∂ÁâõÂø´‰º†/ÁßªÂä®‰∫ë‰∫ëÁ©∫Èó¥/Â∞èÈ£ûÊú∫Áõò/‰∫øÊñπ‰∫ë/123‰∫ëÁõò/CloudreveÁ≠âÔºåÊîØÊåÅÂä†ÂØÜÂàÜ‰∫´Ôºå‰ª•ÂèäÈÉ®ÂàÜÁΩëÁõòÊñá‰ª∂Â§πÂàÜ‰∫´„ÄÇ\nÂø´ÈÄüÂºÄÂßã\nÂëΩ‰ª§Ë°å‰∏ãËΩΩÂàÜ‰∫´Êñá‰ª∂Ôºö\ncurl -LOJ\n\"\nhttps://lz.qaiu.top/parser?url=https://share.feijipan.com/s/nQOaNRPW&pwd=1234\n\"\nÊàñËÄÖ‰ΩøÁî®wget:\nwget -O bilibili.mp4\n\"\nhttps://lz.qaiu.top/parser?url=https://share.feijipan.com/s/nQOaNRPW&pwd=1234\n\"\nÊàñËÄÖ‰ΩøÁî®ÊµèËßàÂô®\nÁõ¥Êé•ËÆøÈóÆ\n:\n### Ë∞ÉÁî®ÊºîÁ§∫Á´ô‰∏ãËΩΩÔºö\nhttps://lz.qaiu.top/parser?url=https://share.feijipan.com/s/nQOaNRPW&pwd=1234  \n### Ë∞ÉÁî®ÊºîÁ§∫Á´ôÈ¢ÑËßàÔºö\nhttps://nfd-parser.github.io/nfd-preview/preview.html?src=https%3A%2F%2Flz.qaiu.top%2Fparser%3Furl%3Dhttps%3A%2F%2Fshare.feijipan.com%2Fs%2FnQOaNRPW&name=bilibili.mp4&ext=mp4\nÈ¢ÑËßàÂú∞ÂùÄ\nÈ¢ÑËßàÂú∞ÂùÄ1\nÈ¢ÑËßàÂú∞ÂùÄ2\nÂ§©Áøº‰∫ëÁõòÂ§ßÊñá‰ª∂Ëß£ÊûêÈôêÊó∂ÂºÄÊîæ\nmainÂàÜÊîØ‰æùËµñJDK17, Êèê‰æõ‰∫ÜJDK11ÂàÜÊîØ\nmain-jdk11\n0.1.8Âèä‰ª•‰∏äÁâàÊú¨jsonÊé•Âè£Ê†ºÂºèÊúâË∞ÉÊï¥ ÂèÇËÄÉjsonËøîÂõûÊï∞ÊçÆÊ†ºÂºèÁ§∫‰æã\nÂ∞èÈ£ûÊú∫Ëß£ÊûêÊúâIPÈôêÂà∂ÔºåÂ§öÊï∞‰∫ëÊúçÂä°ÂïÜÁöÑÂ§ßÈôÜIP‰ºöË¢´Êã¶Êà™ÔºàÂèØ‰ª•Ëá™Ë°åÈÖçÁΩÆ‰ª£ÁêÜÔºâÔºåÂíåÊú¨Á®ãÂ∫èÊó†ÂÖ≥\nÊ≥®ÊÑè: ËØ∑‰∏çË¶ÅËøáÂ∫¶‰æùËµñlz.qaiu.topÈ¢ÑËßàÂú∞ÂùÄÊúçÂä°ÔºåÂª∫ËÆÆÊú¨Âú∞Êê≠Âª∫ÊàñËÄÖ‰∫ëÊúçÂä°Âô®Ëá™Ë°åÊê≠Âª∫„ÄÇËß£ÊûêÊ¨°Êï∞ËøáÂ§öIP‰ºöË¢´ÈÉ®ÂàÜÁΩëÁõòÂéÇÂïÜÈôêÂà∂Ôºå‰∏çÊé®ËçêÂÅöÂÖ¨ÂÖ±Ëß£Êûê„ÄÇ\nÁΩëÁõòÊîØÊåÅÊÉÖÂÜµ:\n20230905 Â•∂Áâõ‰∫ëÁõ¥ÈìæÂÅö‰∫ÜÈò≤ÁõóÈìæÔºåÈúÄÂä†ÂÖ•ËØ∑Ê±ÇÂ§¥ÔºöReferer:\nhttps://cowtransfer.com/\n20230824 123‰∫ëÁõòËß£ÊûêÂ§ßÊñá‰ª∂(>100MB)Â§±ÊïàÔºåÈúÄË¶ÅÁôªÂΩï\n20230722 UCÁΩëÁõòËß£ÊûêÂ§±ÊïàÔºåÈúÄË¶ÅÁôªÂΩï\nÁΩëÁõòÂêçÁß∞-ÁΩëÁõòÊ†áËØÜ:\nËìùÂ•è‰∫ë-lz\nËìùÂ•è‰∫ë‰ºò‰∫´-iz\nÂ•∂ÁâõÂø´‰º†-cow\nÁßªÂä®‰∫ë‰∫ëÁ©∫Èó¥-ec\nÂ∞èÈ£ûÊú∫ÁΩëÁõò-fj\n‰∫øÊñπ‰∫ë-fc\n123‰∫ëÁõò-ye\n115ÁΩëÁõò(Â§±Êïà)-p115\n118ÁΩëÁõò(Â∑≤ÂÅúÊúç)-p118\nÊñáÂèîÂèî-ws\nËÅîÊÉ≥‰πê‰∫ë-le\nQQÈÇÆÁÆ±‰∫ëÁõò-qqw\nQQÈó™‰º†-qqsc\nÂüéÈÄöÁΩëÁõò-ct\nÁΩëÊòì‰∫ëÈü≥‰πêÂàÜ‰∫´ÈìæÊé•-mnes\nÈÖ∑ÁãóÈü≥‰πêÂàÜ‰∫´ÈìæÊé•-mkgs\nÈÖ∑ÊàëÈü≥‰πêÂàÜ‰∫´ÈìæÊé•-mkws\nQQÈü≥‰πêÂàÜ‰∫´ÈìæÊé•-mqqs\nÂí™ÂíïÈü≥‰πêÂàÜ‰∫´ÈìæÊé•(ÂºÄÂèë‰∏≠)\nCloudreveËá™Âª∫ÁΩëÁõò-ce\nÂæÆÈõ®‰∫ëÂ≠òÂÇ®-pvvy\nË∂ÖÊòü‰∫ëÁõò(ÈúÄË¶Åreferer: https://pan-yz.chaoxing.com)-pcx\nGoogle‰∫ëÁõò-pgd\nOnedrive-pod\nDropbox-pdp\niCloud-pic\n‰ªÖ‰∏ìÂ±ûÁâàÊèê‰æõ\nÁßªÂä®‰∫ëÁõò-p139\nËÅîÈÄö‰∫ëÁõò-pwo\nÂ§©Áøº‰∫ëÁõò-p189\nAPIÊé•Âè£ËØ¥Êòé\nyour_hostÊåáÁöÑÊòØÊÇ®ÁöÑÂüüÂêçÊàñËÄÖIPÔºåÂÆûÈôÖ‰ΩøÁî®Êó∂ÊõøÊç¢‰∏∫ÂÆûÈôÖÂüüÂêçÊàñËÄÖIPÔºåÁ´ØÂè£ÈªòËÆ§6400ÔºåÂèØ‰ª•‰ΩøÁî®nginx‰ª£ÁêÜÊù•ÂÅöÂüüÂêçËÆøÈóÆ„ÄÇ\nËß£ÊûêÊñπÂºèÂàÜ‰∏∫‰∏§ÁßçÁ±ªÂûãÁõ¥Êé•Ë∑≥ËΩ¨‰∏ãËΩΩÊñá‰ª∂ÂíåËé∑Âèñ‰∏ãËΩΩÈìæÊé•,\nÊØè‰∏ÄÁßçÈÉΩÊèê‰æõ‰∫Ü‰∏§ÁßçÊé•Âè£ÂΩ¢Âºè:\nÈÄöÁî®Êé•Âè£parser?url=\nÂíå\nÁΩëÁõòÊ†áÂøó/ÂàÜ‰∫´keyÊãºÊé•ÁöÑÁü≠Âú∞ÂùÄÔºàÊ†áÂøóÁü≠ÈìæÔºâ\nÔºåÊâÄÊúâËßÑÂàôÂèÇËÄÉÁ§∫‰æã„ÄÇ\nÈÄöÁî®Êé•Âè£:\n/parser?url=ÂàÜ‰∫´ÈìæÊé•&pwd=ÂØÜÁ†Å\nÊ≤°ÊúâÂàÜ‰∫´ÂØÜÁ†ÅÂéªÊéâ&pwdÂèÇÊï∞;\nÊ†áÂøóÁü≠Èìæ:\n/d/ÁΩëÁõòÊ†áËØÜ/ÂàÜ‰∫´key@ÂØÜÁ†Å\nÊ≤°ÊúâÂàÜ‰∫´ÂØÜÁ†ÅÂéªÊéâ@ÂØÜÁ†Å;\nÁõ¥ÈìæJSON:\n/json/ÁΩëÁõòÊ†áËØÜ/ÂàÜ‰∫´key@ÂØÜÁ†Å\nÂíå\n/json/parser?url=ÂàÜ‰∫´ÈìæÊé•&pwd=ÂØÜÁ†Å\nÁΩëÁõòÊ†áËØÜÂèÇËÄÉ‰∏äÈù¢ÁΩëÁõòÊîØÊåÅÊÉÖÂÜµ\nÂΩìÂ∏¶ÊúâÂàÜ‰∫´ÂØÜÁ†ÅÊó∂ÈúÄË¶ÅÂä†‰∏äÂØÜÁ†ÅÂèÇÊï∞(pwd)\nÁßªÂä®‰∫ë‰∫ëÁ©∫Èó¥,Â∞èÈ£ûÊú∫ÁΩëÁõòÁöÑÂä†ÂØÜÂàÜ‰∫´ÁöÑÂØÜÁ†ÅÂèØ‰ª•ÂøΩÁï•\nÁßªÂä®‰∫ëÁ©∫Èó¥ÂàÜ‰∫´keyÂèñÂàÜ‰∫´ÈìæÊé•‰∏≠ÁöÑdataÂèÇÊï∞,ÊØîÂ¶Ç\n&data=xxx\nÁöÑÂèÇÊï∞Â∞±ÊòØxxx\nAPIËßÑÂàô:\nÂª∫ËÆÆ‰ΩøÁî®UrlEncodeÁºñÁ†ÅÂàÜ‰∫´ÈìæÊé•\nËß£ÊûêÂπ∂Ëá™Âä®302Ë∑≥ËΩ¨\nhttp://your_host/parser?url=ÂàÜ‰∫´ÈìæÊé•&pwd=xxx\nhttp://your_host/parser?url=UrlEncode(ÂàÜ‰∫´ÈìæÊé•)&pwd=xxx\nhttp://your_host/d/ÁΩëÁõòÊ†áËØÜ/ÂàÜ‰∫´key@ÂàÜ‰∫´ÂØÜÁ†Å\nËé∑ÂèñËß£ÊûêÂêéÁöÑÁõ¥Èìæ--JSONÊ†ºÂºè\nhttp://your_host/json/parser?url=ÂàÜ‰∫´ÈìæÊé•&pwd=xxx\nhttp://your_host/json/ÁΩëÁõòÊ†áËØÜ/ÂàÜ‰∫´key@ÂàÜ‰∫´ÂØÜÁ†Å\nÊñá‰ª∂Â§πËß£Êûêv0.1.8fixed3Êñ∞Â¢û\nhttp://your_host/json/getFileList?url=ÂàÜ‰∫´ÈìæÊé•&pwd=xxx\njsonÊé•Âè£ËØ¥Êòé\n1. Êñá‰ª∂Ëß£ÊûêÔºö/json/parser?url=ÂàÜ‰∫´ÈìæÊé•&pwd=xxx\njsonËøîÂõûÊï∞ÊçÆÊ†ºÂºèÁ§∫‰æã:\nshareKey\n:    ÂÖ®Â±ÄÂàÜ‰∫´key\ndirectLink\n:  ‰∏ãËΩΩÈìæÊé•\ncacheHit\n:    ÊòØÂê¶‰∏∫ÁºìÂ≠òÈìæÊé•\nexpires\n:     ÁºìÂ≠òÂà∞ÊúüÊó∂Èó¥\n{\n\"code\"\n:\n200\n,\n\"msg\"\n:\n\"\nsuccess\n\"\n,\n\"success\"\n:\ntrue\n,\n\"count\"\n:\n0\n,\n\"data\"\n: {\n\"shareKey\"\n:\n\"\nlz:xxx\n\"\n,\n\"directLink\"\n:\n\"\n‰∏ãËΩΩÁõ¥Èìæ\n\"\n,\n\"cacheHit\"\n:\ntrue\n,\n\"expires\"\n:\n\"\n2024-09-18 01:48:02\n\"\n,\n\"expiration\"\n:\n1726638482825\n},\n\"timestamp\"\n:\n1726637151902\n}\n2. ÂàÜ‰∫´ÈìæÊé•ËØ¶ÊÉÖÊé•Âè£ /v2/linkInfo?url=ÂàÜ‰∫´ÈìæÊé•\n{\n\"code\"\n:\n200\n,\n\"msg\"\n:\n\"\nsuccess\n\"\n,\n\"success\"\n:\ntrue\n,\n\"count\"\n:\n0\n,\n\"data\"\n: {\n\"downLink\"\n:\n\"\nhttps://lz.qaiu.top/d/fj/xx\n\"\n,\n\"apiLink\"\n:\n\"\nhttps://lz.qaiu.top/json/fj/xx\n\"\n,\n\"cacheHitTotal\"\n:\n5\n,\n\"parserTotal\"\n:\n2\n,\n\"sumTotal\"\n:\n7\n,\n\"shareLinkInfo\"\n: {\n\"shareKey\"\n:\n\"\nxx\n\"\n,\n\"panName\"\n:\n\"\nÂ∞èÈ£ûÊú∫ÁΩëÁõò\n\"\n,\n\"type\"\n:\n\"\nfj\n\"\n,\n\"sharePassword\"\n:\n\"\n\"\n,\n\"shareUrl\"\n:\n\"\nhttps://share.feijipan.com/s/xx\n\"\n,\n\"standardUrl\"\n:\n\"\nhttps://www.feijix.com/s/xx\n\"\n,\n\"otherParam\"\n: {\n\"UA\"\n:\n\"\nMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0\n\"\n},\n\"cacheKey\"\n:\n\"\nfj:xx\n\"\n}\n    },\n\"timestamp\"\n:\n1736489219402\n}\n3. Êñá‰ª∂Â§πËß£Êûê(‰ªÖÊîØÊåÅËìùÂ•è‰∫ë/ËìùÂ•è‰ºò‰∫´/Â∞èÈ£ûÊú∫ÁΩëÁõò)\n/v2/getFileList?url=ÂàÜ‰∫´ÈìæÊé•&pwd=ÂàÜ‰∫´ÂØÜÁ†Å\n{\n\"code\"\n:\n200\n,\n\"msg\"\n:\n\"\nsuccess\n\"\n,\n\"success\"\n:\ntrue\n,\n\"data\"\n: [\n    {\n\"fileName\"\n:\n\"\nxxx\n\"\n,\n\"fileId\"\n:\n\"\nxxx\n\"\n,\n\"fileIcon\"\n:\nnull\n,\n\"size\"\n:\n999\n,\n\"sizeStr\"\n:\n\"\n999 M\n\"\n,\n\"fileType\"\n:\n\"\nfile/folder\n\"\n,\n\"filePath\"\n:\nnull\n,\n\"createTime\"\n:\n\"\n17 Â∞èÊó∂Ââç\n\"\n,\n\"updateTime\"\n:\nnull\n,\n\"createBy\"\n:\nnull\n,\n\"description\"\n:\nnull\n,\n\"downloadCount\"\n:\n\"\n‰∏ãËΩΩÊ¨°Êï∞\n\"\n,\n\"panType\"\n:\n\"\nlz\n\"\n,\n\"parserUrl\"\n:\n\"\n‰∏ãËΩΩÈìæÊé•/Êñá‰ª∂Â§πÈìæÊé•\n\"\n,\n\"extParameters\"\n:\nnull\n}\n  ]\n}\n4. Ëß£ÊûêÊ¨°Êï∞ÁªüËÆ°Êé•Âè£ /v2/statisticsInfo\n{\n\"code\"\n:\n200\n,\n\"msg\"\n:\n\"\nsuccess\n\"\n,\n\"success\"\n:\ntrue\n,\n\"count\"\n:\n0\n,\n\"data\"\n: {\n\"parserTotal\"\n:\n320508\n,\n\"cacheTotal\"\n:\n5957910\n,\n\"total\"\n:\n6278418\n},\n\"timestamp\"\n:\n1736489378770\n}\nIDEA HttpClientÁ§∫‰æã:\n# Ëß£ÊûêÂπ∂ÈáçÂÆöÂêëÂà∞Áõ¥Èìæ\n### ËìùÂ•è‰∫ëÊôÆÈÄöÂàÜ‰∫´\n# @no-redirect\nGET http://127.0.0.1:6400/parser?url=https://lanzoux.com/ia2cntg\n### Â•∂ÁâõÂø´‰º†ÊôÆÈÄöÂàÜ‰∫´\n# @no-redirect\nGET http://127.0.0.1:6400/parser?url=https://cowtransfer.com/s/9a644fe3e3a748\n### 360‰∫øÊñπ‰∫ëÂä†ÂØÜÂàÜ‰∫´\n# @no-redirect\nGET http://127.0.0.1:6400/parser?url=https://v2.fangcloud.com/sharing/e5079007dc31226096628870c7&pwd=QAIU\n\n# RestËØ∑Ê±ÇËá™Âä®302Ë∑≥ËΩ¨(Âè™Êèê‰æõÂÖ±‰∫´Êñá‰ª∂Id):\n### ËìùÂ•è‰∫ëÊôÆÈÄöÂàÜ‰∫´\n# @no-redirect\nGET http://127.0.0.1:6400/lz/ia2cntg\n### Â•∂ÁâõÂø´‰º†ÊôÆÈÄöÂàÜ‰∫´\n# @no-redirect\nGET http://127.0.0.1:6400/cow/9a644fe3e3a748\n### 360‰∫øÊñπ‰∫ëÂä†ÂØÜÂàÜ‰∫´\nGET http://127.0.0.1:6400/json/fc/e5079007dc31226096628870c7@QAIU\n\n\n# Ëß£ÊûêËøîÂõûjsonÁõ¥Èìæ\n### ËìùÂ•è‰∫ëÊôÆÈÄöÂàÜ‰∫´\nGET http://127.0.0.1:6400/json/lz/ia2cntg\n### Â•∂ÁâõÂø´‰º†ÊôÆÈÄöÂàÜ‰∫´\nGET http://127.0.0.1:6400/json/cow/9a644fe3e3a748\n### 360‰∫øÊñπ‰∫ëÂä†ÂØÜÂàÜ‰∫´\nGET http://127.0.0.1:6400/json/fc/e5079007dc31226096628870c7@QAIU\nÁΩëÁõòÂØπÊØî\nÁΩëÁõòÂêçÁß∞\nÂÖçÁôªÈôÜ‰∏ãËΩΩÂàÜ‰∫´\nÂä†ÂØÜÂàÜ‰∫´\nÂàùÂßãÁΩëÁõòÁ©∫Èó¥\nÂçïÊñá‰ª∂Â§ßÂ∞èÈôêÂà∂\nËìùÂ•è‰∫ë\n‚àö\n‚àö\n‰∏çÈôêÁ©∫Èó¥\n100M\nÂ•∂ÁâõÂø´‰º†\n‚àö\nX\n10G\n‰∏çÈôêÂ§ßÂ∞è\nÁßªÂä®‰∫ë‰∫ëÁ©∫Èó¥(‰∏™‰∫∫Áâà)\n‚àö\n‚àö(ÂØÜÁ†ÅÂèØÂøΩÁï•)\n5G(‰∏™‰∫∫)\n‰∏çÈôêÂ§ßÂ∞è\nÂ∞èÈ£ûÊú∫ÁΩëÁõò\n‚àö\n‚àö(ÂØÜÁ†ÅÂèØÂøΩÁï•)\n10G\n‰∏çÈôêÂ§ßÂ∞è\n360‰∫øÊñπ‰∫ë\n‚àö\n‚àö(ÂØÜÁ†ÅÂèØÂøΩÁï•)\n100G(È°ªÂÆûÂêç)\n‰∏çÈôêÂ§ßÂ∞è\n123‰∫ëÁõò\n‚àö\n‚àö\n2T\n100GÔºà>100MÈúÄË¶ÅÁôªÂΩïÔºâ\nÊñáÂèîÂèî\n‚àö\n‚àö\n10G\n5GB\nÂ§∏ÂÖãÁΩëÁõò\nx\n‚àö\n10G\n‰∏çÈôêÂ§ßÂ∞è\nUCÁΩëÁõò\nx\n‚àö\n10G\n‰∏çÈôêÂ§ßÂ∞è\nÊâìÂåÖÈÉ®ÁΩ≤\nJDK‰∏ãËΩΩÔºàlz.qaiu.topÊèê‰æõÁõ¥Èìæ‰∫ëËß£ÊûêÊúçÂä°Ôºâ\nÈòøÈáåjdk17(Dragonwell17-windows-x86)\nÈòøÈáåjdk17(Dragonwell17-linux-x86)\nÈòøÈáåjdk17(Dragonwell17-linux-aarch64)\nËß£ÊûêÊúâÊïàÊÄßÊµãËØï-ÁßªÂä®‰∫ë‰∫ëÁ©∫Èó¥-ÈòøÈáåjdk17-linux-x86\nÂºÄÂèëÂíåÊâìÂåÖ\n#\nÁéØÂ¢ÉË¶ÅÊ±Ç: Jdk17 + maven;\nmvn clean\nmvn package\nÊâìÂåÖÂ•ΩÁöÑÊñá‰ª∂‰Ωç‰∫é web-service/target/netdisk-fast-download-bin.zip\nLinuxÊúçÂä°ÈÉ®ÁΩ≤\nDocker ÈÉ®ÁΩ≤ÔºàMainÂàÜÊîØÔºâ\nÊµ∑Â§ñÊúçÂä°Âô®DockerÈÉ®ÁΩ≤\n#\nÂàõÂª∫ÁõÆÂΩï\nmkdir -p netdisk-fast-download\ncd\nnetdisk-fast-download\n#\nÊãâÂèñÈïúÂÉè\ndocker pull ghcr.io/qaiu/netdisk-fast-download:latest\n#\nÂ§çÂà∂ÈÖçÁΩÆÊñá‰ª∂ÔºàÊàñ‰∏ãËΩΩ‰ªìÂ∫ìweb-service\\src\\main\\resourcesÔºâ\ndocker create --name netdisk-fast-download ghcr.io/qaiu/netdisk-fast-download:latest\ndocker cp netdisk-fast-download:/app/resources ./resources\ndocker rm netdisk-fast-download\n#\nÂêØÂä®ÂÆπÂô®\ndocker run -d -it --name netdisk-fast-download -p 6401:6401 --restart unless-stopped -e TZ=Asia/Shanghai -v ./resources:/app/resources -v ./db:/app/db -v ./logs:/app/logs ghcr.io/qaiu/netdisk-fast-download:latest\n#\nÂèç‰ª£6401Á´ØÂè£\n#\nÂçáÁ∫ßÂÆπÂô®\ndocker run --rm -v /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --cleanup --run-once netdisk-fast-download\nÂõΩÂÜÖDockerÈÉ®ÁΩ≤\n#\nÂàõÂª∫ÁõÆÂΩï\nmkdir -p netdisk-fast-download\ncd\nnetdisk-fast-download\n#\nÊãâÂèñÈïúÂÉè\ndocker pull ghcr.nju.edu.cn/qaiu/netdisk-fast-download:latest\n#\nÂ§çÂà∂ÈÖçÁΩÆÊñá‰ª∂ÔºàÊàñ‰∏ãËΩΩ‰ªìÂ∫ìweb-service\\src\\main\\resourcesÔºâ\ndocker create --name netdisk-fast-download ghcr.nju.edu.cn/qaiu/netdisk-fast-download:latest\ndocker cp netdisk-fast-download:/app/resources ./resources\ndocker rm netdisk-fast-download\n#\nÂêØÂä®ÂÆπÂô®\ndocker run -d -it --name netdisk-fast-download -p 6401:6401 --restart unless-stopped -e TZ=Asia/Shanghai -v ./resources:/app/resources -v ./db:/app/db -v ./logs:/app/logs ghcr.nju.edu.cn/qaiu/netdisk-fast-download:latest\n#\nÂèç‰ª£6401Á´ØÂè£\n#\nÂçáÁ∫ßÂÆπÂô®\ndocker run --rm -v /var/run/docker.sock:/var/run/docker.sock containrrr/watchtower --cleanup --run-once netdisk-fast-download\nÂÆùÂ°îÈÉ®ÁΩ≤ÊåáÂºï ->\nÁÇπÂáªËøõÂÖ•ÂÆùÂ°îÈÉ®ÁΩ≤ÊïôÁ®ã\nLinuxÂëΩ‰ª§Ë°åÈÉ®ÁΩ≤\nÊ≥®ÊÑè: netdisk-fast-download.service‰∏≠ÁöÑExecStartÁöÑË∑ØÂæÑÊîπ‰∏∫ÂÆûÈôÖË∑ØÂæÑ\ncd\n~\nwget -O netdisk-fast-download.zip https://github.com/qaiu/netdisk-fast-download/releases/download/v0.1.9b7/netdisk-fast-download-bin.zip\nunzip netdisk-fast-download-bin.zip\ncd\nnetdisk-fast-download\nbash service-install.sh\nÊúçÂä°Áõ∏ÂÖ≥ÂëΩ‰ª§:\nÊü•ÁúãÊúçÂä°Áä∂ÊÄÅ\nsystemctl status netdisk-fast-download.service\nÂêØÂä®ÊúçÂä°\nsystemctl start netdisk-fast-download.service\nÈáçÂêØÊúçÂä°\nsystemctl restart netdisk-fast-download.service\nÂÅúÊ≠¢ÊúçÂä°\nsystemctl stop netdisk-fast-download.service\nÂºÄÊú∫ÂêØÂä®ÊúçÂä°\nsystemctl enable netdisk-fast-download.service\nÂÅúÊ≠¢ÂºÄÊú∫ÂêØÂä®\nsystemctl disable netdisk-fast-download.service\nWindowsÊúçÂä°ÈÉ®ÁΩ≤\n‰∏ãËΩΩÂπ∂Ëß£ÂéãreleasesÁâàÊú¨netdisk-fast-download-bin.zip\nËøõÂÖ•netdisk-fast-download‰∏ãÁöÑbinÁõÆÂΩï\n‰ΩøÁî®ÁÆ°ÁêÜÂëòÊùÉÈôêËøêË°ånfd-service-install.bat\nÂ¶ÇÊûú‰∏çÊÉ≥‰ΩøÁî®ÊúçÂä°ËøêË°åÂèØ‰ª•Áõ¥Êé•ËøêË°årun.bat\nÊ≥®ÊÑè: Â¶ÇÊûújdkÁéØÂ¢ÉÂèòÈáèÁöÑjavaÁâàÊú¨‰∏çÊòØ17ËØ∑‰øÆÊîπnfd-service-template.xml‰∏≠ÁöÑjavaÂëΩ‰ª§ÁöÑË∑ØÂæÑÊîπ‰∏∫ÂÆûÈôÖË∑ØÂæÑ\nÁõ∏ÂÖ≥ÈÖçÁΩÆËØ¥Êòé\nresourcesÁõÆÂΩï‰∏ãÂåÖÂê´ÊúçÂä°Á´ØÈÖçÁΩÆÊñá‰ª∂ ÈÖçÁΩÆÊñá‰ª∂Ëá™Â∏¶ËØ¥ÊòéÔºåÂÖ∑‰ΩìËØ∑Êü•ÁúãÈÖçÁΩÆÊñá‰ª∂ÂÜÖÂÆπÔºå\napp-dev.yml ÂèØ‰ª•ÈÖçÁΩÆËß£ÊûêÊúçÂä°Áõ∏ÂÖ≥‰ø°ÊÅØÔºå ÂåÖÊã¨Á´ØÂè£ÔºåÂüüÂêçÔºåÁºìÂ≠òÊó∂ÈïøÁ≠â\nserver-proxy.yml ÂèØ‰ª•ÈÖçÁΩÆ‰ª£ÁêÜÊúçÂä°ËøêË°åÁöÑÁõ∏ÂÖ≥‰ø°ÊÅØÔºå ÂåÖÊã¨ÂâçÁ´ØÂèçÂêë‰ª£ÁêÜÁ´ØÂè£ÔºåË∑ØÂæÑÁ≠â\nip‰ª£ÁêÜÈÖçÁΩÆËØ¥Êòé\nÊúâÊó∂ÂÄôËß£ÊûêÈáèÂæàÂ§ßÔºåIPÂÆπÊòìË¢´banÔºåËøôÊó∂ÂÄôÂèØ‰ª•‰ΩøÁî®ÂÖ∂‰ªñÊúçÂä°Âô®Êê≠Âª∫nfd-proxy‰ª£ÁêÜÊúçÂä°„ÄÇ\n‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂Ôºö\napp-dev.yml\nproxy\n:\n  -\npanTypes\n:\npgd,pdb,pod\n#\nÁΩëÁõòÊ†áËØÜ\ntype\n:\nhttp\n#\nÊîØÊåÅhttp/socks4/socks5\nhost\n:\n127.0.0.1\n#\n‰ª£ÁêÜIP\nport\n:\n7890\n#\nÁ´ØÂè£\nusername\n:\n#\nÁî®Êà∑Âêç\npassword\n:\n#\nÂØÜÁ†Å\nnfd-proxyÊê≠Âª∫http‰ª£ÁêÜÊúçÂä°Âô®\nÂèÇËÄÉ\nhttps://github.com/nfd-parser/nfd-proxy\n0.1.9 ÂºÄÂèëËÆ°Âàí\nÁõÆÂΩïËß£Êûê(‰∏ìÂ±ûÁâà)\nÂ∏¶cookie/tokenÂèÇÊï∞Ëß£ÊûêÂ§ßÊñá‰ª∂(‰∏ìÂ±ûÁâà)\nÊäÄÊúØÊ†à:\nJdk17+Vert.x4\nCoreÊ®°ÂùóÈõÜÊàêVert.xÂÆûÁé∞Á±ª‰ººspringÁöÑÊ≥®Ëß£ÂºèË∑ØÁî±API\nStar History\nÂÖçË¥£Â£∞Êòé\nÁî®Êà∑Âú®‰ΩøÁî®Êú¨È°πÁõÆÊó∂ÔºåÂ∫îËá™Ë°åÊâøÊãÖÈ£éÈô©ÔºåÂπ∂Á°Æ‰øùÂÖ∂Ë°å‰∏∫Á¨¶ÂêàÂΩìÂú∞Ê≥ïÂæãÊ≥ïËßÑÂèäÁΩëÁõòÊúçÂä°Êèê‰æõÂïÜÁöÑ‰ΩøÁî®Êù°Ê¨æ„ÄÇ\nÂºÄÂèëËÄÖ‰∏çÂØπÁî®Êà∑Âõ†‰ΩøÁî®Êú¨È°πÁõÆËÄåÂØºËá¥ÁöÑ‰ªª‰ΩïÂêéÊûúË¥üË¥£ÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÊï∞ÊçÆ‰∏¢Â§±„ÄÅÈöêÁßÅÊ≥ÑÈú≤„ÄÅË¥¶Âè∑Â∞ÅÁ¶ÅÊàñÂÖ∂‰ªñ‰ªª‰ΩïÂΩ¢ÂºèÁöÑÊçüÂÆ≥„ÄÇ\nÊîØÊåÅËØ•È°πÁõÆ\nÂºÄÊ∫ê‰∏çÊòìÔºåÁî®Áà±ÂèëÁîµÔºåÊú¨È°πÁõÆÈïøÊúüÁª¥Êä§Â¶ÇÊûúËßâÂæóÊúâÂ∏ÆÂä©, ÂèØ‰ª•ËØ∑‰ΩúËÄÖÂñùÊùØÂíñÂï°, ÊÑüË∞¢ÊîØÊåÅ\nÂÖ≥‰∫é‰∏ìÂ±ûÁâà\n99ÂÖÉ, Êèê‰æõÂØπÂ∞èÈ£ûÊú∫,ËìùÂ•è‰ºò‰∫´Â§ßÊñá‰ª∂Ëß£ÊûêÁöÑÊîØÊåÅ, Êèê‰æõÂ§©Áøº‰∫ëÁõò,ÁßªÂä®‰∫ëÁõò,ËÅîÈÄö‰∫ëÁõòÁöÑËß£ÊûêÊîØÊåÅ\n199ÂÖÉ, ÂåÖÂê´ÈÉ®ÁΩ≤ÊúçÂä°ÂíåÈ¶ñÈ°µÂÆöÂà∂, ÈúÄÊèê‰æõÂÆùÂ°îÁéØÂ¢É\nÂèØ‰ª•Êèê‰æõÂäüËÉΩÂÆöÂà∂ÂºÄÂèë, Âä†v‰ª∑Ê†ºËØ¶Ë∞à:\nqq: 197575894\nwechat: imcoding_",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 32",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 2,248"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/qaiu/netdisk-fast-download"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/helix-editor/helix",
      "title": "helix-editor/helix",
      "date": null,
      "executive_summary": [
        "A post-modern modal text editor.",
        "---",
        "A\nKakoune\n/\nNeovim\ninspired editor, written in Rust.\nThe editing model is very heavily based on Kakoune; during development I found\nmyself agreeing with most of Kakoune's design decisions.\nFor more information, see the\nwebsite\nor\ndocumentation\n.\nAll shortcuts/keymaps can be found\nin the documentation on the website\n.\nTroubleshooting\nFeatures\nVim-like modal editing\nMultiple selections\nBuilt-in language server support\nSmart, incremental syntax highlighting and code editing via tree-sitter\nAlthough it's primarily a terminal-based editor, I am interested in exploring\na custom renderer (similar to Emacs) using wgpu or skulpin.\nNote: Only certain languages have indentation definitions at the moment. Check\nruntime/queries/<lang>/\nfor\nindents.scm\n.\nInstallation\nInstallation documentation\n.\nContributing\nContributing guidelines can be found\nhere\n.\nGetting help\nYour question might already be answered on the\nFAQ\n.\nDiscuss the project on the community\nMatrix Space\n(make sure to join\n#helix-editor:matrix.org\nif you're on a client that doesn't support Matrix Spaces yet).\nCredits\nThanks to\n@jakenvac\nfor designing the logo!",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 31",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 40,220"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/helix-editor/helix"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    },
    {
      "url": "https://github.com/Ranchero-Software/NetNewsWire",
      "title": "Ranchero-Software/NetNewsWire",
      "date": null,
      "executive_summary": [
        "RSS reader for macOS and iOS.",
        "---",
        "NetNewsWire\nNetNewsWire is a free and open-source feed reader for macOS and iOS.\nIt supports\nRSS\n,\nAtom\n,\nJSON Feed\n, and\nRSS-in-JSON\nformats.\nMore info:\nhttps://netnewswire.com/\nYou can\nreport bugs and make feature requests\nhere on GitHub. You can also\nread change notes\nfor current and previous releases.\nHere‚Äôs\nHow to Support NetNewsWire\n. Spoiler: don‚Äôt send money. :)\n(NetNewsWire‚Äôs Help menu has these links, so you don‚Äôt have to remember to come back to this page.)\nCommunity\nJoin the Slack group\nto talk with other NetNewsWire users ‚Äî¬†and to help out, if you‚Äôd like to, by testing, coding, writing, providing feedback, or just helping us think things through. Everybody is welcome and encouraged to join.\nEvery community member is expected to abide by the\ncode of conduct\nwhich is included in the\nContributing\npage.\nPull Requests\nSee the\nContributing\npage for our process. It‚Äôs pretty straightforward.\nBuilding\nYou can build and test NetNewsWire without a paid developer account.\ngit clone https://github.com/Ranchero-Software/NetNewsWire.git\nYou can locally override the Xcode settings for code signing\nby creating a\nDeveloperSettings.xcconfig\nfile locally at the appropriate path.\nThis allows for a pristine project with code signing set up with the appropriate\ndeveloper ID and certificates, and for developer to be able to have local settings\nwithout needing to check in anything into source control.\nYou can do this in one of two ways: using the included\nsetup.sh\nscript or by creating the folder structure and file manually.\nUsing\nsetup.sh\nOpen Terminal and\ncd\ninto the NetNewsWire directory.\nRun this command to ensure you have execution rights for the script:\nchmod +x setup.sh\nExecute the script with the following command:\n./setup.sh\nand complete the answers.\nManually\nMake a directory\nSharedXcodeSettings\nnext to where you have this repository.\nThe directory structure is:\ndirectory/\n  SharedXcodeSettings/\n    DeveloperSettings.xcconfig\n  NetNewsWire/\n    NetNewsWire.xcodeproj\nExample:\nIf your NetNewsWire Xcode project file is at:\n/Users/name/projects/NetNewsWire/NetNewsWire.xcodeproj\nCreate your\nDeveloperSettings.xcconfig\nfile at\n/Users/name/projects/SharedXcodeSettings/DeveloperSettings.xcconfig\nThen create a plain text file in it:\nSharedXcodeSettings/DeveloperSettings.xcconfig\nand\ngive it the contents:\nCODE_SIGN_IDENTITY = Mac Developer\nDEVELOPMENT_TEAM = <Your Team ID>\nCODE_SIGN_STYLE = Automatic\nORGANIZATION_IDENTIFIER = <Your Domain Name Reversed>\nDEVELOPER_ENTITLEMENTS = -dev\nPROVISIONING_PROFILE_SPECIFIER =\nSet\nDEVELOPMENT_TEAM\nto your Apple supplied development team.  You can use Keychain\nAccess to\nfind your development team ID\n.\nSet\nORGANIZATION_IDENTIFIER\nto a reversed domain name that you control or have made up.\nNote that\nPROVISIONING_PROFILE_SPECIFIER\nshould not have a value associated with it.\nYou can now open the\nNetNewsWire.xccodeproj\nin Xcode.\nNow you should be able to build without code signing errors and without modifying\nthe NetNewsWire Xcode project.  This is a special build of NetNewsWire with some\nfunctionality disabled.  This is because we have API keys that can't be stored in the\nrepository or shared between developers.  Certain account types, like iCloud and Feedly, aren't\nenabled and the Reader View isn't enabled because of this.\nIf you have any problems, we will help you out in Slack (\nsee above\n).",
        "‰ªäÊó•„ÅÆÁç≤Âæó„Çπ„Çø„ÉºÊï∞: 30",
        "Á¥ØÁ©ç„Çπ„Çø„ÉºÊï∞: 9,152"
      ],
      "key_findings": null,
      "references": [
        "https://github.com/Ranchero-Software/NetNewsWire"
      ],
      "retrieved_at": "2025-10-10T02:09:56Z"
    }
  ]
}