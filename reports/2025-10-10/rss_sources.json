{
  "generated_at": "2025-10-10T02:10:08Z",
  "site": "tech-blogs/rss-sources",
  "num_articles": 4,
  "sources": [
    {
      "feed_name": "The Airbnb Tech Blog - Medium",
      "category": "tech_blogs",
      "title": "From Static Rate Limiting to Adaptive Traffic Management in Airbnbâ€™s Key-Value Store",
      "url": "https://medium.com/airbnb-engineering/from-static-rate-limiting-to-adaptive-traffic-management-in-airbnbs-key-value-store-29362764e5c2?source=rss----53c7c27702d5---4",
      "date": "2025-10-09T16:01:55",
      "text": "How Airbnb hardened Mussel, our key-value store, with smarter traffic controls to stay fast and reliable during trafficÂ spikes. By Shravan Gaonkar , Casey Getz , WonheeÂ Cho Introduction Every request lookup on Airbnb, from stays, experiences, and services search to customer support inquiries ultimately hits Mussel , our multi-tenant key-value store for derived data. Mussel operates as a proxy service, deployed as a fleet of stateless dispatchersâ€Šâ€”â€Šeach a Kubernetes pod. On a typical day, this fleet handles millions of predictable point and range reads. During peak events, however, it must absorb several-fold higher volume, terabyte-scale bulk uploads, and sudden bursts from automated bots or DDoS attacks. Its ability to reliably serve this volatile mix of traffic is therefore critical to both the Airbnb user experience and the stability of the many services that power our platform. Given Musselâ€™s traffic volume and its role in core Airbnb flows, quality of service (QoS) is one of the productâ€™s defining features. The first-generation QoS system was primarily an isolation tool. It relied on a Redis-backed counter, client quota based rate-limiter, that checked a callerâ€™s requests per second (QPS) against a configurable fixed quota. The goal was to prevent a single misbehaving client from overwhelming the service and causing a complete outage. For this purpose, it was simple and effective. However, as the service matured, our goal shifted from merely preventing meltdowns to maximizing goodputâ€Šâ€”â€Šthat is, getting the most useful work done without degrading performance. A system of fixed, manually configured quotas canâ€™t achieve this, as it canâ€™t adapt in real time to shifting traffic patterns, new query shapes, or sudden threats like a DDoS attack. A truly effective QoS system needs to be adaptive, automatically exerting prioritized backpressure when it senses the system has reached its useful capacity. To better match our QoS system to the realities of online traffic and maximize goodput, over time we evolved it to add several newÂ layers. Resource-aware rate control (RARC) : Charges each request in request units (RU) that reflect rows, bytes, and latency, not justÂ counts. Load shedding with criticality tiers : Guarantees that high-priority traffic (e.g., customer support, trust and safety) stays responsive when capacity evaporates. Hot-key detection & DDoS mitigation : Detects skewed access patterns in real time and then shields the backendâ€Šâ€”â€Šwhether the surge is legitimate or a DDoS burstâ€Šâ€”â€Šby caching or coalescing the duplicate requests before they reach the storageÂ layer. What follows is an engineerâ€™s view of how these layers were designed, deployed, and battle-tested, and why the same ideas may apply to any multi-tenant system that has outgrown simple QPSÂ limits. Progression Timeline Background: Life with Client Quota RateÂ Limiter When Mussel launched, rate-limiting was entirely handled via simple QPS rate-limiting using a Redis-based distributed counter service. Each caller received a static, per-minute quota, and the dispatcher incremented a Redis key for every incoming request. If the keyâ€™s value exceeded the callerâ€™s quota, the dispatcher returned an HTTP 429. The design was simple, predictable, and easy toÂ operate. Two architectural details made this feasible. First, Mussel and its storage engine were tightly coupled; backend effort correlated reasonably well with the number of calls at the front door. Second, the traffic mix was modest in size and variety, so a single global limit per caller rarely causedÂ trouble. As adoption grew, two limitations becameÂ clear. Cost variance: A one-row lookup and a 100,000-row scan were treated equally, even though their load on the backend differed by orders of magnitude. The system couldnâ€™t distinguish high-value cheap work from low-value expensive work. Traffic skew: Per-caller rate limits provided isolation at the client level, but were blind to the dataâ€™s access pattern. When a single key became â€œhotâ€â€Šâ€”â€Šfor example, a popular listing accessed by thousands of different callers simultaneouslyâ€Šâ€”â€Šthe aggregate traffic could overwhelm the underlying storage shard, even if each individual caller remained within its quota. This created a localized bottleneck that degraded performance for the entire cluster, impacting clients requesting completely unrelated data. Isolation by caller was insufficient to prevent this kind of resource contention. Addressing these gaps meant shifting from a request-counting mindset to a resource-accounting mindset and designing controls that reflect the real cost of each operation. Resource-aware rateÂ control A fair quota system must account for the real work a request imposes on the storage layer. Resource-aware rate control (RARC) meets this need by charging operations in request units (RU) rather than raw requests perÂ second. A request unit blends four observable factors: fixed per-call overhead, rows processed, payload bytes, andâ€Šâ€”â€Šcruciallyâ€Šâ€”â€Šlatency. Latency captures effects that rows and bytes alone miss: two one-megabyte reads can differ greatly in cost if one hits cache and the other triggers disk. In practice, we use a linear model. For both reads and writes, the costÂ is: RU_read = 1 + w_r Ã— bytes_read + w_l Ã— latency_ms RU_write = 6 + w_b Ã— bytes_written / 4096 bytes + w_l Ã— latency_ms Weight factors w_r, w_b, and w_l come from load-test calibration based on the compute, network and disk I/O. bytes_read, bytes_written and latency is measured per request Although approximate, the formula separates operations whose surface metrics look similar yet load the backend very differently. Impact of Latency on RU computation Each dispatcher continues to rely on rate-limiter for distributed counting, but the counter now represents request-unit tokens instead of raw QPS. At the start of every epoch, the dispatcher adds the callerâ€™s static RU quota to a local token bucket and immediately debits that bucket by the RU cost of each incoming request. When the bucket is empty, the request is rejected with HTTP 419. Because all dispatchers follow the same procedure and epochs are short, their buckets remain closely aligned without additional coordination. Adaptive protection is handled in the separate load-shedding layer; backend latency influences which traffic is dropped or delayed, not the size of the periodic RU refill. This keeps rate accounting straightforwardâ€Šâ€”â€Šstatic quotas expressed in request unitsâ€Šâ€”â€Šwhile still reacting quickly when the storage layer shows signs ofÂ stress. Load shedding: Staying healthy when capacity evaporates or developsÂ hotspots Rate limits based on request units excel at smoothing normal traffic, but they adjust on a scale of seconds. When the workload shifts fasterâ€Šâ€”â€Ša bot floods a key, a shard stalls, or a batch job begins a full-table scanâ€Šâ€”â€Šthose seconds are enough for queues to balloon and service-level objectives to slip. To bridge this reaction-time gap, Mussel uses a load-shedding safety net that combines three real-time signals: (1) traffic criticality, (2) a latency ratio, and (3) a CoDel-inspired queueingÂ policy. The latency ratio is a ratio that serves as a real-time indicator of stress on the system stress. Each dispatcher computes this ratio by dividing the long-term p95 latency by the short-term p95 latency. A stable system has a ratio near 1.0; a value dropping towards 0.3 indicates that latency is rising sharply. When that threshold is crossed, the dispatcher temporarily increases the RU cost applied to a designated client class so that its token bucket drains faster and the request rate naturally backs off. If the ratio keeps falling, the same penalty can be expanded to additional classes until latency returns to a safeÂ range. The estimate uses the constant-memory PÂ² algorithm [1], requiring no raw sample storage or cross-node coordination. Latency response over time and illustration of throttling The Control-Delay (CoDel) thread pool tackles the second hazard: queue buildup inside the dispatcher itself [2]. It monitors the time a request waits in the queue. If that sojourn time proves the system is already saturated, the request fails early, freeing up memory and threads for higher-priority work. An optional latency penalty can also be applied to RU accounting, charging more for queries from callers that persistently trigger the latencyÂ ratio. Together, these layersâ€Šâ€”â€Šcriticality, a real-time latency ratio, and adaptive queueingâ€Šâ€”â€Šform a shield that lets guest-facing traffic ride out backend hiccups. In practice, this system has cut recovery times by about half and keeps dispatchers stable without human intervention. Hot-key detection and DDoSÂ defence Request-unit limits and load shedding keep client usage fair, but they cannot stop a stampede of identical reads aimed at one record. Imagine a listing that hits the front page of a major news outlet: tens of thousands of guests refresh their browser, all asking for the same key. A misconfigured crawlerâ€Šâ€”â€Šor a deliberate botnetâ€Šâ€”â€Šcan generate the same access pattern, only faster. The result is shard overload, a full dispatcher queue, and rising latency for unrelated work. Mussel neutralises this amplification with a three-step hot-key defence layer : real-time detection, local caching, and request coalescing. Real-time detection in constantÂ space Every dispatcher streams incoming keys into an in-memory top-k counter. The counter is a variant of the Space-Saving algorithm [2] popularized in Brian Hayesâ€™s â€œBritney Spears Problemâ€ essay [4]. In just a few megabytes, it tracks approximate hit counts, maintains a frequency-ordered heap, and surfaces the hottest keys in real time in each individual dispatcher. Local caching and request coalescing When a key crosses the hot threshold, the dispatcher serves it from a process-local LRU cache. Entries expire after roughly three seconds, so they vanish as soon as demand cools; no global cache is required. A cache miss can still arrive multiple times in the same millisecond, so the dispatcher tracks in-flight reads for hot keys. New arrivals attach to the pending future; the first backend response then fans out to all waiters. In most cases only one request per hot key per dispatcher pod ever reaches the storageÂ layer. Impact in production In a controlled DDoS drill that targeted a small set of keys at â‰ˆ million-QPS scale, the hot-key layer collapsed the burst to a trickleâ€Šâ€”â€Šeach dispatcher forwarded only an occasional request, well below the capacity of any individual shardâ€Šâ€”â€Šso the backend never felt theÂ surge. Hotkeys detected and served from dispatcher cache in realÂ time Retrospective and key takeaways The journey from a single QPS counter to a layered, cost-aware QoS stack has reshaped how Mussel handles traffic and, just as importantly, how engineers think about fairness and resilience. A few themes surface when we look back across the stages described above. The first is the value of early, visible impact. The initial release of request-unit accounting went live well before load shedding or hot-key defence. Soon after deployment it automatically throttled a caller whose range scans had been quietly inflating cluster latency. That early win validated the concept and built momentum for the deeper changes that followed. A second lesson is to prefer to keep control loops local. All the key signalsâ€Šâ€”â€ŠPÂ² latency quantiles, the Space-Saving top-k counter, and CoDel queue delayâ€Šâ€”â€Šrun entirely inside each dispatcher. Because no cross-node coordination is required, the system scales linearly and continues to protect capacity even if the control plane is itself underÂ stress. Third, effective protection works on two different time-scales . Per-call RU pricing catches micro-spikes; the latency ratio and CoDel queue thresholds respond to macro slow-downs. Neither mechanism alone would have kept latency flat during the last controlled DDoS drill, but in concert they absorbed the shock and recovered withinÂ seconds. Finally, QoS is a living system. Traffic patterns evolve, back-end capabilities improve, and new workloads appear. Planned next steps include database-native resource groups and automatic quota tuning from thirty-day usage curves. The principles that guided this projectâ€Šâ€”â€Šmeasure true cost, react locally and quickly, layer defencesâ€Šâ€”â€Šform a durable template, but the implementation will continue to grow with the platform it protects. Does this type of work interest you? Weâ€™re hiring, check out open roles here . ğŸ“š References Raj Jain and Imrich Chlamtac. 1985. The PÂ² algorithm for dynamic calculation of quantiles and histograms without storing observations. Communications of the ACM , 28 (10), 1076â€“1085. https://doi.org/10.1145/4372.4378 Erik D. Demaine, Alejandro LÃ³pez-Ortiz, and J. Ian Munro. 2002. Frequency estimation of internet packet streams with limited space. In Algorithmsâ€Šâ€”â€ŠESA 2002: 10th Annual European Symposium , Rome, Italy, September 17â€“21, 2002. Rolf H. MÃ¶hring and Rajeev Raman (Eds.). Lecture Notes in Computer Science , Vol. 2461 . Springer, 348â€“360. Kathleen M. Nichols and Van Jacobson. 2012. Controlling queue delay. Communications of the ACM , 55 (7), 42â€“50. https://doi.org/10.1145/2209249.2209264 Brian Hayes. 2008. Computing science: The Britney Spears problem. American Scientist , 96 (4), 274â€“279. https://www.americanscientist.org/article/the-britney-spears-problem From Static Rate Limiting to Adaptive Traffic Management in Airbnbâ€™s Key-Value Store was originally published in The Airbnb Tech Blog on Medium, where people are continuing the conversation by highlighting and responding to this story."
    },
    {
      "feed_name": "AI News",
      "category": "ai_ml",
      "title": "ã€ŒãªãœLLMã¯â€œæ›ã‘ç®—â€ãŒã§ããªã„ã®ã‹ã€è§£æ˜ã€ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚„ã‚·ãƒŠãƒ—ã‚¹ã£ã½ãå‹•ãè„³ã‚’çœŸä¼¼ã—ãŸæ–°è¨€èªAIã€ŒDragon Hatchlingã€ãªã©ç”ŸæˆAIæŠ€è¡“5ã¤ã‚’è§£èª¬ï¼ˆç”ŸæˆAIã‚¦ã‚£ãƒ¼ã‚¯ãƒªãƒ¼ï¼‰ | ãƒ†ã‚¯ãƒã‚¨ãƒƒã‚¸ TechnoEdge",
      "url": "https://www.techno-edge.net/article/2025/10/10/4649.html",
      "date": "2025-10-10T01:21:49",
      "text": "è„³ã®ç¥çµŒå›è·¯ã‚’æ¨¡å€£ã™ã‚‹æ–°è¨€èªãƒ¢ãƒ‡ãƒ«ãŒç´¹ä»‹ã•ã‚Œã‚‹ã€‚ é•·æ™‚é–“å‹•ç”»ç”Ÿæˆã‚’æŒ‡ç¤ºå¤‰æ›´ã®ä¸‹ã§å¯èƒ½ã«ã™ã‚‹æŠ€è¡“ã‚‚ç´¹ä»‹ã€‚ æ›ã‘ç®—ç ”ç©¶ã‚„ä¸–ç•Œãƒ¢ãƒ‡ãƒ«AIãªã©è©±é¡Œã‚’ç¶²ç¾…ã€‚ www.techno-edge.net/article/2025/10/10/4649.html ğŸ–Šï¸ç´„3,000æ–‡å­—, ğŸ§ ğŸ’¡ğŸ“ˆ"
    },
    {
      "feed_name": "Zennã®ã€ŒAIé§†å‹•é–‹ç™ºã€ã®ãƒ•ã‚£ãƒ¼ãƒ‰",
      "category": "zenn",
      "title": "AIé§†å‹•é–‹ç™ºã«ãŠã‘ã‚‹ã€Œå¢ƒç•Œç·šã€ã®å¼•ãæ–¹ ~UIã¯è‡ªç”±ã«ã€ãƒ­ã‚¸ãƒƒã‚¯ã¯ä¸å¤‰ã«~",
      "url": "https://zenn.dev/mk668a/articles/bf6be73d9e8fb1",
      "date": "2025-10-09T22:00:06",
      "text": "ã¯ã˜ã‚ã«\nçµå±€AIé§†å‹•ã§é–‹ç™ºã™ã‚‹æ™‚ã«å›°ã‚‹ã®ã£ã¦ã€ã‚³ãƒ¼ãƒ‰é‡ãŒå¢—ãˆã‚‹ã¨æ•´åˆæ€§ãŒå–ã‚Œãªããªã£ã¦ã„ãã“ã¨ã ã¨æ€ã„ã¾ã™ã€‚\nUIã‚’å¤‰ãˆã‚ˆã†ã¨ã—ã¦ã€æ–°è¦ãƒãƒ£ãƒƒãƒˆã§LLMã«æŒ‡ç¤ºã‚’å‡ºã™ã¨ã€é‡è¤‡ã—ãŸé–¢æ•°ã‚’å¢—ã‚„ã—å§‹ã‚ãŸã‚Šã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ç‹¬è‡ªå®Ÿè£…ã—ãŸã‚Šã€æ—¢å­˜ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½¿ã£ã¦ãã‚Œãªã‹ã£ãŸã‚Šã€ã€ã€\nãã‚“ãªã‚ã‚‹ã‚ã‚‹ã‚’è§£æ±ºã™ã‚‹ã«ã¯ã€å¤‰ãˆã¦ã„ã„ã‚³ãƒ¼ãƒ‰ã¨å¤‰ãˆãŸãç„¡ã„ã‚³ãƒ¼ãƒ‰ã®ç·šå¼•ãã¨ãã®å¢ƒç•Œç·šã®å¼¾ãæ–¹ãŒè‚ã«ãªã‚‹ã®ã§ã¯ãªã„ã§ã—ã‚‡ã†ã‹ã€‚\nå®Ÿéš›ã€é–‹ç™ºã—ã¦ã¦æ€ã†ã®ã¯ã€UIã ã‘ãªã‚‰æ•£ã‚‰ã‹ã£ãŸã‚³ãƒ¼ãƒ‰ã«ãªã£ã¦ã‚‚ãªã‚“ã¨ã‹ä¿®æ­£ã§ãã‚‹ãŒã€ãƒ­ã‚¸ãƒƒã‚¯ã¨UIãŒä¾å­˜ã—ãŸã‚³ãƒ¼ãƒ‰ã®é‡ãŒå¢—ãˆã‚‹ã¨é›£ã—ããªã£ã¦ãã¨ã„ã†ã“ã¨ã§ã™ã€‚é€†ã«è¨€ã†ã¨ã€é©åˆ‡ã«ã‚³..."
    },
    {
      "feed_name": "AIã‚¿ã‚°ãŒä»˜ã‘ã‚‰ã‚ŒãŸæ–°ç€è¨˜äº‹ - Qiita",
      "category": "qiita",
      "title": "ä»Šæ—¥ã®Qiitaãƒˆãƒ¬ãƒ³ãƒ‰è¨˜äº‹ã‚’ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã§è´ã“ã†ï¼ 2025/10/10",
      "url": "https://qiita.com/ennagara128/items/cfbeacfa55d239bdd88e",
      "date": "2025-10-10T01:05:55",
      "text": "å‰æ—¥å¤œã®æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰è¨˜äº‹ã®AIãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã‚’æ¯æ—¥æœ7æ™‚ã«æ›´æ–°ã—ã¦ã„ã¾ã™ã€‚\né€šå‹¤ä¸­ãªã©ã«ãªãŒã‚‰è´ãã—ã‚ˆã†ï¼\nï¼ˆQiitaæŠ•ç¨¿ã¯é€šå‹¤ã«ã¯é–“ã«åˆã‚ãªã„ã¨æ€ã‚ã‚Œã¾ã™ãŒï¼‰\nãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨ã‹åŠ©ã‹ã‚Šã¾ã™ã®ã§ãã ã•ã„\nâ†“ã“ã¡ã‚‰ã‹ã‚‰\n\nå‡ºå…¸\n[ã‚¹ãƒšãƒƒã‚¯é§†å‹•é–‹ç™º] å“è³ªã‚’æ‹…ä¿ã—ãŸ AI é§†..."
    }
  ]
}